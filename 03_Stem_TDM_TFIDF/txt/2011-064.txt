BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2011-064
Semiparametric Estimation with Generated Covariates
Enno Mammen* Christoph Rothe** Melanie Schienle***
* Universität Mannheim, Germany ** Toulouse School of Economics, France *** Humboldt-Universität zu Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Semiparametric Estimation with
Generated Covariates
Enno Mammen, Christoph Rothe, and Melanie Schienle
University of Mannheim, Toulouse School of Economics, and Humboldt University Berlin
This Version: October 17, 2011
Abstract In this paper, we study a general class of semiparametric optimization estimators of a vector-valued parameter. The criterion function depends on two types of infinite-dimensional nuisance parameters: a conditional expectation function that has been estimated nonparametrically using generated covariates, and another estimated function that is used to compute the generated covariates in the first place. We study the asymptotic properties of estimators in this class, which is a nonstandard problem due to the presence of generated covariates. We give conditions under which estimators are root-n consistent and asymptotically normal, and derive a general formula for the asymptotic variance.
JEL Classification: C14, C31 Keywords: Semiparametric estimation, generated covariates, profiling, propensity score
Enno Mammen, Department of Economics, University of Mannheim, D-68131 Mannheim, Germany. E-mail: emammen@rumms.uni-mannheim.de. Christoph Rothe, Toulouse School of Economics, 21 All´ee de Brienne, F-31000 Toulouse, France. E-mail: rothe@cict.fr. Melanie Schienle, School of Business and Economics, Humboldt University Berlin, Spandauer Str. 1, D-10178 Berlin, Germany. E-mail: melanie.schienle@wiwi.hu-berlin.de. The later gratefully acknowledges support of the German Science Foundation via the collaborative research center "Economic Risk".
1

1. Introduction
In this paper, we study a general class of semiparametric optimization estimators of a vector-valued parameter. The criterion function depends on two types of infinitedimensional nuisance parameters: a conditional expectation function that has been estimated nonparametrically using generated covariates, and another estimated function that is used to obtain the generated covariates in the first place. The nonparametric component may be profiled and thus depend on unknown finite-dimensional parameters. Generated covariates may originate from an either parametric, semiparametric or nonparametric first step. Deriving asymptotic properties of estimators in this class is a nonstandard problem due to the presence of generated covariates. We give conditions under which estimators are root-n consistent and asymptotically normal, and derive a general formula for the asymptotic variance. We also apply our methods to two substantial examples: estimation of average treatment effects via regression on the propensity score (Rosenbaum and Rubin, 1983), and estimation of production functions in the presence of serially correlated technology shocks (Olley and Pakes, 1996; Levinsohn and Petrin, 2003). In both cases, our results contribute new insights to the existing literature.
Semiparametric estimation problems involving both finite- and infinite-dimensional parameters are central to econometrics, and are studied extensively under general conditions by e.g. Newey (1994), Andrews (1994), Chen and Shen (1998), Ai and Chen (2003, 2007), Chen, Linton, and Van Keilegom (2003), Chen and Pouzo (2009), or Ichimura and Lee (2010). None of these papers explicitly considers the case of generated covariates in the nonparametric component. However, as we argue in this paper, it turns out that in order to account for such a structure in semiparametric models it is not necessary to derive a completely new theory. Perhaps surprisingly, the "high-level" conditions given in the aforementioned papers are mostly sufficiently general to encompass the generation step, and only the methods used to verify them need to be adapted. Compared to a standard analysis, the main difficulties occur when establishing a uniform rate of consistency for the nonparametric component (e.g. Newey, 1994, Assumption 5.1(ii); or Chen, Linton, and Van Keilegom, 2003, Condition (2.4)), and an asymptotic normality result for a linearized version of the objective function (e.g. Newey, 1994, Assumption 5.3 and
2

Lemma 1; or Chen, Linton, and Van Keilegom, 2003, Condition (2.6)). The main contribution of our paper is to provide a connection between the extensive
literature on estimation and inference in semiparametric models and the one on applications with generated covariates. We derive a new stochastic expansion that characterizes the influence of generated covariates in the model's nonparametric component on the asymptotic properties of the final estimator. We then show how to directly apply this expansion to verify the above-mentioned uniform consistency and asymptotic normality conditions. The expansion, which is proven using techiques from empirical process theory (e.g. Van der Vaart and Wellner, 1996; van de Geer, 2009), is related to a result in Mammen, Rothe, and Schienle (2011) for purely nonparametric regression problems with generated covariates. The main difference is that in the present paper we derive bounds on weighted integrals of the remainder term instead of controlling its supremum norm. This requires substantially different mathematical methods. The new bounds shrink at a considerably faster rate than those obtained in Mammen, Rothe, and Schienle (2011), which is critical for our development of a general theory of semiparametric estimation with generated covariates.
As a further contribution, we provide an explicit formula for the asymptotic variance of semiparametric estimators contained in the general class we consider. Compared to an infeasible procedure that uses the true values of the covariates, the influence function of such an estimator generally contains two additional terms: one that accounts for using generated covariates to estimate the nonparametric component, and one that accounts for the direct influence of generated covariates in other parts of the model, e.g. through determining the point of evaluation of the infinite-dimensional parameter. As a byproduct, we obtain a characterization of cases under which these two adjustment terms exactly offset each other, and thus do not affect first-order asymptotic theory. Our methods can also be used to verify conditions under which a bootstrap procedure leads to asymptotically valid inference. The latter aspect can be important in many applications where the asymptotic variance is difficult to estimate.
Our paper is related to an extensive literature on models with generated covariates. To the best of our knowledge, Newey (1984) and Murphy and Topel (1985) were among the first to study the theoretical properties of such two-step estimators in a fully parametric
3

setting. Pagan (1984) and Oxley and McAleer (1993) provide extensive surveys. Nonparametric regression with (possibly nonparametrically) generated covariates is studied by Mammen, Rothe, and Schienle (2011) under general conditions. See their references for a list of examples, and Andrews (1995), Song (2008) and Sperlich (2009) for related results. Examples of semiparametric applications with generated covariates include Olley and Pakes (1996), Heckman, Ichimura, and Todd (1998), Li and Wooldridge (2002), Levinsohn and Petrin (2003), Blundell and Powell (2004), Linton, Sperlich, and Van Keilegom (2008), Rothe (2009) and Escanciano, Jacho-Ch´avez, and Lewbel (2010), among many others. Hahn and Ridder (2011) use Newey's (1994) path-derivative method to derive the form of the influence function of semiparametric linear, just-identified GMMtype estimators in the presence of generated covariates, but do not study conditions for
 the estimators' n-consistency or asymptotic normality. Our paper complements and extends their findings by deriving such conditions for a larger class of semiparametric models, allowing e.g. for profiled optimization estimators. We also derive a formula for the asymptotic variance of estimators in this more general class, which does not involve functional derivatives, and discuss validity of the bootstrap for inference. Escanciano, Jacho-Cha´vez, and Lewbel (2011) provide stochastic expansions for sample means of weighted semiparametric regression residuals with potentially generated regressors in a particular class of "index models", which is contained in the general class we study in this paper. Their approach also relies on certain high-level conditions that seem to be difficult to verify in practice. Our results use direct bounds to control the impact of generated covariates, and apply to a wider range of applications. We discuss the relationship between Hahn and Ridder (2011), Escanciano, Jacho-Ch´avez, and Lewbel (2011), and the results in our paper in more detail in Section 4.4.
The remainder of the paper is structured as follows: In Section 2, we describe the class of models we consider. In Section 3, we present our main technical result, a stochastic expansion that characterizes the influence of generated covariates in the model's nonparametric component. Section 4 shows how this expansion can be used to verify classic
 conditions for n-consistency and asymptotic normality of semiparametric estimators, and derives a general formula for the asymptotic variance. In Section 5, we discuss two econometric applications that make use of our results. All proofs and further details on
4

the applications are collected in Appendix A and B, respectively.
2. Generated Covariates in Semiparametric Models
We consider a general class of semiparametric optimization estimators where the criterion function depends on two types of infinite dimensional nuisance parameters: a conditional expectation function that has been estimated nonparametrically using generated covariates, and another estimated function that is used to compute the generated covariates in a first step. No specific estimation procedure is required for the latter object. Our results cover both parametrically and nonparametrically generated covariates, as well as intermediate cases. The setting and notation is otherwise similar to Chen, Linton, and Van Keilegom (2003), and thus allows for nonsmooth criterion functions and profiled estimation of the nonparametric components.
2.1. Model and Estimation Procedure. Let Z = (Y, X, W )  RdZ be a random variable distributed according to some probability measure P0 that is contained in a semiparametric model P = {P, :   ,   }, where   Rd denotes a finite dimensional parameter space with generic element , and  = M × R is an infinite dimensional parameter space with generic element  = (m, r). Denote by 0   and 0(·, ) = (m0(·, ), r0(·))   the true values of the finite and infinite dimensional parameter, respectively, which implies that P0 = P0,0(·,0). We assume that there exists a nonrandom function q : supp(Z)××  Rdq such that Q(, 0(·, )) = E(q(Z, , 0(·, ))) = 0 if and only if  = 0. The parametric component of our semiparametric model is thus identified via a moment condition. For simplicity, we also assume that for every    the objective function Q(, (·, )) depends on the nuisance parameter  through its value over some compact set IT × IR only, which is useful to later accommodate "fixed trimming" schemes into the estimation procedure.
We also impose certain restrictions on the nature of the infinite dimensional parameter 0(·, ) = (m0(·, ), r0(·)). First, we assume that r0 is identified from the distribution of W  Z, and that this distribution does not depend on the true value of the other parameters in the model. This allows for a consistent estimate of r0 to be computed without knowledge of 0 and m0. Second, we assume that m0(·, ) is a con-
5

ditional expectation function that depends on    and the true value r0 through the relationship m0(·, ) = E(Y |T (X, , r0) = ·) where T (X, , r) = t(X, r(Xr), ) is a random vector of dimension dT , Xr  X are the covariates that enter the function r, and t : RdX × Rdr ×   RdT is a known function. The role of r0 is thus to generate (some of) the covariates used to compute the function m0. By allowing m0 to depend on X and r0(Xr) through a known transformation indexed by , our setup includes a broad class of index models that require profiling of the nonparametric component.

To make the notation more compact, we usually suppress the arguments of the infinite dimensional parameters, writing (, ) = (, m, r)  (, m(·, ), r(·)), (, 0) = (, m0, r0)  (, m0(·, ), r0(·)), and (0, 0) = (0, m0, r0)  (0, m0(·, 0), r0(·)). We also write T (, r)  T (X, , r), T ()  T (, r0), T (r)  T (0, r) and T  T (0, r0). We assume that  is a class of continuous and bounded functions endowed with the pseudonorm ·  induced by the sup-norm, i.e. we have   = sup supx |m(x, )|+supxr |r(xr)|. We also write B = (tr(B AB))1/2 for any matrix B, where we suppress the dependence

of the norm on the fixed symmetric positive definite matrix A for notational convenience.

Given an i.i.d. sample (Z1, . . . , Zn) from the distribution of Z, a three-step semiparametric extremum estimator ^ of 0 can be constructed as follows. In the first step, we compute a (possibly nonparametric) estimate r^ of r0. In the second step, for every    we obtain an estimate m(·, ) of m0(·, ) through a nonparametric regression of Y on the generated covariates T^() = T (, r^). We discuss how to implement these two estimation procedures in detail below. Finally, writing (, ^) = (, m(·, ), r(·)), we define the estimator ^ of 0 as any approximate solution to the problem of minimizing a semiparametric
GMM-type objective function:

Qn(^, ^)

= inf

Qn(, ^)

 + op(1/ n),



(2.1)

where

Qn(, ^)

=

1 n

n i=1

q(Zi,

,

^).

Here,

we

avoid

evaluating

^ in

areas

where

it

is

im-

precisely estimated by restricting the influence of the nuisance parameter to be exceeded

through its value over some compact set IT ×IR introduced above. Such "fixed trimming"

procedures are commonly used to derive properties of profiled semiparametric estimators.

Our estimator is a semiparametric procedure involving generated covariates, in the

sense that a preliminary estimate r^ of the nuisance parameter r0 is used to compute the

6

covariates entering the nonparametric regression procedure to estimate m0(·, ). Note that because r^ is also allowed to appear as a separate argument in the objective function

Qn, it does not only determine the shape of the function m, but could also exert a direct influence. For instance, the function m can be evaluated at (some transformation of) the

generated covariates. This flexibility is required for all examples we consider below.

For the later asymptotic analysis, it will be useful to also consider an infeasible esti-

mation procedure that uses the true value r0 instead of an estimate r^. Such an estimator ~ of 0 can be obtained by first computing an estimate m(·, ) of m0(·, ) via nonparametric regression of Y on T () for every   , and then finding an approximate minimizer

of an infeasible version of the objective function:

Qn(~, ^)

= inf

Qn(, ~)

 + op(1/ n)



(2.2)

where (, ~) = (, m~ (·, ), r0(·)). In order to distinguish the two procedures, we refer to ^ and m in the following as the real estimators of 0 and m0, respectively, and to ~ and m as the corresponding oracle estimators.

2.2. A Framework for Asymptotic Analysis. It is straightforward to show that ^ is a consistent estimate of the true value 0 under standard conditions. We therefore focus on the more interesting problem of establishing its asymptotic distribution. A number of papers have given "high level" conditions for semiparametric estimators to be root-n consistent and asymptotically normal in models that do not involve generated covariates. Examples include Newey (1994), Andrews (1994), Chen and Shen (1998), Ai and Chen (2003), Chen, Linton, and Van Keilegom (2003), or Ichimura and Lee (2010). It turns out that these conditions are generally sufficient to establish the same type of asymptotic properties for semiparametric estimators in models with generated covariates. What needs to be adjusted, however, are the arguments to verify some of them.
To illustrate how previous results in the literature on semiparametric estimation can be adapted to our context, consider the main theorem from Chen, Linton, and Van Keilegom (2003).1 Before we repeat their result, we have to introduce some further notation. Since
1A similar argument could be made for the respective results in one of the other papers mentioned above.

7

we assume that ^ is consistent, we can work with small subsets of the parameter spaces. For some small  > 0, define  = {   :  - 0  } and  = {   :  - 0   }. Furthermore, for any (, )   × , we denote the ordinary derivative of Q(, ) with respect to  by Q(, ). For any   , we say that Q(, ) is pathwise differentiable at    in the direction ¯ if there exists a continuous linear functional Q(, ) : ×  Rl such that Q(, )[¯] = lim0(Q(,  +  ¯) - Q(, ))/ . The functional Q(, ) is called the pathwise derivative of Q(, ).

Theorem 1 (Chen, Linton, and Van Keilegom (2003)). Suppose that 0  int() satisfies Q(0, 0) = 0, that ^ = 0 + op(1), and that:

(N1)

Qn(^, ^)

= inf

Qn(, ^)

 + op(1/ n).

(N2) (i) the ordinary derivative Q(, 0) of Q(, 0) in  exists for    and is continuous at  = 0; (ii) the matrix Q0 = Q(0, 0) is of full rank.

(N3) For all    the pathwise derivative Q(, 0)[ - 0] of Q(, 0) exists in all

directions [[ - 0]]  ; and for all (, )  n × n with a positive sequence

n = o(1): (i)

Q(, )-Q(, 0)-Q(, 0)[-0]

c

-0

2 

for

a

constant

c



0;

(ii) Q(, 0)[ - 0] - Q0[ - 0]  o(1)n, where Q0[ - 0] = Q(0, 0)[ - 0].

(N4) ^   with probability tending to one; and ^ - 0  = op(n-1/4)

(N5) For any positive sequence n = o(1). 
sup n Qn(, ) - Q(, ) - Qn(0, 0) -0 n, -0 n 1 + n( Qn(, ) + Q(, ) )

= op(1)

(N6)

 n(Qn(0,

0)

+

Q0[^ -

0])

d

N (0,

V

)

for

some

finite

matrix

V.

Then n(^ - 0) d N (0, ), where  = (Q0TAQ0)-1Q0TAV AQ0(Q0TAQ0)-1.

Chen, Linton, and Van Keilegom (2003) provide an extensive discussion of the conditions of Theorem 1, arguing that they are fairly general and thus satisfied in a wide range of semiparametric models. Moreover, the result is sufficiently flexible to apply in our setting. Neither of its conditions nor one of the steps in its proof rules out the type

8

of semiparametric estimation problems with generated covariates we consider in this paper. Asymptotic normality of the real estimator of ^ can thus simply be established by checking (N1)­(N6). There is no need to develop a completely new theory.2
This does not imply that the presence of generated covariates does not affect the asymptotic properties of our estimator. Verification of the "uniform convergence" condition (N4) and the "asymptotic normality" condition (N6) are substantially more complicated, and the asymptotic variance V in (N6) will generally be different from the one we would have obtained if the true value r0 had been used in the estimation procedure instead of the estimate r^. In the following section, we therefore derive new and general methods to check conditions like (N4) and (N6). On the other hand, note that the remaining conditions of Theorem 1 are not affected by the presence of generated covariates, and can thus be verified by standard arguments: (N1) simply states that ^ is an approximate minimizer of the objective function, which we assumed in the first place; (N2) and (N3) are smoothness conditions on the population moment function, and (N5) is a stochastic equicontinuity condition. Neither involves estimates of the nonparametric components of our model, and thus they can be verfied independently of the issue of generated covariates.

3. Controlling the Influence of Generated Covariates

This section contains our main technical result. In particular, we consider a stochastic

expansion of nonparametrically estimated regression functions under very general condi-

tions, deriving a sharp bound on weighted averages of the respective remainder terms.

This is the key ingredient for showing condition (N6). Throughout this section, we use the

notation that for any vector a  Rd the values amin = min1jd aj and amax = max1jd aj

denote the smallest and largest of its elements, respectively, a+ =

d j=1

aj

denotes

the

sum of its elements, a-k = (a1, . . . , ak-1, ak+1, . . . , ad) denotes the d - 1-dimensional subvector of a with the kth element removed, and ab = (a1b1, . . . , abdd) for any vector b  Rd.

2To the best of our knowledge, this point has not been made explicitly in the literature on semipara-

metric estimation. However, it has at least implicitly been noted for a special case in Linton, Sperlich,

and Van Keilegom (2008).

9

3.1. Assumptions. To derive our main result, we need to be more specific about

the estimation procedures for the infinite-dimensional nuisance parameters. We do not

require a specific procedure for the estimator r^ of r0, but only impose certain "high-level"

restrictions that cover a wide range of methods. Given an estimate of r0, for every   

we then obtain an estimate of m0(·, ) through a nonparametric regression of Y on the generated covariates T^() = t(X, r^(Xr), ) using p-th order local polynomial smoothing.

Our estimator is thus given by m(x, ) = , where

n

(, ) = argmin (Yi -  -

uT(Ti() - x)u)2Kh(Ti() - x) ,

, i=1

1u+p

(3.1)

where Kh(v) =

dT j=1

K(vj

/hj

)/hj

is

a

d-dimensional

product

kernel

built

from

the

uni-

variate kernel function K, h = (h1, ..., hdT ) is a vector of bandwidths that tend to zero

as the sample size n tends to infinity, and 1u+p denotes the summation over all u = (u1, . . . , up) with 1  u+  dT . For p = 1, we get the usual local linear estimator.

We allow for uneven orders p > 1 for the purpose of bias control. To present our results

later, it will also be useful to introduce the infeasible oracle estimate m(·, ), which is

obtained via local linear smoothing of Y versus T () for every   , i.e. it is given by

m(x, ) = , where

n

(, ) = argmin (Yi -  -

uT(Ti() - x)u)2Kh(Ti() - x).

, i=1

1u+p

We focus on local polynomial estimation for m0(·, ) in this paper because the particular

structure of the estimator facilitates controlling the presence of generated covariates (see

Mammen, Rothe, and Schienle, 2011), and does not require a separate treatment of

boundary regions. While it might be possible to conduct a similar analysis for other

nonparametric procedures, such as e.g. orthogonal series estimators, we conjecture that

this would require substantially more involved technical arguments.

Assumption 1 (Regularity). We assume the following properties for the data distribution, the bandwidth, and kernel function K.

(i) The sample observations Zi are independent and identically distributed.

(ii) The parameter space  is compact. For every   , the random vector T () = t(X, r0(Xr), ) is continuously distributed with compact support IT satisfying IT 

10

int(IT ) with IT compact. The corresponding density function fT (·, ) is continuously differentiable for every   , and inf,xIT fT (x, ) > 0.
(iii) For every   , the functions m0(·, ) and t(·, ) are (p + 1)-times continuously differentiable on their respective domains.
(iv) For a constant C > 0 it holds that E[exp(l|Y |)]  C for l > 0 small enough.
(v) The function K is twice continuously differentiable and satisfies the following conditions: K(u)du = 1, uK(u)du = 0 and |u2K(u)|du < , and K(u) = 0 for values of u not contained in some compact interval, say [-1, 1].
(vi) The bandwidth h = (h1, . . . , hdT ) satisfies hj  n-j for all j = 1, . . . , dT , and (1 - +)/2 > max.
Most restrictions imposed in Assumption 1 are standard for nonparametric kernel-type estimators of nuisance functions in semiparametric models. Part (i) is not necessary and could be relaxed to allow for certain forms of temporal dependence. Part (ii) introduces a "fixed trimming" procedure, ensuring a stable estimate m(·, ) at the points of evaluation. The differentiability conditions in (iii) are used to control the magnitude of bias terms. Assuming subexponential tails of  conditional on T () in part (iv) is necessary to apply certain results from empirical process theory in our proofs. Part (v) describes a standard kernel function with compact support. Finally, the restrictions on the bandwidth in (vi) imply that those bias terms are dominated by certain stochastic terms.
Assumption 2 (Accuracy). We assume the following properties of the estimator r: (i) sups |rj(s) - r0,j(s)| = oP (n-j) for some j > 1/4 and all j = 1, . . . , dr, and (ii) sup,x |Tj(x, , r) - Tj(x, , r0)| = oP (n-j ) for some j > j and all j = 1, . . . , dt,
where in both cases the subscript j denotes the j-th component of the respective object.
Assumption 2 imposes restrictions on the accuracy of the first-step estimator r^: part (i) is needed for condition (N4) of Theorem 1 to hold, whereas part (ii) ensures that the difference between the respective components of T () and T () tend to zero in probability at a rate as least as fast as the corresponding bandwidth in the second stage of the
11

estimation procedure, uniformly in . Such conditions can be verified for a wide range of nonparametric estimators (e.g. Masry (1996), Newey (1997)), and they trivially hold for regular parametric estimators.
Assumption 3 (Complexity). For every j = 1, . . . , dT , there exist a sequence of sets of functions Tn,j such that
(i) Pr(Tj(·, r)  Tn,j)  1 as n  .
(ii) For a constant CT > 0 and a function rn with Tj(x, , rn) - Tj(x, , r0)  = oP (n-j ), the set Tn,j = Tn,j  {Tj(·, r) : Tj(x, , r) - Tj(x, , rn)   n-j } can be covered by at most CT exp(-j nj ) balls with · -radius  for all   n-j , where 0 < j  2, j  R and ·  denotes the supremum norm in x  X and   .
Assumption 3 restricts the complexity of the function space in which the mapping (x, )  T (x, , r) takes its values by imposing constraints on the cardinality of the covering sets. Since we have that T (x, , r) = t(x, r(xr), ) for some known function t which, by Assumption 1(iii), is continuously differentiable with respect to its second component, the condition imposes implicit restrictions on the complexity of the first-stage estimator r. Indeed, we could equivalently state a restriction similar to Assumption 3 on the set Rn = {r  R : Tj(·, r)  Tn,j for all j = 1, . . . , dT }.
Restrictions on covering numbers are a common requirement in the literature on empirical processes, that is typically fulfilled under suitable smoothness assumptions. Suppose for example that Rn is the set of smooth functions defined on the compact set IR  RdXr , whose partial derivatives up to order k exist and are uniformly bounded by some multiple of nj for some j  0, and that |Tj(x, r(xr), ) - Tj(x, r(xr), )|  C  -  for every ,  and every value of x and r. Then the set Tn,j satisfies Assumption 3(ii) with j = dXr /k and j = jj (Van der Vaart and Wellner, 1996, Corollary 2.7.2). The same entropy bound applies if Rn consists in the sum of one fixed function and a smooth function from a respective smoothness class. This extension is useful if one chooses the fixed function as equal to the sum of r0 and the bias of r. Thus it is not necessary that the bias term is a smooth function. In a setting where r0 is estimated by parametric or semiparametric methods, substantially smaller values can be established for the constants j and j. See e.g. van de Geer (2009) for further discussion and examples.
12

Assumption 4 (Continuity). We assume that the elements of Rn = {r  R : Tj(·, r)  Tn,j for all j = 1, . . . , dT } satisfy the following properties:
(i) For all r  Rn and    the function  B(t, , r) = E((X, )|T (r) = t) with (X, ) = E(Y |X) - E(Y |T ()) is p + 1 times differentiable with respect to its first argument, and the derivatives are uniformly bounded in absolute value.
(ii) For a constant CB > 0 and for r1, r2  Rn ,    it holds that
 B(T (r1), , r1) -  B(T (r2), , r2)  CB r1 - r2  a.s.
(iii) For a constant CB > 0 and all r1, r2  Rn ,    and t  IT it holds that
E (T (, r1) - t)uh-uKh(T (, r1) - t) - E (T (, r2) - t)uh-uKh(T (, r2) - t)  CB r1 - r2 
for 0  u+  p.
Assumption 4(i)­(ii) are technical conditions that ensure that the conditional expectation of the "index bias" (X, ) satisfies certain smoothness restrictions. In certain applications, we have that (X, ) = 0 with probability 1, and thus these conditions trivially hold. Assumption 4(iii) is a further smoothness condition. If the random vector r(Xr) is continuously distributed, this condition holds if f1 - f2   CB r1 - r2  for all r1, r2  Rn , where fj denotes the density function of rj(Xr) for j = 1, 2. See Escanciano, Jacho-Ch´avez, and Lewbel (2011, Assumption 10) for a similar restriction on the densities of the generated covariates.

3.2. Stochastic Expansions of the Nonparametric Component. Using the assumptions outlined above, we can now derive a sharp stochastic approximation of the nonparametric estimator m. To state the result, we denote the unit vector (1, 0, . . . , 0) in Rp+1 by e1, and write wi(t, , r) = (1, (Ti(r, )-t)/h, ..., (Ti(r, )-t)p/hp) and Nh(x, ) = E(wi(t, , r)wi(t, , r) Kh(Ti(r, ) - t)). Recalling that (X, ) = E(Y |X) - E(Y |T ()), we then define the approximating function m by

m(t, ) = m~ (t, ) + nA(t, , r) + Bn (t, , r),

(3.2)

13

where

nA(t, , r) = -m0(t, )e1 Nh(x, )-1E(Kh(Ti() - t)wi(x, )(Ti(r, ) - Ti()))

in case of local linear regression with p = 1 (a general, notationally much more involved definition for higher order local polynomials is given in (A.2) in Appendix A), and

nB(t, , r) = e1 Nh(x, )-1E(Kh(Ti() - t) wi(x, )(Ti(r, ) - Ti())(X, ))
for any r  Rn. Here we use the notation Kh(v) = (Kh,j(v) : j = 1, ..., dT ) with elements Kh,j(v) = K (vj/hj)/hj2 j=j K(vj/hj)/hj. Our main result concerns the accuracy when using m as an approximation of m.
Theorem 2. Suppose that Assumption 1­4 hold. Then for any   , it is

(m(t, ) - m(t, ))(x)dx = op(n-)

(3.3)

for some weight function  : Rd  R whose partial derivatives of order one are uniformly absolutely bounded, and that satisfies (x) = 0 for all x / IT , and  = min{1, . . . , 4} with

1 =

1 2

+

(1

-

max 2

)min

-

(

+ )max , 2

2 < (p + 1)min + ( - )min,

3

< (2 -

max 2

)min

+

1 2

(1

-

+)

-

( + )max , 2

4 < 2min.

The Theorem provides a sharp bound on weighted averages the the approximation error m(t, ) - m(t, ). We focus on this class of distance measures because they are particularly suitable to verify conditions of the type (N6) in Theorem 1. Bounds on the supremum norm of the approximation error, as studied Mammen, Rothe, and Schienle (2011), typically vanish at a rate slower than n-1/2, and are thus not useful to establish the "asymptotic normality" condition. They can however, with some adaptaion, be employed to verify the "uniform consistency" condition (N4), as explained below.
The function m consists of two components: the term m~ (·, ) is the oracle estimator of m0(·, ) introduced above, whereas nA(t, , r) + nB(t, , r) is an adjustment term that captures the additional uncertainty due to the presence of generated covariates. Note that the generated covariates enter the expansion only through smoothed versions of the

14

estimation error T (, r^)-T (, r0). Since this additional smoothing typically improves the rate of convergence of the stochastic part of the first-step estimator (although it does not improve the order of the bias component), we generally expect the adjustment term to have a faster rate of convergence. Hence the dimensionality of the generation step should play a less pronounced role in this context.

4. Application to Semiparametric Estimation
In this section, we show how to verify conditions of the type (N4) and (N6) in Theorem 1. We also derive a general formula for the asymptotic variance of the estimator ^. Throughout the section, we assume that the smoothness conditions (N2)­(N3) on the criterion function Q hold.

4.1. Verifying "Uniform Consistency". To verify the "Uniform Consistency" condition (N4), we use a variation of an earlier result in Mammen, Rothe, and Schienle (2011) to derive the uniform rate of consistency of the estimator m(t, ).

Theorem 3 (Uniform Consistency). Suppose Assumption 1­3 and 4(i)­(ii) hold. Then

sup |m(t, ) - m0(t, )| = Op n-(p+1)min + log(n)n-(1-+) + n-min + n- ,
tIT ,

where  = min{1, ..., 3} with

1 <

1 (1
2

-

+)

+

(

-

)min

-

1 (
2

+

)max,

2 < (p + 1)min + ( - )min,

3 < min + ( - )min.

The first two terms in the error bound on the right hand side follow from a standard uniform consistency result of the oracle estimator m (Masry, 1996), whereas the remaining two terms are due to the presence of generated covariates. In order for condition (N4) to hold, these terms have to be of smaller order than n-1/4. For the oracle part, this can easily be achieved by choosing an appropriate bandwidth under sufficient smoothness conditions. For the remaining terms, Assumption 2(i) and Assumption 1(iii) jointly imply that min > 1/4. It then follows from simple calculations that Op n-min + n- = op(n-1/4) under appropriate restrictions on the sets Tn,j.3
3Note that when studying the "asymptotic normality" condition (N6) in the next subsection, we will

15

4.2. Verifying "Asymptotic Normality". Given a specific estimator r of r0, the expansion m(t, ) in (3.2) can usually be calculated more explicitly, and can then be used to verify (N6). To illustrate this idea in a general setting, suppose that the estimator used to generate the covariates satisfies the following asymptotically linear representation, which can be shown to be satisfied for a wide range nonparametric, semiparametric, and fully parametric estimation procedures (we discuss two representative examples below).

Assumption 5 (Linear Representation). The estimator r of r0 satisfies

r(s)

-

r0(s)

=

1 n

n

rni(s) + Rn(s)

i=1

(4.1)

with rni(s) = Hn(Si, s)(Wi) for some Si  Wi and supsIR |Rn(s)| = op(n-1/2). The term (Wi) satisfies E((Wi)|Si) = 0 and E((Wi)(Wi) ) < , and Hn is a weighting function satisfying E( Hn(Si, Sj) 2) = o(n) for i = j.

To see how this additional structure can be utilized for our purposes, recall that it follows from elementary rules for pathwise derivatives that

Q0[^ - 0] = Qm(0, 0)[m^ - m0] + Qr(0, 0)[r^ - r0],

where for any (, r) the functional Qm(, )[m¯ ] is the pathwise derivative of Q(, (m, r)) at m in the direction m¯ , and similarly for Qr. In most applications, m and r are square integrable functions of random vectors Zm and Zr, respectively, and it follows from the Riesz representation theorem that there exists unique square integrable functions m and u such that

Qm(0, 0)[m^ - m0] = m(z)(m^ (z) - m0(z))dFZm(z), Qr(0, 0)[r^ - r0] = r(z)(r^(z) - r0(z))dFZr (z).

(4.2) (4.3)

See e.g. Newey (1994). The form of m and r depends on the particular application. For example, if the criterion function Q(, ) = E(q(Z, , m, r)) is such that the term
introduce some additional structure on the estimator r of r0 in Assumption 5. Using this additional structure, it would be possible to derive better rates than the one given in Theorem 3. See the remark at the end of the proof of Theorem 3 in Appendix A for details.

16

q(Z, , m, r) only depends on the functions m and r smoothly through their value when evaluated at some random vectors Zm and Zr, respectively, we have that

m(zm) = E(q(Z, , m0, r0)/m0(Zm, 0)|Zm = zm) r(zr) = E(q(Z, , m0, r0)/r0(Zr)|Zr = zr).

All econometric applications we consider in Section 5 below exhibit this structure.

When m and r are sufficiently smooth, one can use Assumption 5 together with the representation in (3.2) to show that there exist fixed functions j with E(j(Z)) = 0 and E(j(Z)j(Z) ) <  for j = 1, 2, 3 such that

m(z)

1 m(z)m~ (z, 0)dFZm(z) = n

n

1(Zi) + op(n-1/2)

i=1

1 n

n
nAi(z, 0, r^) + Bn (z, 0, r^)

1 dFZm(z) = n

n
2(Zi) + op(n-1/2),

i=1 i=1

1 r(z) n

n

rni(z)dFZr (z)

=

1 n

n

3(Zi) + op(n-1/2).

i=1 i=1

Moreover, the properties of the remainder term Rn(t) = m(t, 0) - m(t, 0) established

in Theorem 2 ensure, under suitable regularity conditions, that

m(z)Rn(z)dFZm(z) = op(n-1/2).

If we now put 0(Zi) = q(Zi, 0, 0) and (z) =

3 j=0

j (z ),

the

above

statements

imply

that

 n(Qn(0, 0)

+

Q0[^ -

0])

=

1 n

n

(Wi) + op(1) d N (0, E((Z)(Z) ))

i=1

(4.4)

by the Central Limit Theorem, and thus condition (N6) holds with V = E((Z)(Z) ).

The following Corollary formalizes this argument, and provides a general formula to

compute the variance matrix V .

Corollary 1 (Normality). Suppose Assumption 1­ 5 holds with p + 1 > dT ,

(

+ )max 2

<

min{(1 -

max 2

)min,

(2

-

max 2

)min

+

1 (1
2

-

+)},

(4.5)

the criterion function satisfies (4.2)­ (4.3) with m(·) and r(·) being (p+1)-times continuously differentiable, and 1/2(p + 1) < j < 1/2dt for j = 1, . . . , dT . Then equation (4.4)

17

holds with

1(Zi) = im(Ti)fZm(Ti)fT (Ti)-1 2(Zi) = -(Wi)E(m (Xr)Hn(Si, Xr)|Si) 3(Zi) = (Wi)E(r(Xr)Hn(Si, Xr)|Si),

where

m (xr) = E(T (r)(X)((X)G (T ) + m0(T )G(T ))|Xr = xr)

and G(t) = m(t)fZm(t)fT (t)-1 and G (t) = tG(t) and T (r)(x) = T (x, 0, r0)/r0(xr).

Restriction (4.5) involves a tradeoff between the complexity of the first and second estimation step for the nonparametric component: It can be shown to be satisfied when r0 is "sufficiently regular" (i.e. the j and j are small) and m0(·, ) is "sufficiently smooth" (i.e. p is large and thus the j can be chosen small). Exact conditions are difficult to give in general, but are easy to check for a specific application, where specific values for the j and j are available. See the discussion after Assumption 3 above for an example.
Assumption 5 is similar to conditions used e.g. in Rothe (2009) or Ichimura and Lee (2010). We now give two examples for which it is satisfied: the case where r0 is a conditional expectation function estimated by nonparametric regression, and the case where r0(xr) = r¯(xr, 0) is a function known up to a finite dimensional parameter 0, for which there exists a regular asymptotically linear estimator. These are arguably the most important cases from an applied point of view.

Example 1 (Nonparametric Regression). Suppose that W is partitioned as W = (D, S), and we have that D = r0(S) +  with E(|S) = 0. Consider a kernel-based nonparametric regression estimator r^ of r0, such as the Nadaraya-Watson or a local polynomial estimator. Then one can show that Assumption 5 holds under suitable smoothness conditions with (Wi) = i and Hn(Si, s) = fS(s)-1Lg(Si - s), where L is a kernel function and g is a bandwidth that tends to zero at an appropriate rate. We then find that

2(Zi)

=

-i

m

(Si)

fXr (Si) fS (Si )

and

3(Zi)

=

i

r

(Si

)

fZr (Si) fS (Si )

.

The form of 0(·) and 1(·) remain unchanged.

18

Example 2 (Nonlinear Parametric Estimation). Assume that r0(xr) = r¯(xr, 0) is a

parametrically specified function (not necessarily a conditional expectation) known up to the finite dimensional parameter 0. Suppose there exists an estimator ^ of 0 that

satisfies



-

0

=

1 n

n

^(Wi) + op(n-1/2),

i=1

where E(^(W )) = 0, E(^(W )^(W ) ) < , and that r(xr, µ) is continuously differentiable in its second argument. Then Assumption 5 is satisfied with (Wi) = ^(Wi)

and Hn(Si, xr) = r(xr, 0), and thus

2(Zi) = -(Wi)E(T r(X)r(Xr, 0)((X)g(T ) + m(T )m0(T )fZm(T )fT (T )-1)) 3(Zi) = (Wi)E(r(Xr)r(Xr, 0)).

In case that r0(xr) = r¯(xr, 0) is a regression function estimated by nonlinear least squares, we have that (Wi) = E(r(Xr, 0)r(Xr, 0) )-1r(Xr,i, 0)(Di - r0(Si)), under the usual conditions.

4.3. The Asymptotic Variance. The argument in the previous subsection conveys some important intuition for the form of the asymptotic variance of ^. Recall that under the conditions of Theorem 1 this variance is given by

 = (Q0 AQ0)-1Q0 AV AQ0(Q0 AQ0)-1

with V = E((Z)(Z) ) and (z) =

3 j=0

j

(z).

In

contrast,

the

asymptotic variance

of the oracle estimator ~ can be shown to be

~ = (Q0 AQ0)-1Q0 AV~ AQ0(Q0 AQ0)-1
with V~ = E((0(Z) + 1(Z))(0(Z) + 1(Z)) ), by simply setting r = r0. The presence of generated covariates thus affects the asymptotic variance only through the additional summands 2(Z) and 3(Z) used to calculate V , as the weight matrix A is chosen by the econometrician and Q0 is simply a population quantity. In particular, the term 2(Z) captures the additional uncertainty due to using generated covariates when estimating the function m0, whereas the term 3(Z) accounts for directly using the generated covariates
19

in other parts of the model, e.g. as a point of evaluation of an estimated function. A simple condition for the presence of generated covariates to be asymptotically negligible, i.e. that  = ~ , is then of course that 2(Z) = -3(Z) with probability one. This finding generalizes recent results in Hahn and Ridder (2011), who were the first to derive the influence function for a class of semiparametric estimators with generated covariates.

Remark 1 (Asymptotic Variance for a Special Case). Hahn and Ridder (2011) consider a

special case of our setup where T (X, , r) = (X1, r(Xr)) and the criterion function of the

form Qn(, m, r) = n-1

n i=1

q

(Zi

,

,

m,

r)

with

q(Z, , m, r)

=

s(m((X1, r(Xr))))

-



for

some known function s. In this setting, one can give intuitive conditions under which the

presence of generated covariates is asymptotically negligible. Suppose for example that

r0 is a nonparametric regression function satisfying D = r0(Xr) +  with E(|Xr) = 0. Applying Corollary 1 as in Example 1 above, we find that in this setting the asymptotic

variance of the estimator is given by4

 = E((1 + 2)(1 + 2) )

where, writing T = (X1, r0(Xr)),

1 = s(m0(T )) -  + s (m0(T )), 2 = -E(s (m0(T ))m0(T )T (r)(X)(Y - E(Y |T ))|Xr).

Here the term 2 = 2(Z) + 3(Z) accounts for the estimation error from using an estimate of r0 instead of the actual function, and is easily seen to be equal to zero if either s(·) is a linear function or E(Y |X) = E(Y |T ).

Remark 2 (Validity of the Bootstrap). In some applications, the asymptotic variance

matrix V could be difficult to estimate since it depends on the nonparametrically es-

timated components of the model in a potentially nontrivial fashion. In such cases,

resampling techniques like the ordinary nonparametric bootstrap can be useful to com-

pute confidence regions for the parameters of interest. Our results can be used to es-

tablish the validity of such an approach. Consider for example the setting in Chen,

Linton, and Van Keilegom (2003), where Qn(, ) = n-1

n i=1

q(Zi,

,

m(Zm,i

,

),

r(Zr,i

))

4The same formula is also derived by Hahn and Ridder (2011) in their Theorem 3.

20

and Q(, ) = E(q(Z, , m(Zm, ), r(Zr))). Let (Z1, . . . , Zn) be be drawn with replace-

ment from the original sample (Z1, . . . , Zn), let  be the same estimator as  but based

on the bootstrap data, and put Qn (, ) = n-1

n i=1

q(Zi,

,

m(Zm ,i,

),

r(Zr,i)).

Next,

define the bootstrap estimator  as any sequence that minimizes a GMM-type criterion

function based on a recentered moment condition:

Qn (^, ^) - Qn(^, ^)

= inf 

Qn (^, ^) - Qn(^, ^)

 + op(1/ n).

Chen, Linton, and Van Keilegom (2003) give sufficient condition under which the distribution of n( - ) converges in distribution to N (0, V ) under the probability measure
implied by the bootstrap. Following the discussion after their Theorem B, these condi-

tions can be verified by the same arguments we used to establish (N4) and (N6) above, and are thus immediate for a wide range of applications.

4.4. Relationship to Recent Literature. The results in our paper are closely related to recent findings in Hahn and Ridder (2011) and Escanciano, Jacho-Cha´vez, and Lewbel (2011). In this subsection, we discuss the differences in detail.

Remark 3 (Relationship to Hahn and Ridder (2011)). In an important related paper,

Hahn and Ridder (2011) study the form of the influence function of semiparametric lin-

ear, just-identified GMM-type estimators in the presence of generated covariates, using

pathwise derivatives as in Newey (1994). They do not consider a particular estimation

procedure, but assume that the estimator satisfies the asymptotically linear representa-

tion

n
^ = 0 + n-1 (Zi) + op(n-1/2)
i=1

(4.6)

with E((Z)) = 0 and E((Z)(Z) ) < . Under this assumption, they derive a

formula for the function  for their class of semiparametric models. However, they do

not study conditions that ensure the validity of the representation (4.6) in the first place,

which is by no means self evident. Their analysis does thus not imply that a particular

estimator is root-n consistent and asymptotically normal.

Our paper complements and extends the work of Hahn and Ridder (2011) in several

important ways. First, we consider a strictly larger class of estimators, allowing e.g. for

21

profiled optimization estimators with non-smooth criterion functions. Second, and more importantly, using our stochastic expansions we provide explicit conditions for root-n consistency and asymptotic normality for estimators contained in this larger class.5 We also derive a general formula for the asymptotic variance of our estimators, and show how to establish validity of the bootstrap, which is important for many empirical applications.
Remark 4 (Relationship to Escanciano, Jacho-Cha´vez, and Lewbel (2011)). In another closely related paper, Escanciano, Jacho-Cha´vez, and Lewbel (2011) derive stochastic expansions for sample means of weighted semiparametric regression residuals. Their results can be used to study the asymptotic properties of estimators in certain semiparametric "index models" with generated covariates, such as e.g. those with (in our notation) a criterion function of the form Qn(, m, r) = n-1 ni=1(Yi - m(T (Xi, , r), ))s(Xi), where s(X) is some weighting term.6 Such models are contained in the general class we consider in this paper. Escanciano, Jacho-Cha´vez, and Lewbel (2011) use stochastic equicontinuity arguments to control the impact of generated regressors on the final estimator, which rely on a certain functional Lipschitz condition (their Assumption 7) that seems difficult to verify in practice. In contrast, our results are derived using more direct bounds to control the impact of generated covariates, and can thus be applied without verifying such a condition.
A further important difference is that Escanciano, Jacho-Cha´vez, and Lewbel (2011) assume that E(Y |T ) = E(Y |X) in their models, i.e. that the index T is a sufficient statistic for the random vector X. As described above, this condition is often not satisfied in applications, such as e.g. the estimation of average treatment effects we study in Section 5.1. Our results do not require such an assumption. To illustrate the implications of this condition, consider the example mentioned above where Qn(, m, r) = n-1 ni=1(Yi - m(T (Xi, , r), ))s(Xi), and suppose again that the function r0 is a non-
5Due to the flexibility of our stochastic expansions, we conjecture that it should also be possible to extend our analysis to semiparametric estimators that are asymptotically normal but do not satisfy an asymptotic linearity condition, as studied e.g. by Cattaneo, Crump, and Jansson (2011).
6The results in Escanciano, Jacho-Cha´vez, and Lewbel (2011) are substantially more general, as they allow for estimated weights, the presence of vanishing trimming terms, and data-dependent choices of the bandwidth. These features make their results very useful even for model not involving generated covariates.
22

parametric regression function that satisfies D = r0(Xr) +  with E(|Xr) = 0. Applying Corollary 1 as in Example 1, we find that the asymptotic variance of the estimator in this setting is equal to
 = Q0-1E((1 + 2 + 3)(1 + 2 + 3) )Q0-1,
where, writing u(t) = E(s(X)|T = t),
1 = (s(X) - E(s(X)|T )) 2 = -E((s(X) - E(s(X)|T ))m0(T )T (r)(X)|Xr) 3 = E(u (T )T (r)(X)(E(Y |X) - E(Y |T ))|Xr).
The terms 2 and 3 account for the estimation error from using an estimate of r0 instead of the actual function. The expansion in Escanciano, Jacho-Cha´vez, and Lewbel (2011) can be used to obtain a similar result under their stronger conditions; see their Corollary 2.1. Since they impose that E(Y |X) = E(Y |T ) the term 3 is equal to zero in this case.
5. Econometric Applications
Semiparametric estimation problems with generated covariates occur in various fields of econometrics. In this subsection, we discuss two applications in greater detail: estimation of average treatment effects via regression on the propensity score, and estimation of production functions in the presence of serially correlated technology shocks. To save space, we only sketch the construction of estimators, and refer to Appendix B for details and regularity conditions.
5.1. Regression on the Propensity Score. Consider the potential outcomes framework, which is commonly used in the literature on program evaluation (Imbens, 2004): Let Y1 and Y0 be the potential outcomes with and without program participation, respectively, D  {0, 1} an indicator of program participation, Y = Y1D + Y0(1 - D) be the observed outcome, X a vector of exogenous covariates, and let (x) = Pr(D = 1|X = x) be the propensity score. A typical object of interest in this context is the average treatment effect (ATE), defined as
0 = E(Y1 - Y0).
23

Since selection into the program may be nonrandom, this object cannot be obtained by simply comparing the average outcomes of treated and untreated individuals. However, when selection depends on observable covariates X only, biases due to nonrandom selection into the program can be removed by conditioning on the propensity score (Rosenbaum and Rubin, 1983). That is, the condition that Y1, Y0D|X implies that Y1, Y0D|(X). Moreover, writing d() = E(Y |D = d, (X) = ), we have that d() = E(Yd|(X) = ), and thus by the law of iterated expectations, the ATE is identified through the relationship

0 = E(1((X)) - 0((X))).

(5.1)

Similar arguments can be made for other measures of program effectiveness (e.g. Heck-

man, Ichimura, and Todd, 1998). Estimating the ATE by a sample analogue of (5.1)

requires nonparametric estimation of the functions 1() and 0(). Since the propensity score is generally unknown and has to be estimated in a first stage, this fits into our framework with Z  (Y, X, (D, X)), r0(Xr)  (X), t(X, r0(Xr), )  (D, (X)), m0(z1)  d(p) and q(z, , m0, r0)  1((x)) - 0((x)) - .
A natural estimate of the ATE is thus the following sample version of (5.1):

^ = 1 n

n
(^1(^ (Xi)) - ^0(^ (Xi))),

i=1

where ^ (x) is the q-th order local polynomial estimator of (x), and ^d() is the local linear estimator of d(), computed using the first-stage estimates of the propensity score (alternatively, we could consider a parametric estimator for the propensity score, such

as e.g. Probit). Here the binary covariate D is accommodated via the usual frequency

method, i.e. the estimate ^d is computed by local linear regression of Yi on ^ (Xi) using

the nd =

n i=1

I{Di

=

d}

observations

with

D

=

d

only.

The following proposition

asymptotic gives the asymptotic properties of the estimator.7

7The form of the influence function was also obtained by Hahn and Ridder (2011), who use the approach in Newey (1994) to compute the influence function of the semiparametric estimator ^. In contrast to our paper, they do not give conditions for root-n consistency and asymptotic normality of the estimator.

24

Proposition 1. Suppose that the regularity conditions given in Appendix B.1 hold. Then we have that n(^ - 0) d N (0, E((Y, D, X)2), where

(Y,

D,

X)

=

µ1 (X )

-

µ0 (X )

+

D(Y - µ1(X)) (X )

-

(1

-

D)(Y - µ0(X)) 1 - (X)

-

0

is the influence function, and µd(x) = E(Y |D = d, X = x) for d = 0, 1.

Under the conditions of the proposition the asymptotic variance of ^ equals the cor-

responding semiparametric efficiency bound obtained by Hahn (1998). The estimator

obtained via regression on the estimated propensity score thus has the same first-order

limit properties as other popular efficient estimators of the ATE under unconfoundedness,

such as e.g. the propensity score reweighting estimator of Hirano, Imbens, and Ridder

(2003).

5.2. Estimation of Production Functions. When estimating the parameters of production functions, a simultaneity problem arises if there is contemporaneous correlation between a firm's inputs and shocks to productivity. In a highly influential paper, Olley and Pakes (1996) propose a methodology to address this issue, which can be seen as a control function approach. Here we consider a simplified version of their method, as described in Levinsohn and Petrin (2003). This setting assumes that firms do not age and cannot be closed. The Cobb-Douglas model for log output Yt of a firm in period t is given by

Yt = 0 + LLt + K Kt + t + t,

(5.2)

where Lt and Kt are labor and capital inputs, respectively, t is a productivity index that follows a first-order Markov process, and t is an i.i.d. productivity shock. Here t and t are both unobserved. The main difference is that t is a state variable, and hence impacts the firm's input choices, while t has no impact on firm behavior. In particular, the firms' investment It in the capital stock is a function of t and Kt: It = t(t, Kt). Under suitable conditions, firms that choose to invest have investment functions that are strictly increasing in the unobserved productivity index, and hence by invertability t can be written as function of capital and investment

t = (Kt, It).

25

Substituting this relationship into (5.2), we find that

Yt = LLt + t + t,

(5.3)

where t = (Kt, It) = KKt + (Kt, It). Equation (5.3) is a standard partially linear model, and thus L and the function (·) can be identified and estimated as in Robinson (1988) through the usual least squares arguments. To identify the coefficient K, it is assumed that capital does not immediately respond to innovations in the productivity index t, which together with the Markov assumption implies that

t = (t-1) + t with E(t|t-1, Kt) = 0.

We can thus rewrite the output net of labor's contribution Yt = Yt - LLt as

Yt = K Kt + (t-1 - K Kt-1) + t,

(5.4)

with (x) = (x) + 0 and t = t + t. Note that while equation (5.4) resembles a partially linear model (given knowledge of L and (·)), its structure is actually somewhat different, as the coefficient K appears both in the linear part and inside the unknown function . Still, the parameter K can be characterized as the solution to a profiled nonlinear least squares problem:

K = argmin E(Yt - LLt - bKt - (t-1 - bKt-1|b))2,
b

(5.5)

where (c|b) = E(Yt - LLt - bKt|t-1 - bKt-1 = c) for any b  R. Implementing

a sample analogue of (5.5) to estimate K requires nonparametric estimation of the function (·|b) using an estimates of the coefficient L and the function (·), both obtained

by estimating (5.3) in a first stage. This problem fits into our framework with Z 

(Yt, Lt, Kt, It, Kt-1, It-1), 0  K , r0(Xr)  (L, t-1), T (X, , r0)  t-1 - bKt-1, m0(·, )  (·|b) and q(Z, , m0, r0)  (Yt-LLt-bKt-(t-1-bKt-1|b))(Kt-b(t-1-

bKt-1|b)Kt-1).

To give an explicit expression for an estimator ^K of K, let ^L and ^(·) be estimates

of L and (·), respectively, obtained via the method in Robinson (1988). For every b  R,

let ^(·|b) be an estimate of ^(·|b), computed by local linear regression of Yit - ^LLit - bKit

on ^i,t-1 - bKi,t-1. Then we can define the final estimator as

^K

=

argmin
b

1 n

n
(Yit
i=1

-

^LLit

-

bKit

-

^(^i,t-1

- bKit-1|b))2.

(5.6)

26

Note that computing ^(·|b) and (·) involves the use of a generated dependent variable. However, compared to the problems arising from the presence of generated covariates, this issue is straightforward to address for linear smoothers like local linear regression. To simplify the expression for the influence function, we introduce the following notation: Let (b)(c|b) = a(a|b)|a=c + a(c|a)|a=b be the total derivative of (b|b) with respect to b, and  (c|b) = c(c|b) the ordinary derivative with respect to the first component. We also define Git = Kit - (b)(i,t-1 - KKi,t-1|K)Ki,t-1 and the "projection residuals" Gt = Gt - E(Gt|t-1 - K Kt-1) and Lt = Lt - E(Lt|t-1 - K Kt-1).
Proposition 2. Suppose that the regularity conditions given in Appendix B.2 hold. Then we have that n(^K - K) d N (0, ) with
 = Q0-1E (0 + 1 + 2)(0 + 1 + 2) Q0-1,
where
0 = Gt t 1 = -E(Gt |Kt-1, It-1) (t-1 - K Kt-1|K )t-1 2 = -E(Gt(Lt - E(Lt|Kt-1, It-1) (t-1 - K Kt-1|K )))
× E((Lt - E(Lt|Kt, It))2)-1(Lt - E(Lt|Kt, It))t.
Asymptotic properties of the above estimation procedure were first studied in Pakes and Olley (1995). Our expression for the influence function given in Proposition 2 differs from the their result, even when taking into account that we only consider a simplified version of their model. The reason is that our derivation does account for the estimation error from using an estimate of (·) when estimating ^(·|b), and not only for the estimation error resulting from using an estimate of (·) when evaluating ^(·|b). In our Proposition 2, both contributions are collected in the term 1.
A. Proofs of Main Results
A.1. Proof of Theorem 2. To simplify notation, we provide the proof only for the special
case dT = 1, i.e. T = T (X, , r) is a univariate random variable, but calculated rates are stated in general form. The proof for higher-dimensional T is conceptionally similar. The following
27

notation is used throughout all our proofs. The unit vector (1, 0, . . . , 0) in Rp+1 is denoted by e1. We write

wi(t, , r) = (1, (Ti(r, ) - t)/h, ..., (Ti(r, ) - t)p/hp) ,

Mh(t, , r)

=

1 n

n

wi(t, r, )wi(t, r, )

Kh(Ti(r, ) - t),

i=1

m0(t, ) = (m0(t, ), hm0(t, )/2, ..., hpm0p(t, )/p!) ,

and Nh(t, ) = E(Mh(t, )). Furthermore, we set wi(t, ) = wi(t, , r0) and w^i(t, ) = wi(t, , r^), and define Mh(t, ) and Mh(t, ) analogously. Using () = () - (X, ), we can write

Yi = m0(Ti(), ) + i() + (Xi, ) .

Note that E(()|X) = 0 for any   . With this representation of the dependent variable, we define the following decompositions of both the real and the oracle estimator:

m(t, ) = m0(t, ) + mA(t, ) + mB(t, ) + mC (t, ) + mD(t, ) + mE(t, )
m(t, ) = m0(t, ) + mA(t, ) + mB(t, ) + mC (t, ) + mD(t, ) + mE(t, ),
with respective components mj(t, ) = e1 j(, r) and mj(t, ) = e1 j(, r0) defined for j 
{A, B, C, D, E} as follows:
n
A(, r) = argmin (i () -  wi(t, , r))2Kh(Ti(, r) - t),
 i=1 n
B(, r) = argmin (m0(Ti(, r0), ) - m0(t, ) wi(t, , r0) -  wi(t, , r))2Kh(Ti(, r) - t),
 i=1 n
C (, r) = argmin (m0(t, ) wi(t, , r0) - m0(t, ) wi(t, , r) -  wi(t, , r))2Kh(Ti(, r) - t),
 i=1 n
D(, r) = argmin (m0(t, ) wi(t, , r) -  wi(t, , r))2Kh(Ti(, r) - t),
 i=1 n
E(, r) = argmin ((Xi, ) -  wi(t, , r))2Kh(Ti(, r) - t).
 i=1
Finally, we denote the component-wise differences between the real and the oracle estimator by

Rj,n(t, ) = mj(t, ) - mj(t, ) for j  {A, B, C, D, E}.

(A.1)

The statement of the theorem follows if for any    the remainder term Rn(t, ) = m(t, ) - m(t, ) satisfies
Rn(t, )(t) dt = OP (n-) .

28

Here m(t, ) = m~ (t, ) + An (t, , r) + Bn (t, , r). The term Bn (t, , r) is as defined in (3.2) , and for p = 1 the term An (t, , r) is also as defined in (3.2). More generally, for uneven p > 1 we set

nA(t, , r) = e1 Nh()-1E(Kh(Ti(r) - t)wi(t, , r)mpol(Ti(r), t, )(Ti(r, ) - Ti()), (A.2)

where mpol(u, t, ) is the derivative of mpol(u, t, ) with respect to its first argument and mpol(u, t, ) is the following polynomial approximation of m0(u, ) in a neighborhood of t:

mpol(u, t, ) = m0(t, ) (1, (u - t)/h, ..., (u - t)p/(p!hp)) .

To simplify the notation, we fix  = 0 for the rest of the proof and we omit  as an argument of functions. To prove Theorem 2, we will then show that

RA,n(t)(t) dt = OP (n-1 ), RB,n(t)(t) dt = OP (n-2 ), RC,n(t)(t) dt = An (t, r^)(t) dt + OP (n-3 + n-4 ), RE,n(t)(t) dt = Bn (t, r^)(t) dt + OP (n-1 + n-2 ).

(A.3) (A.4) (A.5) (A.6)

where the terms Rn,j are defined in (A.1) above. This directly implies the statement of the theorem since

(m(t) - m(t))(t) dt =

Rn,j(t)(t) dt,

j{A,...,E}

(A.7)

and RD,n(t)  0 by construction. We start with the proof of (A.3). Denote i(t, r) = e1 Mh(t, r)-1wi(t, r)Kh(Ti(r) - t) and
write i(r) = i(t, r)(t) dt. Furthermore let Lh(Ti(r) - t) = Kh(Ti(r) - t)wi(t, r) be a

vector-valued kernel type function. Then it holds that

1 RA,n(t) = n

n

(i(t, r0) - i(t, r))

i.

i=1

Using elementary arguments, one can show that

Mh(Ti(r1), r1) - Mh(Ti(r2), r2) = OP (nmax ) r1 - r2 .
uniformly for r1, r2  Rn and 1  i  n. With the help of this bound, we find that, uniformly for r1, r2  Rn and 1  i  n and some generic constant c > 0 which can take different values

29

at each appearance

|i(r1) - i(r2)|  e1 Mh(t, r1)-1Lh(Ti(r1) - t) - e1 Mh(t, r2)-1Lh(Ti(r2) - t) (t)dt

= e1 Mh(Ti(r1) - hu, r1)-1(Ti(r1) - hu)

- e1 Mh(Ti(r2) - hu, r2)-1(Ti(r2) - hu) L(u)du

 max cnj |Tj(r1) - Tj(r2)|.
1jdT

(A.8)

This last bound can be used to calculate a rough bound on the entropy Hn() of the class of functions i  i(r). Using Assumption 3, this class of functions can be covered by c exp((n-j )-n) balls of radius n-j . Thus we find that the entropy Hn()  c max1jdt -j njj+j for some constant c > 0. This implies

Cn
Hn1/2()d  cn-(1-max/2)min+(+)max/2
0

for Cn = n-min. We now apply Theorem 8.13 in van de Geer (2000) with Z¯ = n-1

n i=1

Zi,

,

Zi, = i(r) i ,  = r, R = Cn = n-min, and a is the entropy bound above. Conditional

on observations X1, ..., Xn, we obtain an exponential bound for Z¯ uniformly in Rn since

1 n

n i=1

E[exp(

|

i|)|Xi]  C

with

probability tending to one,

for

some

constants C,



>0

due to Assumption 1 (iv). With standard arguments this yields

sup
r1 ,r2 Rn

1 n

n
(i(r1)
i=1

-

i(r2))

 i

=

oP

n-(1/2)-(1-max/2)min+(+)max/2

.

(A.9)

Equation (A.9) provides the desired result (A.3) for RA.

For the proof of (A.4), note that for some nonnegative integers a, b and constants C1, C2 > 0 it holds that m0(Ti(r)) - m0(t) wi(t, r)  C1n-(p+1)min and

1 n

n

Kh(Ti(r1) - t)wia,k(t, r1)wib,l(t, r1) - Kh(Ti(r2) - t)wia,k(t, r2)wib,l(t, r2)

 C2n-(-)min

i=1

for components l, k and all t  IT and r, r1, r2  Rn. These two statements directly imply (A.4).

For the proof of (A.5), note that uniformly over 1  i  n and r  Rn it holds that

m0(t) wi(t, r0) - m0(t) wi(t, r) = mpol(Ti(), t)(Ti(r) - Ti(r0)) + OP (n-2min ).

Substituting this expression into RC,n, we find that

1 RC,n(t)(t)dt = n

n

i (r)(Ti(r) - Ti(r0)) + OP (n-2min ),

i=1

30

where

i(r) = e1 Mh(t, r)-1Lh(Ti(r) - t)mpol(Ti(r), t)(t)dt.

Furthermore, we have that

An (t,

r)(t)dt

=

1 n

n

i(r0)(Ti(r) - Ti(r0)) + op(n-1/2).

i=1

Thus, for (A.5) we have to show that

1 n

n
(i(r) - i(r0))(Ti(r) - Ti(r0)) = OP (n-3 + n-4 ).

i=1

(A.10)

Since |Ti(r) - Ti(r0)| = OP (n-min) uniformly over r  Rn and 1  i  n, one only has to prove that
|i(r) - i (r0)| = OP (n-4+min + n-min )

that uniformly for r  Rn and 1  i  n in order to establish (A.10). To see why the last claim holds, note that we can write:

i (r) - i(r0) = e1 [Mh(t, r)-1Lh(Ti(r) - t)mpol(Ti(r), t) - Mh(t, r0)-1Lh(Ti(r0) - t)mpol(Ti(r0), t)](t)dt
= e1 [Mh(Ti(r) - hu, r)-1(Ti(r) - hu)mpol(Ti(r), Ti(r) - hu) - Mh(Ti(r0) - hu, r0)-1(Ti(r0) - hu)mpol(Ti(r0), Ti(r0) - hu)]L(u)du.

First, it is easy to see that

max sup sup |(Ti(r) - t) - (Ti(r0) - t)| = OP (n-min)
1in rRn tIT

max
1in

sup
rRn

sup
tIT

|mpol(Ti(r),

Ti(r)

-

t)

-

mpol(Ti(r0),

Ti(r0)

-

t)|

=

OP

(n-min )

and

due to the smoothness of the functions involved. It thus remains to consider the elements of

the matrix Mh(Ti(r) - t, r) - Mh(Ti(r0) - t, r0). Any such element is of the form

1n n

(Ti(r) - t)uh-uKh(Ti(r) - t) - (Ti(r0) - t)uh-uKh(Ti(r0) - t)

i=1

for some 0  u+  p. We thus show that

1n n

(Ti(r) - t)uh-uKh(Ti(r) - t)

i=1

- (Ti(r0) - t)uh-uKh(Ti(r0) - t) = OP (n-min + n-4+min ).

(A.11)

31

uniformly over r  Rn . Because of Assumption 4(iii), we have that

E (Ti(r) - t)uh-uKh(Ti(r) - t) - E (Ti(r0) - t)uh-uKh(Ti(r0) - t) = OP (n-min ).

uniformly over r  Rn. Thus, for a proof of (A.11) it suffices to establish that

1n n

(Ti(r) - t)uh-uKh(Ti(r) - t) - E (Ti(r) - t)uh-uKh(Ti(r) - t)

i=1

- (Ti(r0) - t)uh-uKh(Ti(r0) - t) - E (Ti(r0) - t)uh-uKh(Ti(r0) - t) = OP (n-4+min ).

The last claim follows from the same type of arguments used in the treatment of RA,n. Taken together, the above derivation shows that
RC,n(t)(t) dt = An (t, r^)(t) dt + OP (n-4 + n-5 ),

as claimed

It remains to show (A.6). Note that

1 RE,n(t)(t) dt = n

n
[i(r^) - i(r0)](Xi).

i=1

Using the same reasoning as in the treatment of RA,n and Assumption 4(i)­(ii), we find that

1 n

n

i(r)((Xi) - E[(Xi)|Ti(r)]) - i(r0)((Xi) - E[(Xi)|Ti(r0)]) = OP (n-1 )

i=1

uniformly for r  Rn . Note that E[(Xi)|Ti(r0)] = 0. We now use that

1 n

n

i(r)E[(Xi)|Ti(r)]

=

1 n

n

i=1 i=1

e1 Mh(t, r)-1Lh(Ti(r) - t)E[(Xi)|Ti(r)](t)dt

= nB(t)(t)dt + OP (n-2 )

uniformly over r  Rn, and thus (A.6) holds. This concludes the proof of Theorem 2.

A.2. Proof of Theorem 3. First, standard results in e.g. Masry (1996), imply that the
oracle estimator m satisfies

sup |m(t, ) - m0(t, )| = op n-pmin + log(n)n-(1-+) .
tIT ,
uniformly over t  IT and    under the conditions of the theorem. Second, one can show that

sup |m(t, ) - m(t, )| = op(n-).
tIT ,

(A.12)

32

The statement (A.12) is an extension of Theorem 1 in Mammen, Rothe, and Schienle (2011), which gives a stochastic expansion of a local linear estimator regression estimator with generated covariates, and the special case that T (x, r, ) = r(xr). Generalizing this result to higher order local polynomials and more general forms of T is conceptionally straightforward, and thus a proof is omitted. With (A.12), the statement of the Theorem follows from a trivial bound on the leading terms of the expansion m.

Remark 5. One could use the additional structure implied by Assumption 5 to prove a somewhat better uniform rate of consistency under some minor additional regularity conditions. In particular, one can show that

sup |m(t, ) - m(t, )| = OP (n-min n-(1-+) log n + n-2min ),
tIT ,

(A.13)

which is better than the rate of OP (n-min) obtained from a crude bound that appears in

Theorem 3.

A.3. Proof of Corollary 1. To prove this result, we first establish a linear stochastic

expansion for the oracle estimator m. Using arguments in Masry (1996), Kong, Linton, and

Xia (2010) or Ichimura and Lee (2010), one can show that

1 m(t, ) =
n

n

m~ (t, ) + O(n-pmin ) + Op(log(n)n-(1-+)),

i=1

uniformly over t  IT and   , where

mn~i(t, ) = e1 Nh(t)-1w(Ti() - t)Kh(Ti() - t)i().

with w(t) = (1, t, ..., tp) and Nh(t, ) = E(w((Ti() - t)/h, )w((T () - t)/h, ) Kh(T () - t)). Next, note that the conditions of the corollary imply that that O(n-pmin) = o(n-1/2) and Op(log(n)n-(1-+)) = op(n-1/2) and O(n-2min ) = op(n-1/2). Applying Theorem 2, we therefore we find that Q0 can be decomposed as follows:

Q0[^ - 0] = A1 + A2 + A3 + A4 + op(n-1/2),

33

where

A1 = A2 =

1 m(zm) n

n

mn~i(zm, 0)fZm (zm)dzm,

i=1

m(zm)nA(zm, 0, r^)fZm (zm)dzm,

A3 = m(zm)nB(zm, 0, r^)fZm (zm)dzm

A4 = r(xr)nr^i(xr, 0, r^)fXr (xr)dxr,

We deal with each of these four terms separately. First, applying standard arguments from

kernel smoothing theory, we find that

1n A1 = n i
i=1

e1 Nh(zm)-1w(Ti() - zm)Kh(Ti() - zm)m(zm)fZm (zm)dzm

1n

= n

i

i=1

e1 Nh(Ti - th)-1w(t)K(t)m(Ti - th)fZm(Ti - th)dt

=

1 n

n i=1

i

m

(Ti

)

fZm (Ti) fT (Ti)

+

O(n-pmin )

1 =
n

n

1(Zi) + op(n-1/2)

i=1

For the second term, first note that it follows from standard bias calculations for kernel-type

estimators that

m(zm)nA(zm, 0, r)fZm (zm)dzm

= -E

Ti(r)

(X

)(r(Xri

)

-

r0

(Xri

))m(Ti)m0(Ti

)

fZm (Ti) fT (Ti)

+ Op(hp)

uniformly for fixed functions r  Rn . Substituting the expansion for r - r0 from Assumption 5 we then directly find that

A2

=

-1 n

n

(Wi)E

i=1

T

(r)(X

)m

(T

)m0

(T

)

fZm (T ) fT (T )

Hn(Si

,

Xr

)

Si

+ Op(n-pmin + n-2min ) + op(n-1/2)

1 =
n

n

2A(Zi) + op(n-1/2).

i=1

34

Concerning the term A3, we have that

A3 = =

m(zm) fT (zm)

Kh

(T

(x)

-

zm

)(T^(x)

-

T

(x))(x)fZm

(zm

)fX

(x)

dxdzm

1 h

K (t)G(T (x) + th) dt(T^(x) - T (x))(x)fX (x) dx

= G (T (x))(T^(x) - T (x))(x)fX (x) dx + O(hp)

=

G (T (x))T (r)(x)

1 n

n

Hn(Si, xr)(Wi)

(x)fX (x) dx + OP (hp + n-2min )

i=1

1 =
n

n

(Wi)E(G (T )T (r)(X)Hn(Si, Xr)(X)|Si) + OP (npmin + n-2min )

i=1

1 =
n

n

2B(Zi) + op(n-1/2)

i=1

with G(t) = m(t)fZm(t)fT (t)-1 and G (t) = tG(t) using integration by parts to obtain the

fourth equality. Finally, we have

A4 = (Wi)E(r(Xr)Hn(Si, Xr)|Si) + op(n-1/2)

1 =
n

n

3(Zi) + op(n-1/2)

i=1

using the same type of arguments as the ones applied above. The statement of the corollary

then follows since 2 = 2A + 2B.

A.4. Derivation of Example 1. Suppose that r0 is a q-times continuously differentiable

regression function estimated by qth order local polynomial regression using a bandwidth g and

a kernel function L. Assume that S is continuously distributed with compact support IS, and

that the corresponding density fS is q-times continuously differentiable, bounded, and bounded

away from zero on IS. Then it follows under some further standard regularity conditions (e.g.

Kong, Linton, and Xia, 2010) that

1 r^(s) - r0(s) = n

n

e1 NhS(s)-1w(Si - s)Lg(Si - s)i + Op(gq + log(n)/(ngds))

i=1

uniformly over s  IS, w(t) = (1, t, ..., tp) as above and NhS(t) = E(w((Si - s)/g, )w((Si -

s)/g, ) Lg(Si - s). The remainder term in the last equation can be made as small as op(n-1/2)

by choosing an appropriate bandwidth if q is sufficiently large. It follows that Assumption 5 is satisfied with (Wi) = i and Hn(Si, s) = e1 NhS(s)-1w(Si - s)Lg(Si - s). The condition that E( Hn(Si, Sj) 2) = o(n) holds if ngds  . To obtain the explicit expressions for 2

and 3, we insert the above relation into the expression from Corollary 1 and apply standard

U-Statistics arguments (e.g. Powell, Stock, and Stoker, 1989).

35

A.5. Derivation of Example 2. This derivation is trivial and thus omitted.

B. Details on Econometric Applications

B.1. Regression on the Propensity Score. In this section, we give details on the
construction of the estimator ^, and the regularity conditions under which Proposition 1 is valid. The data consist of a sample {(Yi, Di, Xi), i = 1, . . . , n} from the distribution of (Y, D, X). The estimator of the propensity score (x) = E(D|X = x) is given by (x) = , where

n

(^, ^) = argmin (Di -  -

u (Xi - x)u)2Lg(Xi - x)

, i=1

1u+q

and Lg(s) =

p j=1

L(sj /g)/g

is

a

dx-dimensional

product

kernel

built

from

the

univariate

kernel

L, g is a bandwidth, which for simplicity is assumed to be the same for all components, and

1u+q denotes the summation over all u = (u1, . . . , up) with 1  u+  q. Next, for d  {0, 1} the estimate of d() = E(Y |D = d, (X) = ) is given by the third-order local polynomial

estimator: we set d() = d, where

n

(d, d) = argmin I{Di = d}(Yi -  -

v ((Xi) - )v)2Kh((Xi) - ) ,

, i=1

1v3

with Kh(u) = K(u/h)/h, K a one-dimensional kernel function and h a bandwidth that tends

to zero as the sample size n tends to infinity. The final estimator of 0 is then given by

^ = 1 n

n
(^1(^ (Xi)) - ^0(^ (Xi))).

i=1

To prove Proposition 1, we make the following assumptions.

Assumption 6. The sample observations {(Yi, Di, Xi), i = 1, . . . , n} are i.i.d.

Assumption 7. (i) The random vector X is continuously distributed with compact support IX . Its density function fX is bounded and bounded away from zero on IX , and is also q + 1-times continuously differentiable for some uneven number q  dX . (ii) The function (x) is bounded away from zero and one on IX , and is also q + 1-times continuously differentiable. (iii) For any d  {0, 1}, the random variable (X) is continuously distributed conditional on D = d, with compact support I. Its conditional density function f|D(·, d) is bounded and bounded. away from zero on I, and is also four times continuously differentiable. (iv) For any d  {0, 1}, the function d() is four times continuously differentiable on I.

36

Assumption 8. The residual  = Y - E(Y |(X)) satisfies E[exp(l||)|X]  C almost surely for a constant C > 0 and l > 0 small enough.
Assumption 9. (i) The function K is twice continuously differentiable and satisfies the following conditions: K(u)du = 1, uK(u)du = 0, |u2K(u)|du < , and K(u) = 0 for values of u not contained in some compact interval, say [-1, 1]. (ii) The function L is k-times continuously differentiable for some natural number k  max{2, dx/2}, and satisfies the following conditions: L(u)du = 1, uL(u)du = 1, and L(u) = 0 for values of u not contained in some compact interval, say [-1, 1].
Assumption 10. The bandwidths satisfy h  n- and g  n- with  = 1/(2q + 1) and 1/8 <  < (q + 2)/(8q + 4).
Proof of Proposition 1. The proof uses the same arguments as that of Corollary 1 and Example 1, and thus the details are omitted. The only issue is to show that  > 1/2. To see this, note that the conditions of the Proposition imply that Assumption 2 holds with  = (q + 1)/(4q + 2) > 1/4, and that Assumption 3 holds with   q/(q + 1) and  = 0. The restrictions on  then ensure that  -  > (1/2)( + ) and (1 - )/2 -  > (1/2)( + ). We then easily see that  > 1/2.

B.2. Estimation of Production Functions. In this section, we give details on the
construction of the estimator ^, and the regularity conditions under which Proposition 2 is valid.

The data consist of a sample {(Yit, Lit, Kit, Iit, Kit-1, Iit-1), i = 1, . . . , n} from the distribution of (Yt, Lt, Kt, It, Kt-1, It-1). As a first step, we obtain an estimator ^L of L using the method in Robinson (1988). Under regularity conditions given in that paper,

n(^L

-

L)

=

E((Lt

-

E(Lt|Kt,

It))2)-1

1 n

n
(Lit - E(Lit|Kit, Iit))it + op(1).

i=1

Next, the estimator of (·) is given by ^(a, b) = ^, where

n

(^, ^) = argmin ((Yit - ^LLit) -  -

uT ((Kit, Iit) - (a, b))u)2Lg((Kit, Iit) - (a, b)),

, i=1

1u+q

and Lg(s) =

p j=1

L(sj /g)/g

is

a

dx-dimensional

product

kernel

built

from

the

univariate

kernel

L, g is a bandwidth, which for simplicity is assumed to be the same for all components, and

1u+q denotes the summation over all u = (u1, . . . , up) with 1  u+  q. To simplify the

37

exposition below, we also define an infeasible estimator of (·) that uses the true value of the

dependent variable. We set ^(a, b) = ^, where

n

(^, ^) = argmin ((Yit - LLit) -  -

rT ((Kit, Iit) - (a, b))u)2Lg((Kit, Iit) - (a, b)).

, i=1

1u+q

We also define ^t = ^(Kt, Lt). Next, for every b the estimator of (·|b) is given by the third-order

local polynomial estimator ^(c|b) = ^, where

n

(, ) = argmin ((Yit-^LLit-bKit)--

v (^it-1-bKit-1-c)v)2Kh(^it-1-bKit-1-c) ,

, i=1

1v3

with Kh(u) = K(u/h)/h, K a one-dimensional kernel function, and h a bandwidth that tends

to zero as the sample size n tends to infinity. Again, we also define an infeasible estimator that

uses the true value of the dependent variable. We set ^(c|b) = ^, where

n

(, ) = argmin ((Yit-LLit-bKit)--

v (^it-1-bKit-1-c)v)2Kh(^it-1-bKit-1-c) ,

, i=1

1v3

Our final estimator is then given as a solution to an empirical moment condition. Let

1 Mn(b) = n

n
(Yit - ^LLit - bKit - ^(it-1 - bKit-1|b))(Kit - b^(it-1 - bKit-1|b)Kit-1)

i=1

Then the final estimator ^K satisfies Mn(^K) = 0.

To prove Proposition 2, we make the following assumptions.

Assumption 11. The sample observations {(Yit, Lit, Kit, Iit, Kit-1, Iit-1), i = 1, . . . , n} are i.i.d.

Assumption 12. The regularity conditions imposed in Robinson (1988), which ensure that

n(^L

-

L)

=

E((Lt

-

E(Lt|Kt,

It))2)-1

1 n

n
(Lit - E(Lit|Kit, Iit))it + op(1)

i=1

(B.1)

hold.

Assumption 13. (i) The random vector St-1 = (Kt-1, It-1) is continuously distributed with compact support IS. Its density function fS is bounded and bounded away from zero on IS, and is also q + 1-times continuously differentiable for some uneven number q  3. (ii) The function (s) is q + 1-times continuously differentiable. (iii) Suppose that K  (B) for some known compact set B. For any b  B, the random variable Tt-1(b) = (St-1) - bKt-1 is continuously distributed with compact support IT . Its density function fT (·, b) is bounded and bounded away from zero on IT , uniformly over b  B. The density is also four times continuously differentiable. (iv) For any b  B, the function (·, b) is four times continuously differentiable on IT .

38

Assumption 14. For any b  B, the residual (b) = (Yt - LLt - bKt) - (Tt-1(b)|b) satisfies E[exp(l|(b)|)|St-1]  C almost surely for a constant C > 0 and l > 0 small enough.
Assumption 15. (i) The function K is two times continuously differentiable and satisfies the following conditions: K(u)du = 1, uK(u)du = 0, |u2K(u)|du < , and K(u) = 0 for values of u not contained in some compact interval, say [-1, 1]. (ii) The function L is k-times continuously differentiable for some natural number k  2, and satisfies the following conditions:
L(u)du = 1, uL(u)du = 1, and L(u) = 0 for values of u not contained in some compact interval, say [-1, 1].
Assumption 16. The bandwidths satisfy h  n- and g  n- with  = 1/(2q + 1) and 1/8 <  < (q + 2)/(8q + 4).
Proof of Proposition 2. Again, we can use the same arguments as that of Corollary 1 and Example 1 to show this result. To show that  > 1/2 under the conditions of the proposition, we proceed as in the proof of Proposition 1. To derive the influence function, it is useful to note that (4.2)­(4.3) hold with
m(c) = -E(Gt|Tt-1 = c) r(c1, c2) = -(E( (Tt-1)Gt|St-1 = c1), E(Gt|Lt = c2)) .
Moreover, the proof uses that
^t-1 = ^t-1 - E(Lt-1|Kt-1, It-1)(^L - 0) + op(n-1/2) ^(c|b) = ^(c|b) - (^L - L)E(Lt|t-1 - bKt-1 = c) + op(n-1/2).
This follows directly from the linearity of the local polynomial smoothing operator.
References
Ai, C., and X. Chen (2003): "Efficient estimation of models with conditional moment restrictions containing unknown functions," Econometrica, 71(6), 1795­1843.
(2007): "Estimation of possibly misspecified semiparametric conditional moment restriction models with different conditioning variables," Journal of Econometrics, 141(1), 5­43.
Andrews, D. (1994): "Asymptotics for semiparametric econometric models via stochastic equicontinuity," Econometrica, 62(1), 43­72.
39

(1995): "Nonparametric kernel estimation for semiparametric models," Econometric Theory, 11(03), 560­586.
Blundell, R., and J. Powell (2004): "Endogeneity in semiparametric binary response models," The Review of Economic Studies, 71(3), 655­679.
Cattaneo, M., R. Crump, and M. Jansson (2011): "Generalized Jackknife Estimators of Weighted Average Derivatives," CREATES Research Papers.
Chen, X., O. Linton, and I. Van Keilegom (2003): "Estimation of semiparametric models when the criterion function is not smooth," Econometrica, 71(5), 1591­1608.
Chen, X., and D. Pouzo (2009): "Efficient estimation of semiparametric conditional moment models with possibly nonsmooth residuals," Journal of Econometrics, 152(1), 46­60.
Chen, X., and X. Shen (1998): "Sieve extremum estimates for weakly dependent data," Econometrica, 66(2), 289­314.
Escanciano, J., D. Jacho-Cha´vez, and A. Lewbel (2010): "Identification and Estimation of Semiparametric Two Step Models," Unpublished manuscript.
(2011): "Uniform Convergence for Semiparametric Two Step Estimators and Tests," Unpublished manuscript.
Hahn, J. (1998): "On the role of the propensity score in efficient semiparametric estimation of average treatment effects," Econometrica, 66(2), 315­331.
Hahn, J., and G. Ridder (2011): "The Asymptotic Variance of Semiparametric Estimators with Generated Regressors," Unpublished manuscript.
Heckman, J., H. Ichimura, and P. Todd (1998): "Matching as an econometric evaluation estimator," Review of Economic Studies, 65(2), 261­294.
Hirano, K., G. Imbens, and G. Ridder (2003): "Efficient estimation of average treatment effects using the estimated propensity score," Econometrica, 71(4), 1161­1189.
Ichimura, H., and S. Lee (2010): "Characterization of the asymptotic distribution of semiparametric M-estimators," Journal of Econometrics, 159(2), 252­266.
40

Imbens, G. (2004): "Nonparametric estimation of average treatment effects under exogeneity: A review," Review of Economics and Statistics, 86(1), 4­29.
Kong, E., O. Linton, and Y. Xia (2010): "Uniform Bahadur representation for local polynomial estimates of M-regression and its application to the additive model," Econometric Theory, 26(05), 1529­1564.
Levinsohn, J., and A. Petrin (2003): "Estimating production functions using inputs to control for unobservables," Review of Economic Studies, 70(2), 317­341.
Li, Q., and J. Wooldridge (2002): "Semiparametric estimation of partially linear models for dependent data with generated regressors," Econometric Theory, 18(03), 625­645.
Linton, O., S. Sperlich, and I. Van Keilegom (2008): "Estimation of a semiparametric transformation model," Annals of Statistics, 36(2), 686­718.
Mammen, E., C. Rothe, and M. Schienle (2011): "Nonparametric Regression with Nonparametrically Generated Covariates," Unpublished manuscript.
Masry, E. (1996): "Multivariate local polynomial regression for time series: uniform strong consistency and rates," Journal of Time Series Analysis, 17(6), 571­599.
Murphy, K. M., and R. H. Topel (1985): "Estimation and Inference in Two-Step Econometric Models," Journal of Business and Economic Statistics, 3, 370­379.
Newey, W. (1984): "A method of moments interpretation of sequential estimators," Economics Letters, 14(2-3), 201­206.
Newey, W. (1994): "The Asymptotic Variance of Semiparametric Estimators," Econometrica, 62, 1349­1382.
Newey, W. (1997): "Convergence rates and asymptotic normality for series estimators," Journal of Econometrics, 79(1), 147­168.
Olley, G., and A. Pakes (1996): "The dynamics of productivity in the telecommunications equipment industry," Econometrica, 64(6), 1263­1297.
Oxley, L., and M. McAleer (1993): "Econometric issues in macroeconomic models with generated regressors," Journal of Economic Surveys, 7(1), 1­40.
41

Pagan, A. (1984): "Econometric issues in the analysis of regressions with generated regressors," International Economic Review, 25(1), 221­247.
Pakes, A., and S. Olley (1995): "A limit theorem for a smooth class of semiparametric estimators," Journal of Econometrics, 65(1), 295­332.
Powell, J., J. Stock, and T. Stoker (1989): "Semiparametric estimation of index coefficients," Econometrica, 57(6), 1403­1430.
Robinson, P. (1988): "Root-N-consistent semiparametric regression," Econometrica, 56(4), 931­954.
Rosenbaum, P., and D. Rubin (1983): "The central role of the propensity score in observational studies for causal effects," Biometrika, 70(1), 41­55.
Rothe, C. (2009): "Semiparametric estimation of binary response models with endogenous regressors," Journal of Econometrics, 153(1), 51­64.
Song, K. (2008): "Uniform convergence of series estimators over function spaces," Econometric Theory, 24(6), 1463­1499.
Sperlich, S. (2009): "A note on non-parametric estimation with predicted variables," Econometrics Journal, 12(2), 382­395.
van de Geer, S. (2009): Empirical Processes in M-Estimation. Cambridge University Press. Van der Vaart, A., and J. Wellner (1996): Weak convergence and empirical processes:
with applications to statistics. Springer Verlag.
42

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Localising temperature risk" by Wolfgang Karl Härdle, Brenda López Cabrera, Ostap Okhrin and Weining Wang, January 2011.
002 "A Confidence Corridor for Sparse Longitudinal Data Curves" by Shuzhuan Zheng, Lijian Yang and Wolfgang Karl Härdle, January 2011.
003 "Mean Volatility Regressions" by Lu Lin, Feng Li, Lixing Zhu and Wolfgang Karl Härdle, January 2011.
004 "A Confidence Corridor for Expectile Functions" by Esra Akdeniz Duran, Mengmeng Guo and Wolfgang Karl Härdle, January 2011.
005 "Local Quantile Regression" by Wolfgang Karl Härdle, Vladimir Spokoiny and Weining Wang, January 2011.
006 "Sticky Information and Determinacy" by Alexander Meyer-Gohde, January 2011.
007 "Mean-Variance Cointegration and the Expectations Hypothesis" by Till Strohsal and Enzo Weber, February 2011.
008 "Monetary Policy, Trend Inflation and Inflation Persistence" by Fang Yao, February 2011.
009 "Exclusion in the All-Pay Auction: An Experimental Investigation" by Dietmar Fehr and Julia Schmid, February 2011.
010 "Unwillingness to Pay for Privacy: A Field Experiment" by Alastair R. Beresford, Dorothea Kübler and Sören Preibusch, February 2011.
011 "Human Capital Formation on Skill-Specific Labor Markets" by Runli Xie, February 2011.
012 "A strategic mediator who is biased into the same direction as the expert can improve information transmission" by Lydia Mechtenberg and Johannes Münster, March 2011.
013 "Spatial Risk Premium on Weather Derivatives and Hedging Weather Exposure in Electricity" by Wolfgang Karl Härdle and Maria Osipenko, March 2011.
014 "Difference based Ridge and Liu type Estimators in Semiparametric Regression Models" by Esra Akdeniz Duran, Wolfgang Karl Härdle and Maria Osipenko, March 2011.
015 "Short-Term Herding of Institutional Traders: New Evidence from the German Stock Market" by Stephanie Kremer and Dieter Nautz, March 2011.
016 "Oracally Efficient Two-Step Estimation of Generalized Additive Model" by Rong Liu, Lijian Yang and Wolfgang Karl Härdle, March 2011.
017 "The Law of Attraction: Bilateral Search and Horizontal Heterogeneity" by Dirk Hofmann and Salmai Qari, March 2011.
018 "Can crop yield risk be globally diversified?" by Xiaoliang Liu, Wei Xu and Martin Odening, March 2011.
019 "What Drives the Relationship Between Inflation and Price Dispersion? Market Power vs. Price Rigidity" by Sascha Becker, March 2011.
020 "How Computational Statistics Became the Backbone of Modern Data Science" by James E. Gentle, Wolfgang Härdle and Yuichi Mori, May 2011.
021 "Customer Reactions in Out-of-Stock Situations ­ Do promotion-induced phantom positions alleviate the similarity substitution hypothesis?" by Jana Luisa Diels and Nicole Wiebach, May 2011.
SFB 649, Spandauer Str. 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
022 "Extreme value models in a conditional duration intensity framework" by Rodrigo Herrera and Bernhard Schipp, May 2011.
023 "Forecasting Corporate Distress in the Asian and Pacific Region" by Russ Moro, Wolfgang Härdle, Saeideh Aliakbari and Linda Hoffmann, May 2011.
024 "Identifying the Effect of Temporal Work Flexibility on Parental Time with Children" by Juliane Scheffel, May 2011.
025 "How do Unusual Working Schedules Affect Social Life?" by Juliane Scheffel, May 2011.
026 "Compensation of Unusual Working Schedules" by Juliane Scheffel, May 2011.
027 "Estimation of the characteristics of a Lévy process observed at arbitrary frequency" by Johanna Kappus and Markus Reiß, May 2011.
028 "Asymptotic equivalence and sufficiency for volatility estimation under microstructure noise" by Markus Reiß, May 2011.
029 "Pointwise adaptive estimation for quantile regression" by Markus Reiß, Yves Rozenholc and Charles A. Cuenod, May 2011.
030 "Developing web-based tools for the teaching of statistics: Our Wikis and the German Wikipedia" by Sigbert Klinke, May 2011.
031 "What Explains the German Labor Market Miracle in the Great Recession?" by Michael C. Burda and Jennifer Hunt, June 2011.
032 "The information content of central bank interest rate projections: Evidence from New Zealand" by Gunda-Alexandra Detmers and Dieter Nautz, June 2011.
033 "Asymptotics of Asynchronicity" by Markus Bibinger, June 2011. 034 "An estimator for the quadratic covariation of asynchronously observed
Itô processes with noise: Asymptotic distribution theory" by Markus Bibinger, June 2011. 035 "The economics of TARGET2 balances" by Ulrich Bindseil and Philipp Johann König, June 2011. 036 "An Indicator for National Systems of Innovation - Methodology and Application to 17 Industrialized Countries" by Heike Belitz, Marius Clemens, Christian von Hirschhausen, Jens Schmidt-Ehmcke, Axel Werwatz and Petra Zloczysti, June 2011. 037 "Neurobiology of value integration: When value impacts valuation" by Soyoung Q. Park, Thorsten Kahnt, Jörg Rieskamp and Hauke R. Heekeren, June 2011. 038 "The Neural Basis of Following Advice" by Guido Biele, Jörg Rieskamp, Lea K. Krugel and Hauke R. Heekeren, June 2011. 039 "The Persistence of "Bad" Precedents and the Need for Communication: A Coordination Experiment" by Dietmar Fehr, June 2011. 040 "News-driven Business Cycles in SVARs" by Patrick Bunk, July 2011. 041 "The Basel III framework for liquidity standards and monetary policy implementation" by Ulrich Bindseil and Jeroen Lamoot, July 2011. 042 "Pollution permits, Strategic Trading and Dynamic Technology Adoption" by Santiago Moreno-Bromberg and Luca Taschini, July 2011. 043 "CRRA Utility Maximization under Risk Constraints" by Santiago MorenoBromberg, Traian A. Pirvu and Anthony Réveillac, July 2011.
SFB 649, Spandauer Str. 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
044 "Predicting Bid-Ask Spreads Using Long Memory Autoregressive Conditional Poisson Models" by Axel Groß-Klußmann and Nikolaus Hautsch, July 2011.
045 "Bayesian Networks and Sex-related Homicides" by Stephan Stahlschmidt, Helmut Tausendteufel and Wolfgang K. Härdle, July 2011.
046 "The Regulation of Interdependent Markets", by Raffaele Fiocco and Carlo Scarpa, July 2011.
047 "Bargaining and Collusion in a Regulatory Model", by Raffaele Fiocco and Mario Gilli, July 2011.
048 "Large Vector Auto Regressions", by Song Song and Peter J. Bickel, August 2011.
049 "Monetary Policy, Determinacy, and the Natural Rate Hypothesis", by Alexander Meyer-Gohde, August 2011.
050 "The impact of context and promotion on consumer responses and preferences in out-of-stock situations", by Nicole Wiebach and Jana L. Diels, August 2011.
051 "A Network Model of Financial System Resilience", by Kartik Anand, Prasanna Gai, Sujit Kapadia, Simon Brennan and Matthew Willison, August 2011.
052 "Rollover risk, network structure and systemic financial crises", by Kartik Anand, Prasanna Gai and Matteo Marsili, August 2011.
053 "When to Cross the Spread: Curve Following with Singular Control" by Felix Naujokat and Ulrich Horst, August 2011.
054 "TVICA - Time Varying Independent Component Analysis and Its Application to Financial Data" by Ray-Bing Chen, Ying Chen and Wolfgang K. Härdle, August 2011.
055 "Pricing Chinese rain: a multi-site multi-period equilibrium pricing model for rainfall derivatives" by Wolfgang K. Härdle and Maria Osipenko, August 2011.
056 "Limit Order Flow, Market Impact and Optimal Order Sizes: Evidence from NASDAQ TotalView-ITCH Data" by Nikolaus Hautsch and Ruihong Huang, August 2011.
057 "Optimal Display of Iceberg Orders" by Gökhan Cebirolu and Ulrich Horst, August 2011.
058 "Optimal liquidation in dark pools" by Peter Kratz and Torsten Schöneborn, September 2011.
059 "The Merit of High-Frequency Data in Portfolio Allocation" by Nikolaus Hautsch, Lada M. Kyj and Peter Malec, September 2011.
060 "On the Continuation of the Great Moderation: New evidence from G7 Countries" by Wenjuan Chen, September 2011.
061 "Forward-backward systems for expected utility maximization" by Ulrich Horst, Ying Hu, Peter Imkeller, Anthony Réveillac and Jianing Zhang.
062 "On heterogeneous latent class models with applications to the analysis of rating scores" by Aurélie Bertrand and Christian M. Hafner, October 2011.
063 "Multivariate Volatility Modeling of Electricity Futures" by Luc Bauwens, Christian Hafner and Diane Pierret, October 2011.
SFB 649, Spandauer Str. 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
064 "Semiparametric Estimation with Generated Covariates" by Enno Mammen, Christoph Rothe and Melanie Schienle, October 2011.
SFB 649, Spandauer Str. 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

