BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2015-031
Simultaneous likelihood-based bootstrap confidence sets for a large
number of models
Mayya Zhilova*
* Humboldt-Universität zu Berlin, Germany This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Simultaneous likelihood-based bootstrap confidence sets for a large number of models
Mayya Zhilova, Weierstrass-Institute,
Mohrenstr. 39, 10117 Berlin, Germany, zhilova@wias-berlin.de
June 18, 2015
Abstract
The paper studies a problem of constructing simultaneous likelihood-based confidence sets. We consider a simultaneous multiplier bootstrap procedure for estimating the quantiles of the joint distribution of the likelihood ratio statistics, and for adjusting the confidence level for multiplicity. Theoretical results state the bootstrap validity in the following setting: the sample size n is fixed, the maximal parameter dimension pmax and the number of considered parametric models K are s.t. (log K)12p3max/n is small. We also consider the situation when the parametric models are misspecified. If the models' misspecification is significant, then the bootstrap critical values exceed the true ones and the simultaneous bootstrap confidence set becomes conservative. Numerical experiments for local constant and local quadratic regressions illustrate the theoretical results.
JEL classification codes: C13, C15 Keywords: simultaneous inference, correction for multiplicity, family-wise error, misspecified model, multiplier/weighted bootstrap
I am very grateful to Vladimir Spokoiny for many helpful discussions and comments. Financial support by the German Research Foundation (DFG) through the Collaborative Research Center 649 "Economic Risk" is gratefully acknowledged.
1

2 Simultaneous bootstrap confidence sets

Contents

1 Introduction

3

2 The multiplier bootstrap procedure

9

3 Theoretical justification of the bootstrap procedure

11

3.1 Overview of the theoretical approach . . . . . . . . . . . . . . . . . . . . . . . . . . 11

3.2 Main results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

4 Numerical experiments

16

4.1 Local constant regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

4.2 Local quadratic regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

4.3 Simulated data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

4.4 Effect of the modeling bias on a width of a bootstrap confidence band . . . . . . . 17

4.5 Effective coverage probability (local constant estimate) . . . . . . . . . . . . . . . . 18

4.6 Correction for multiplicity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

5 Conditions

22

5.1 Basic conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

5.2 Conditions required for the bootstrap validity . . . . . . . . . . . . . . . . . . . . . 23

5.3 Dependence of the involved terms on the sample size and cardinality of the param-

eters' set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

A Approximation of the joint distributions of 2 -norms

25

A.1 Joint Gaussian approximation of 2 -norm of sums of independent vectors by Lin-

deberg's method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27

A.2 Gaussian comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35

A.3 Simultaneous anti-concentration for 2 -norms of Gaussian vectors . . . . . . . . . 37

A.4 Proof of Proposition A.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

B Square-root Wilks approximations

42

B.1 Finite sample theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

B.2 Finite sample theory for the bootstrap world . . . . . . . . . . . . . . . . . . . . . 44

B.3 Simultaneous square-root Wilks approximations . . . . . . . . . . . . . . . . . . . . 46

C Proofs of the main results

47

C.1 Bernstein matrix inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47

C.2 Bootstrap validity for the case of one parametric model . . . . . . . . . . . . . . . 48

C.3 Proof of Theorem 3.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

C.4 Proof of Theorem 3.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51

C.5 Proof of Theorem 3.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55

References

56

1 Introduction

zhilova, m.

3

The problem of simultaneous confidence estimation appears in numerous practical applications when a confidence statement has to be made simultaneously for a collection of objects, e.g. in safety analysis in clinical trials, gene expression analysis, population biology, functional magnetic resonance imaging and many others. See e.g. Miller (1981); Westfall (1993); Manly (2006); Benjamini (2010); Dickhaus (2014), and references therein. This problem is also closely related to construction of simultaneous confidence bands in curve estimation, which goes back to Working and Hotelling (1929). For an extensive literature review about constructing the simultaneous confidence bands we refer to Hall and Horowitz (2013), Liu (2010), and Wasserman (2006).
A simultaneous confidence set requires a probability bound to be constructed jointly for several possibly dependent statistics. Therefore, the critical values of the corresponding statistics should be chosen in such a way that the joint probability distribution achieves a required family-wise confidence level. This choice can be made by multiplicity correction of the marginal confidence levels. The Bonferroni correction method (Bonferroni (1936)) uses a probability union bound, the corrected marginal significance levels are taken equal to the total level divided by the number of models. This procedure can be very conservative if the considered statistics are positively correlated and if their number is large. The Sida´k correction method (Sida´k (1967)) is more powerful than Bonferroni correction, however, it also becomes conservative in the case of large number of dependent statistics.
Most of the existing results about simultaneous bootstrap confidence sets and resamplingbased multiple testing are asymptotic (with sample size tending to infinity), see e.g. Beran (1988, 1990); Hall and Pittelkow (1990); H¨ardle and Marron (1991); Shao and Tu (1995); Hall and Horowitz (2013), and Westfall (1993); Dickhaus (2014). The results based on asymptotic distribution of maximum of an approximating Gaussian process (see Bickel and Rosenblatt (1973); Johnston (1982); H¨ardle (1989)) require a huge sample size n , since they yield a coverage probability error of order (log(n))-1 (see Hall (1991)). Some papers considered an alternative approach in context of confidence band estimation based on the approximation of the underlying empirical processes by its bootstrap counterpart. In particular, Hall (1993) showed that such an approach leads to a significant improvement of the error rate (see also Neumann and Polzehl (1998); Claeskens and Van Keilegom (2003)). Chernozhukov et al. (2014a) constructed honest confidence bands for nonparametric density estimators without requiring the existence of limit distribution of the supremum of the studentized empirical process: instead, they used an approximation between sup-norms of an empirical and Gaussian processes, and anti-concentration

4 Simultaneous bootstrap confidence sets
property of suprema of Gaussian processes. In many modern applications the sample size cannot be large, and/or can be smaller
than a parameter dimension, for example, in genomics, brain imaging, spatial epidemiology and microarray data analysis, see Leek and Storey (2008); Kim and van de Wiel (2008); Arlot et al. (2010); Cao and Kosorok (2011), and references therein.
For the recent results on resampling-based simultaneous confidence sets in highdimensional finite sample set-up we refer to the papers by Arlot et al. (2010) and Chernozhukov et al. (2013a, 2014a,b). Arlot et al. (2010) considered i.i.d. observations of a Gaussian vector with a dimension possibly much larger than the sample size, and with unknown covariance matrix. They examined multiple testing problems for the mean values of its coordinates and provided non-asymptotic control for the family-wise error rate using resampling-type procedures. Chernozhukov et al. (2013a) presented a number of non-asymptotic results on Gaussian approximation and multiplier bootstrap for maxima of sums of high-dimensional vectors (with a dimension possibly much larger than a sample size) in a very general set-up. As an application the authors considered the problem of multiple hypothesis testing in the framework of approximate means. They derived non-asymptotic results for the general stepdown procedure by Romano and Wolf (2005) with improved error rates and in high-dimensional setting. Chernozhukov et al. (2014a) showed how this technique applies to the problem of constructing an honest confidence set in nonparametric density estimation. Chernozhukov et al. (2014b) extended the results from maxima to the class of sparsely convex sets.
The present paper studies simultaneous likelihood-based bootstrap confidence sets in the following setting:
1. the sample size n is fixed;
2. the parametric models can be misspecified;
3. the number K of the parametric models can be exponentially large w.r.t. n ;
4. the maximal dimension pmax of the considered parametric models can be dependent on the sample size n .
This set-up, in contrast with the paper by Chernozhukov et al. (2014b), does not require the sparsity condition , in particular the dimension p1, . . . , pK of each parametric family may grow with the sample size. Moreover, the simultaneous likelihood-based confidence sets are not necessarily convex, and the parametric assumption can be violated.
The considered simultaneous multiplier bootstrap procedure involves two main steps: estimation of the quantile functions of the likelihood ratio statistics, and multiplicity correction of the marginal confidence level. Theoretical results of the paper state the

zhilova, m.

5

bootstrap validity in the setting 1-4 taking in account the multiplicity correction. The resulting approximation bound requires the quantity (log K)12p3max/n to be small. The log-factor here is suboptimal and can probably be improved. The paper particularly focuses on the impact of the model misspecification. We distinguish between slight and strong misspecifications. Under the so called small modeling bias condition (SmB) given in Section 5.2 the bootstrap approximation is accurate. This condition roughly means that all the parametric models are close to the true distribution. If the (SmB) condition is not fulfilled, then the simultaneous bootstrap confidence set is still applicable, however, it becomes conservative. This property is nicely confirmed by the numerical experiments in Section 4.
Let the random data

Y d=ef (Y1, . . . , Yn)

(1.1)

consist of independent observations Yi , and belong to the probability space (, F, IP ) . The sample size n is fixed. IP is an unknown probability distribution of the sample Y . Consider K regular parametric families of probability distributions:

{IPk()} d=ef {IPk() µ0,   k  IRpk } , k = 1, . . . , K.

Each parametric family induces the quasi log-likelihood function for   k  IRpk

Lk(Y , ) d=ef log

dIPk() (Y ) dµ0

=

n
log
i=1

dIPk() dµ0

(Yi)

.

(1.2)

It is important that we do not require that IP belongs to any of the known parametric families {IPk()} , that is why the term quasi log-likelihood is used here. Below in this section we consider two popular examples of simultaneous confidence sets in terms of the quasi log-likelihood functions (1.2). Namely, the simultaneous confidence band for local constant regression, and multiple quantiles regression.
The target of estimation for the misspecified log-likelihood Lk() is such a parameter k , that minimises the Kullback-Leibler distance between the unknown true measure IP and the parametric family {IPk()} :

k d=ef argmax IELk().
k
The maximum likelihood estimator is defined as:

(1.3)

k d=ef argmax Lk().
k

6 Simultaneous bootstrap confidence sets

The parametric sets k have dimensions pk , therefore, k, k  IRpk . For 1  k, j  K and k = j the numbers pk and pj can be unequal.
The likelihood-based confidence set for the target parameter k is

Ek(z) d=ef   k : Lk(k) - Lk()  z2/2  IRpk .

(1.4)

Let zk() denote the (1 - ) -quantile of the corresponding square-root likelihood ratio statistic:

zk() d=ef inf z  0 : IP Lk(k) - Lk(k) > z2/2   .

(1.5)

Together with (1.4) this implies for each k = 1, . . . , K :

IP k  Ek (zk())  1 - .

(1.6)

Thus Ek(z) and the quantile function zk() fully determine the marginal (1 - ) confidence set. The simultaneous confidence set requires a correction for multiplicity . Let c() denote a maximal number c  (0, ] s.t.

IP This is equivalent to

K k=1

2Lk(k) - 2Lk(k) > zk(c)

 .

(1.7)

c() d=ef sup c  (0, ] : IP max
1kK

2Lk(k) - 2Lk(k) - zk(c) > 0   . (1.8)

Therefore, taking the marginal confidence sets with the same confidence levels 1 - c() yields the simultaneous confidence bound of the total level 1- . The value c()  (0, ] is the correction for multiplicity. In order to construct the simultaneous confidence set using this correction, one has to estimate the values zk(c()) for all k = 1, . . . , K . By its definition this problem splits into two subproblems:

1. Marginal step. Estimation of the marginal quantile functions z1() , . . . , zK() given in (1.5).

2. Correction for multiplicity. Estimation of the correction for multiplicity c() given in (1.8).

If the 1 -st problem is solved for any   (0, 1) , the 2 -nd problem can be treated by
calibrating the value  s.t. (1.8) holds. It is important to take into account the correlation between the likelihood ratio statistics Lk(k) - Lk(k) , k = 1, . . . , K , otherwise the estimate of the correction c() can be too conservative. For instance, the Bonferroni

zhilova, m.

7

correction would lead to the marginal confidence level 1 - /K , which may be very conservative if K is large and the statistics Lk(k) - Lk(k) are highly correlated.
In Section 2 we suggest a multiplier bootstrap procedure, which performs the steps 1 and 2 described above. Theoretical justification of the procedure is given in Section 3. The proofs are based on several approximation bounds: non-asymptotic square-root Wilks theorem, simultaneous Gaussian approximation for 2 -norms, Gaussian comparison, and simultaneous Gaussian anti-concentration inequality.
Spokoiny and Zhilova (2014) considered the 1 -st subproblem for the case of a single parametric model ( K = 1 ): a multiplier bootstrap procedure was applied for construction of a likelihood-based confidence set, and justified theoretically for a fixed sample size and for possibly misspecified parametric model. In the present paper we extend that approach for the case of simultaneously many parametric models.
Below we illustrate the definitions (1.2)-(1.8) of the simultaneous likelihood-based confidence sets with two popular examples.
Example 1 (Simultaneous confidence band for local constant regression): Let Y1, . . . , Yn be independent random scalar observations and X1, . . . , Xn some deterministic design points. Consider the following quadratic likelihood function reweighted with the kernel functions K(·) :

L(, x, h) d=ef - 1 2

n
i=1(Yi

-

)2wi(x,

h),

wi(x, h) d=ef K({x - Xi}/h),

K(x)  [0, 1], K(x)dx = 1, K(x) = K(-x).
IR

Here h > 0 denotes bandwidth, the local smoothing parameter. The target point and

the local MLE read as:

(x, h) d=ef

n i=1

wi(x,

h)IE

n i=1

wi(x,

h)

Yi

,

(x, h) d=ef

n i=1

wi(x,

h)Yi

n i=1

wi

(x,

h)

.

(x, h) is also known as Nadaraya-Watson estimate. Fix a bandwidth h and consider
the range of points x1, . . . , xK . They yield K local constant models with the target parameters k d=ef (xk, h) and the likelihood functions Lk() d=ef L(, xk, h) for k = 1, . . . , K . The confidence intervals for each model are defined as

Ek(z, h) d=ef    : L((xk, h), xk, h) - L(, xk, h)  z2/2 ,

for the quintile functions zk() and for the multiplicity correction c() from (1.5) and (1.8) they form the following simultaneous confidence band:

IP

K k=1

k  Ek zk (c())

 1 - .

8 Simultaneous bootstrap confidence sets

In Section 4 we provide results of numerical experiments for this model. Example 2 (Multiple quantiles regression): Quantile regression is an important
method of statistical analysis, widely used in various applications. It aims at estimating conditional quantile functions of a response variable, see Koenker (2005). Multiple quantiles regression model considers simultaneously several quantile regression functions based on a range of quantile indices, see e.g. Liu and Wu (2011); Qu (2008); He (1997). Let Y1, . . . , Yn be independent random scalar observations and X1, . . . , Xn  IRd some deterministic design points, as in Example 1. Consider the following quantile regression models for k = 1, . . . , K :

Yi = gk(Xi) + k,i, i = 1, . . . , n,
where gk(x) : IRd  IR are unknown functions, the random values k,1, . . . , k,n are independent for each fixed k , and

IP (k,i < 0) = k for all i = 1, . . . , n.

The range of quantile indices 1, . . . , K  (0, 1) is known and fixed. We are interested in simultaneous parametric confidence sets for the functions g1(·), . . . , gK(·) . Let fk(x, ) : IRd × IRpk  IR be known regression functions. Using the quantile regression approach by Koenker and Bassett Jr (1978), this problem can be treated with the quasi maximum likelihood method and the following log-likelihood functions:
n
Lk() = - i=1 k (Yi - fk(Xi, )) , k (x) d=ef x (k - 1I {x < 0}) .

for k = 1, . . . , K . This quasi log-likelihood function corresponds to the Asymmetric

Laplace distribution with the density k(1 - k)e-k (x-a) . If  = 1/2 , then 1/2(x) =

|x|/2 and L() = -

n i=1

|Yi

-

fk(Xi, )| /2 ,

which

corresponds

to

the

median

regres-

sion.

The paper is organised as follows: Section 2 describes the multiplier bootstrap proce-

dure, Section 3 explains the ideas of the theoretical approach and provides main results

in Sections 3.1 and 3.2 correspondingly. All the necessary conditions are given in Section

5. In Section 5.3 and in statements of the main theoretical results we provide information

about dependence of the involved terms on the sample size and parametric dimensions

in the case of i.i.d. observations. Proofs of the main results are given in Section C.

Statements from Sections A and B are used for the proofs in Section C. Numerical ex-

periments are described in Section 4: we construct simultaneous confidence corridors

for local constant and local quadratic regressions using both bootstrap and Monte Carlo

zhilova, m.

9

procedures. The quality of the bootstrap procedure is checked by computing the effective

simultaneous coverage probabilities of the bootstrap confidence sets. We also compare

the widths of the confidence bands and the values of multiplicity correction obtained

with bootstrap and with Monte Carlo procedures. The experiments confirm that the

multiplier bootstrap and the bootstrap multiplicity correction become conservative if the

local parametric model is considerably misspecified. The results given here are valid on a random set of probability 1 - Ce-x for some

explicit constant C > 0 . The number x > 0 determines this dominating probability

level. For the case of the i.i.d. observations (see Secion 5.3) we take x = C log n .

Throughout the text · denotes the Euclidean norm for a vector and spectral norm for

a matrix. · max is the maximal absolute value of elements of a vector (or a matrix),

psum d=ef

p1 + · · · + pK ,

pmax

d=ef

max
1kK

pk

.

2 The multiplier bootstrap procedure

Let i,k() denote the log-density from the k -th parametric distribution family evaluated at the i -th observation:

i,k() d=ef log

dIPk() dµ0

(Yi)

,

(2.1)

then due to independence of Y1, . . . , Yn

Lk() =

n
i=1 i,k()  k = 1, . . . , K.

Consider i.i.d. scalar random variables ui independent of the data Y , s.t. IEui = 1 , Var ui = 1 , IE exp(ui) <  (e.g. ui  N (1, 1) or ui  exp(1) or ui  2Bernoulli(0.5) ). Multiply the summands of the likelihood function Lk() with the new random variables:

ab Lk ()

d=ef

n
i=1 i,k()ui,

(2.2)

then it holds IE ba Lkba () = Lk() , where IE ba stands for the conditional expectation given Y.

Therefore, the quasi MLE for the Y -world is a target parameter for the bootstrap

world for each k = 1, . . . , K :

ab ab argmaxk IE Lk () = argmaxk Lk() = k.

The corresponding bootstrap MLE is:

ab k

d=ef

argmaxk

ba Lk ().

10 Simultaneous bootstrap confidence sets

The k where all

-th the

likelihood elements:

ratio statistic the function

in the Lkba ()

bootstrap world equals ab
and the arguments k

to Lkab(kab) - Lkab(k) , , k are known and

available for computation. This means, that given the data Y , one can estimate the distribution or quantiles of the statistic Lkab(kab)-Lkab(k) by generating many independent

samples of the bootstrap weights u1, . . . , un and computing with them the bootstrap

likelihood ratio.

Let us introduce similarly to (1.5) the (1 - ) -quantile for the bootstrap square-root

likelihood ratio statistic:

ab zk ()

d=ef

inf

z  0 : IP ba

ab ba Lk (k )

-

ba Lk (k)

>

z2/2



,

(2.3)

here IP ab denotes probability measure conditional on the data Y , therefore, zkab() is a random value dependent on Y .

Spokoiny and Zhilova (2014) considered the case of a single parametric model ( K = 1 ), and showed that the bootstrap quantile zkba () is close to the true one zk() under
a so called "Small Modeling Bias" (SmB) condition, which is fulfilled when the true

distribution is close to the parametric family or when the observations are i.i.d. When the

SmB condition does not hold, the bootstrap quantile is still valid, however, it becomes conservative. Therefore, for each fixed k = 1, . . . , K the bootstrap quantiles zkba () are rather good estimates for the true unknown ones zk() , however, they are still
"pointwise" in k , i.e. the confidence bounds (1.6) hold for each k separately. Our

goal here is to estimate z1(), . . . , zK() and c() according to (1.7) and (1.8). Let us introduce the bootstrap correction for multiplicity:

c

ba ()

d=ef

sup

c  (0, ] : IP ba

K k=1

2Lkab(kba )

-

2Lkab(k

)

>

ba zk

(c)

By its definition c ba () depends on the random sample Y .

  . (2.4)

The multiplier bootstrap procedure below explains how to estimate the bootstrap quantile functions zkab (c ab()) corrected for multiplicity.

The simultaneous bootstrap procedure:

Input: The data Y (as in (1.1)) and a fixed confidence level (1 - )  (0, 1).

Step 1: Generate B independent samples of i.i.d. bootstrap weights {u(1b), . . . , un(b)} , b = 1, . . . , B . For the bootstrap likelihood processes

Lkba(b)() d=ef

n i=1

i,k ()u(i b) .

(2.5)

compute the bootstrap likelihood fixed b the bootstrap likelihoods

rLa1tba(ibo)s(L),kba.(b.).(,LkbaK(bab()b))(-)Lakabr(be)

(k) . For computed

each using

zhilova, m.

11

the same bootstrap sample {u(ib)} , s.t. the i -th summand i,k() is always multiplied with the i -th weight u(ib) as in (2.5).

Step 2:

Estimate for each

the k=

marginal 1, . . . , K ,

quantile using B

fubnocottisotnrsapzkrba e(al)isadteifionnesdofinL(k2ba (.3)kba )se-paLrkaab(telky)

from Step 1.

Step 3: Find by an iterative procedure the maximum value c  (0, ] s.t.

IP ab

K k=1

2Lkba (kab)

-

2Lkba (k

)



ba zk

(c)

 .

Otput: The resulting critical values are zkba (c) , k = 1, . . . , K .

Remark 2.1. The requirement in Step 1 to use the same bootstrap generation of the bootstrap likelihood ratios Lkab(b)(kba(b))-Lkab(b)(k) , k

sample = 1, . . .

{ui(b)} for , K allows

to preserve the correlation structure between the ratios and, therefore, to make a sharper

simultaneous adjustment in Step 3.

This procedure is justified theoretically in the next section.

3 Theoretical justification of the bootstrap procedure
Before stating the main results in Section 3.2 we introduce in Section 3.1 the basic ingredients of the proofs. The general scheme of the theoretical approach here is taken from Spokoiny and Zhilova (2014). In the present work we extend that approach for the case of simultaneously many parametric models.
3.1 Overview of the theoretical approach
For justification of the described multiplier bootstrap procedure for simultaneous inference it has to be checked that the joint distributions of the sets of likelihood ratio statistics Lk(k) - Lk(k) : k = 1, . . . , K and Lkba (kab) - Lkab(k) : k = 1, . . . , K are close to each other. These joint distributions are approximated using several non-asymptotic

12 Simultaneous bootstrap confidence sets

steps given in the following scheme:

Y -world:
Bootstrap world:

uniform
sq-Wilks theorem

joint Gauss. approx. & anti-concentr.

2Lk(k) - 2Lk(k)



pk +log K

n

k



2Lkab(kab) - 2Lkba (k)


pk +log K n

1kK ba
k



k



w

simultaneous Gauss. compar.

(3.1)

ba k ,

 the accuracy of these approximating steps is C

pm3 ax n

log9 (K )

log3(npsum)

1/8
;

 Gaussian comparison step yields an approximation error proportional to

s2mb

pm3 ax n

1/4 pmax log2(K) log3/4(npsum) , where s2mb comes from condition (SmB) ,

see also (3.4) below.

ab Here k and k denote normalized score vectors for the Y and bootstrap likelihood processes:

k d=ef Dk-1Lk(k),

ab k

d=ef

kba (k)

d=ef

Dk-1  Lk (k ),

(3.2)

Dk2 is the full Fisher information matrix for the corresponding k -th likelihood:

Dk2 d=ef -2IELk(k).

k



N (0, Var k)

and

ba k



N

(0,

Var

ba

ab k )

denote

approximating

Gaussian

vectors,

ab which have the same covariance matrices as  and  . Moreover the vectors 1 , . . . , K

ba ba

and  1 , . . . ,  K are normally distributed and have the same covariance matrices

ab ab

ba ab

as the vectors 1 , . . . , K and  1 , . . . ,  K correspondingly. Var and Cov

denote variance and covariance operators w.r.t. the probability measure IP ab conditional

on Y .

The first two approximating steps: square root Wilks and Gaussian approximations

are performed in parallel for both Y and bootstrap worlds, which is shown in the cor-

responding lines of the scheme (3.1). The two worlds are connected in the last step:

Gaussian comparison for 2 -norms of Gaussian vectors. All the approximations are performed simultaneously for K parametric models.

Let us consider each step in more details. Non-asymptotic square-root Wilks approx-

imation result had been obtained recently by Spokoiny (2012a, 2013). It says that for

zhilova, m.

13

a fixed sample size and misspecified parametric assumption: IP / {IPk} , it holds with exponentially high probablity:

2 Lk(k) - Lk(k) - k  k,W

pk , n

here the index k is fixed, i.e. this statement is for one parametric model. The precise

statement of this result is given in Section B.1, and its simultaneous version ­ in Sec-

tion B.3. The approximating value k is 2 -norm of the score vector k given in (3.2). The next approximating step is between the joint distributions of 1 , . . . , K and 1 , . . . , K . This is done in Section A.1 for general centered random vectors under bounded exponential moments assumptions. The main tools for the simultaneous

Gaussian approximation are: Lindeberg's telescopic sum, smooth maximum function and

three times differentiable approximation of the indicator function 1I{x  IR : x > 0} .

The simultaneous anti-concentration inequality for the 2 -norms of Gaussian vectors is obtained in Section A.3. The result is based on approximation of the 2 -norm with a maximum over a finite grid on a hypersphere, and on the anti-concentration inequality

for maxima of a Gaussian random vector by Chernozhukov et al. (2014c). The same

approximating steps are performed for the bootstrap world, the square-root bootstrap

Wilks approximation is given in Sections B.2, B.3. The last step in the scheme (3.1)

is comparison of the joint distributions of the sets of ab ba

2 -norms of Gaussian vectors:

1 , . . . , K and 1 , . . . , K by Slepian interpolation (see Section A.2 for the

result in a general setting). The error of approximation is proportional to

max
1k1,k2K

Cov(k1

,

k2

)

-

Cov

ab ba (k1

,

ba k2

)

max .

(3.3)

It is shown, using Bernstein matrix inequality (Sections C.1 and C.3), that the value (3.3) is bounded from above (up to a constant) on a random set of dominating probability with

max
1kK

Hk-1Bk2Hk-1

 s2mb

(3.4)

for

Bk2 d=ef Hk2 d=ef

n
i=1 IE {

i,k(k)} IE {

i,k (k )}

n
IE
i=1

 i,k(k) i,k(k)

.

,

(3.5)

The value Hk-1Bk2Hk-1 is responsible for the modelling bias of the k -th model. If the parametric family {IPk()} contains the true distribution IP or if the observations
Yi are i.i.d., then Bk2 equals to zero. Condition (SmB) assumes that all the values Hk-1Bk2Hk-1 are rather small.

14 Simultaneous bootstrap confidence sets

3.2 Main results

The following theorem shows the closeness of the joint cumulative distribution functions

(c.d.f-s.) of

2Lk(k) - 2Lk(k), k = 1, . . . , K and

2Lkab(kab) - 2Lkab(k), k =

1, . . . , K . The approximating error term total equals to a sum of the errors from

all the steps in the scheme (3.1).

Theorem 3.1. Under the conditions of Section 5 it holds with probability  1 - 12e-x

for

zk



 C pk,

1C

<2

IP

K k=1

2Lk(k) - 2Lk(k) > zk

- IP ab

K k=1

2Lkab(kba ) - 2Lkba (k) > zk

 total.

The approximating total error total  0 is deterministic and in the case of i.i.d. observations (see Section 5.3) it holds:

total  C

p3max n

1/8
log9/8(K) log3/8(npsum)

a2 + a2B

1 + V2(x) 3/8 ,

(3.6)

where the deterministic terms a2, a2B and V2(x) come from the conditions (I) , (IB) and (SD1) . total is defined in (C.5).

Remark 3.1. The obtained approximation bound is mainly of theoretical interest, although it shows the impact of pmax , K and n on the quality of the bootstrap procedure. For more details on the error term see Remark A.1.

The next theorem justifies the bootstrap procedure under the (SmB) condition. The theorem says that the bootstrap quantile functions zkab(·) with the bootstrap-corrected for multiplicity confidence levels 1 - c ab() can be used for construction of the simultaneous
confidence set in the Y -world.

Theorem 3.2 (Bootstrap validity for a small modeling bias). Assume the conditions of Theorem 3.1, and c(), 0.5c ab()  full, max , then for   1 - 8e-x it holds with
probability 1 - 12e-x

IP

K k=1

2Lk (k )

-

2Lk (k )



ba zk

(c

ab ()

-

2full,

max)

-   z, total,

IP

K k=1

2Lk (k )

-

2Lk (k )



ba zk

(c

ab()

+

2full,

max)

-   -z, total,

where full, max  C{(pmax + x)3/n}1/8 in the case of i.i.d. observations (see Section 5.3), and z, total  3total ; their explicit definitions are given in (C.11) and (C.14).

zhilova, m.

15

Moreover

c

ab ()



c (

+

c)

+

full, max,

c

ab ()



c (

-

c)

-

full, max,

for 0  c  2total , defined in (C.15).

The following theorem does not assume the (SmB) condition to be fulfilled. It turns
out that in this case the bootstrap procedure becomes conservative, and the bootstrap critical values corrected for the multiplicity zkab (c ba ()) are increased with the modelling bias tr{Dk-1Hk2Dk-1} - tr{Dk-1(Hk2 - Bk2)Dk-1} , therefore, the confidence set based
on the bootstrap estimates can be conservative.

Theorem 3.3 (Bootstrap conservativeness for a large modeling bias). Under the con-

ditions of Section 5 except for (SmB) it holds with probability  1 - 14e-x for zk 

 C pk,

1C

<2

IP

K k=1

2Lk(k) - 2Lk(k) > zk

 IP ab

K k=1

2Lkba (kab) - 2Lkab(k) > zk

+ b, total.

The deterministic value b, total  [0, total] (see (3.6) in the case 5.3). Moreover, the bootstrap-corrected for multiplicity confidence level 1 - c ab() is conservative in comparison with the true corrected confidence level:

1

-

c

ab ()



1

-

c (

+

b,c)

-

full, max,

and it holds for all k = 1, . . . , K and   1 - 8e-x

ba zk (c

ba ())



zk

(c (

+

b,c)

+

full, max)

+ tr{Dk-1Hk2Dk-1} - tr{Dk-1(Hk2 - Bk2)Dk-1} - qf,1,k,

for 0 above

 b,c  with (a2k

2total , defined in (C.18), and the positive

+

a2B,k

 )( 8xpk

+

6x)

for

the

constants

a2k

value qf,1,k > 0, a2B,k  0

is bounded from from conditions

(I) , (IB) .

The (SmB) condition is automatically fulfilled if all the parametric models are correct or in the case of i.i.d. observations. This condition is checked for generalised linear model and linear quantile regression in Spokoiny and Zhilova (2014) (the version of 2015).

16 Simultaneous bootstrap confidence sets

4 Numerical experiments
Here we check the performance of the bootstrap procedure by constructing simultaneous confidence sets based on the local constant and local quadratic estimates, the former one is also known as Nadaraya-Watson estimate Nadaraya (1964); Watson (1964). Let Y1, . . . , Yn be independent random scalar observations and X1, . . . , Xn some deterministic design points. In Sections 4.1-4.3 below we introduce the models and the data, Sections 4.4-4.6 present the results of the experiments.

4.1 Local constant regression

Consider the following quadratic likelihood function reweighted with the kernel functions K(·) :

L(, x, h) d=ef - 1 2

n
i=1(Yi

-

)2wi(x,

h),

wi(x, h) d=ef K({x - Xi}/h),

K(x)  [0, 1], K(x)dx = 1, K(x) = K(-x).
IR

Here h > 0 denotes bandwidth, the local smoothing parameter. The target point and

the local MLE read as:

(x, h) d=ef

n i=1

wi(x,

h)IE

n i=1

wi(x,

h)

Yi

,

(x, h) d=ef

n i=1

wi(x,

h)Yi

n i=1

wi

(x,

h)

.

Let us fix a bandwidth h and consider the range of points x1, . . . , xK . They yield K local constant models with the target parameters k d=ef (xk, h) and the likelihood functions Lk() d=ef L(, xk, h) for k = 1, . . . , K .
The bootstrap local likelihood function is defined similarly to the global one (2.2), by
reweighting L(, x, h) with the bootstrap multipliers u1, . . . , un :

ab Lk ()

d=ef

L

ab (,

xk ,

h)

d=ef

-1 2

ba k

d=ef



ab (xk,

h)

d=ef

n
i=1(Yi

-

)2 wi (xk ,

h)ui,

n i=1

wi(xk

,

n i=1

wi(xk

h)uiYi , h)ui

.

4.2 Local quadratic regression

Here the local likelihood function reads as

L(, x, h) d=ef - 1 2
, i  IR3,

n
i=1(Yi - i

)2wi(x, h),

i d=ef 1, Xi, Xi2 ,

zhilova, m.

17

and

(x, h) d=ef  W (x, h)

-1
 W (x, h)IEY ,

(x, h) d=ef  W (x, h)

-1
 W (x, h)Y ,

where

Y d=ef (Y1, . . . , Yn) ,  d=ef (1, . . . , n)  IR3×n, W (x, h) d=ef diag {w1(x, h), . . . , wn(x, h)} .

And similarly for the bootstrap objects

L

ab (, x, h)

d=ef

-1

2

n
i=1(Yi - i

)2wi(x, h)ui,



ba (x, h)

d=ef

 U W (x, h)

-1
 U W (x, h)Y ,

for U d=ef diag {u1, . . . , un} .

4.3 Simulated data

In the numerical experiments we constructed two 90% simultaneous confidence bands: using Monte Carlo (MC) samples and bootstrap procedure with Gaussian weights ( ui  N (1, 1) ), in each case we used 104 {Yi} and 104 {ui} independent samples. The sample size n = 400 . K(x) is Epanechnikov's kernel function. The independent random observations Yi are generated as follows:

Yi = f (Xi) + N (0, 1), Xi are equidistant on [0, 1],


5,   
f (x) = 5 + 3.8{1 - 100(x - 0.35)2},
  5 - 3.8{1 - 100(x - 0.55)2},

x  [0, 0.25]  [0.65, 1]; x  [0.25, 0.45]; x  [0.45, 0.65].

(4.1) (4.2)

The number of local models K = 71 , the points x1, . . . , x71 are equidistant on [0, 1] . For the bandwidth we considered two cases: h = 0.12 and h = 0.3 .

4.4 Effect of the modeling bias on a width of a bootstrap confidence band
The function f (x) defined in (4.2) should yield a considerable modeling bias for both mean constant and mean quadratic estimators. Figures 4.1, 4.2 demonstrate that the bootstrap confidence bands become conservative (i.e. wider than the MC confidence

18 Simultaneous bootstrap confidence sets

band) when the local model is misspecified. The top graphs on Figures 4.1, 4.2 show the 90% confidence bands, the middle graphs show their width, and the bottom graphs show the value of the modelling bias for K = 71 local models (see formulas (4.3) and (4.4) below). For the local constant estimate (Figure 4.1) the width of the bootstrap confidence sets is considerably increased by the modeling bias when x  [0.25, 0.65] . In this case case the expression for the modeling bias term for the k -th model (see also (SmB) condition) reads as:

Hk-1Bk2Hk-1 =

n i=1

{IEYi

-

 (xk )}2

wi2 (xk ,

h)

n i=1

IE

{Yi

-

 (xk )}2

wi2 (xk ,

h)

=1- 1+

n i=1

wi2(xk

,

h)

{f

(Xi)

-

(xk

)}2

n i=1

wi2(xk

,

h)

-1
.

(4.3)

And for the local quadratic estimate it holds:

Hk-1Bk2Hk-1 = Ip - Hk-1

n
i=1 ii

wi2(xk, h)

Hk-1

,

(4.4)

where Ip is the identity matrix of dimension p × p (here p = 3 ), and

Hk2 = =

n
i=1 ii

wi2(xk, h)IE {Yi - (xk)}2

n
i=1 ii

wi2(xk, h) {f (Xi) - (xk)}2 +

n
i=1 ii

wi2(xk, h).

(4.5)

Therefore, if max1kK {f (Xi) - (xk)}2 = 0 , then Hk-1Bk2Hk-1 = 0 . On the Figure 4.1 both the modelling bias and the difference between the widths of the bootstrap and

MC confidence bands are close to zero in the regions where the true function f (x) is

constant. On Figure 4.2 the modelling bias for h = 0.12 is overall smaller than the

corresponding value on Figure 4.1. For the bigger bandwidth h = 0.3 the modelling

biases on Figures 4.1 and 4.2 are comparable with each other.

Thus the numerical experiment is consistent with the theoretical results from Sec-

tion 3.2, and confirm that in the case when a (local) parametric model is close to the

true distribution the simultaneous bootstrap confidence set is valid. Otherwise the boot-

strap procedure is conservative: the modelling bias widens the simultaneous bootstrap

confidence set.

4.5 Effective coverage probability (local constant estimate)
In this part of the experiment we check the bootstrap validity by computing the effective coverage probability values. This requires to perform many independent experiments: for each of independent 5000 {Yi}  (4.1) samples we took 104 independent bootstrap samples {ui}  N (1, 1) , and constructed simultaneous bootstrap confidence sets for a range of confidence levels. The second row of Table 4.1 contains this range (1 - ) =

zhilova, m.

Figure 4.1: Local constant regression: Confidence bands, their widths, and the modeling bias

bandwidth = 0.12

bandwidth = 0.3

19

Legend for the top graphs:

90% bootstrap simultaneous confidence band

the true function f (x)

90% MC simultaneous confidence band

local constant MLE

smoothed target function

Legend for the middle and the bottom graphs:

width of the 90% bootstrap confidence bands from the upper graphs

width of the 90% MC confidence bands from the upper graphs

modeling bias from the expression (4.3)

20 Simultaneous bootstrap confidence sets

Figure 4.2: Local quadratic regression: Confidence bands, their widths, and the modeling bias

bandwidth = 0.12

bandwidth = 0.3

Legend for the top graphs:

90% bootstrap simultaneous confidence band

the true function f (x)

90% MC simultaneous confidence band

local constant MLE

smoothed target function

Legend for the middle and the bottom graphs:

width of the 90% bootstrap confidence bands from the upper graphs

width of the 90% MC confidence bands from the upper graphs

modeling bias from the expression (4.4)

zhilova, m.

21

0.95, 0.9, . . . , 0.5 . The third and the fourth rows of Table 4.1 show the frequencies of the

event

max
1kK

Lk

(k)

-

Lk

(k

)

-

ab zk (c

ab ())

0

among 5000 data samples, for the bandwidths h = 0.12, 0.3 , and for the range of (1-) .

The results show that the bootstrap procedure is rather conservative for both h = 0.12

and h = 0.3 , however, the larger bandwidth yields bigger coverage probabilities.

Table 1: Effective coverage probabilities for the local constant regression
Confidence levels h 0.95 0.90 0.85 0.80 0.75 0.70 0.65 0.60 0.55 0.50 0.12 0.971 0.947 0.917 0.888 0.863 0.830 0.800 0.769 0.738 0.702 0.3 0.982 0.963 0.942 0.918 0.895 0.868 0.842 0.815 0.784 0.750

4.6 Correction for multiplicity
Here we compare the Y and the bootstrap corrections for multiplicity, i.e. the values c() and c ba () defined in (1.8) and (2.4). The numerical results in Tables 2, 3 are based on 104 {Yi}  (4.1) independent samples and 104 independent bootstrap samples {ui}  N (1, 1) . The second line in Tables 2, 3 contains the range of the nominal confidence levels (1 - ) = 0.95, 0.9, . . . , 0.5 (similarly to the Table 1). The first column contains the values of the bandwidth h = 0.12, 0.3 , and the second column ­ the resampling scheme: Monte Carlo (MC) or bootstrap (B). The Monte Carlo experiment yields the corrected confidence levels 1 - c() , and the bootstrap yields 1 - c ba () . The lines 3­6 contain the average values of 1 - c() and 1 - c ab() over all the experiments. The results show that for the smaller bandwidth both the MC and bootstrap corrections are bigger than the ones for the larger bandwidth. In the case of a smaller bandwidth the local models have less intersections with each other, and hence, the corrections for multiplicity are closer to the Bonferroni's bound.
Remark 4.1. The theoretical results of this paper can be extended to the case when a set of considered local models has cardinality of the continuum, and the confidence bands are uniform w.r.t. the local parameter. This extension would require some uniform statements such as locally uniform square-root Wilks approximation (see e.g. Spokoiny and Zhilova (2013)).
Remark 4.2. The use of the bootstrap procedure in the problem of choosing an optimal bandwidth is considered in Spokoiny and Willrich (2015).

22 Simultaneous bootstrap confidence sets
Table 2: Local constant regression: MC vs Bootstrap confidence levels corrected for multiplicity
Confidence levels h r.m. 0.95 0.90 0.85 0.80 0.75 0.70 0.65 0.60 0.55 0.50
MC 0.997 0.994 0.989 0.985 0.980 0.975 0.969 0.963 0.956 0.949 0.12
B 0.998 0.995 0.991 0.988 0.984 0.979 0.975 0.969 0.963 0.957 MC 0.993 0.983 0.973 0.962 0.949 0.936 0.922 0.906 0.891 0.873 0.3 B 0.994 0.986 0.977 0.968 0.958 0.947 0.935 0.922 0.908 0.893

Table 3: Local quadratic regression: MC vs Bootstrap confidence levels corrected for multiplicity
Confidence levels h r.m. 0.95 0.90 0.85 0.80 0.75 0.70 0.65 0.60 0.55 0.50
MC 0.997 0.993 0.989 0.985 0.979 0.974 0.968 0.961 0.954 0.946 0.12
B 0.998 0.995 0.991 0.988 0.984 0.979 0.974 0.969 0.963 0.956 MC 0.993 0.983 0.973 0.961 0.949 0.936 0.921 0.904 0.887 0.868 0.3 B 0.996 0.991 0.985 0.978 0.971 0.963 0.954 0.944 0.934 0.923

5 Conditions
Here we show necessary conditions for the main results. The conditions in Section 5.1 come from the general finite sample theory by Spokoiny (2012a), they are required for the results of Sections B.1 and B.2. The conditions in Section 5.2 are necessary to prove the statements on multiplier bootstrap validity.

5.1 Basic conditions
Introduce the stochastic part of the k -th likelihood process: k() d=ef Lk() - IELk() , and its marginal summand: i,k() d=ef i,k() - IE i,k() for i,k() defined in (2.1).

(ED0) For each k = 1, . . . , K there exist a positive-definite pk × pk symmetric matrix Vk2 and constants gk > 0, k  1 such that Var {k(k)}  Vk2 and

sup

log IE exp

 

 k (k )

 IRpk

Vk 

 k22/2,

||  gk.

(ED2) For each k = 1, . . . , K there exist a constant k > 0 and for each r > 0 a

zhilova, m.

23

constant g2,k(r) such that it holds for all   0,k(r) and for j = 1, 2

sup log IE exp
j IRpk
j 1

 k

1

Dk-1 2 k ()Dk-1  2

 k22/2,

||  g2,k(r).

(L0) For each k = 1, . . . , K and for each r > 0 there exists a constant k(r)  0 such that for r  r0,k ( r0,k come from condition (B.1) of Theorem B.1 in Section B.1) (r)  1/2 , and for all   0,k(r) it holds

Dk-1D k2()Dk-1 - Ipk  k(r), where D k2() d=ef -2 IELk() and 0,k(r) d=ef {  k : Dk( - k)  r} . (I) There exist constants ak > 0 for all k = 1, . . . , K s.t.

ak2Dk2  Vk2. Denote a2 d=ef max1kK a2k .
(Lr) For each k = 1, . . . , K and r  r0,k there exists a value bk(r) > 0 s.t. rbk(r)   for r   and   k : Dk( - k) = r it holds
-2 {IELk() - IELk(k)}  r2bk(r).

5.2 Conditions required for the bootstrap validity

(SmB) There exists a constant smb  0 such that it holds for the matrices Bk2 and Hk2 defined in (3.5):

max
1kK

Hk-1Bk2Hk-1

 s2mb,

s2mb  C

n pm13ax

1/8
log-7/8(K) log-3/8(npsum).

(ED2m) For each k = 1, . . . , K , r > 0 , i = 1, . . . , n , j = 1, 2 and for all   0,k(r) it holds for the values k  0 and g2,k(r) from the condition (ED2) :

sup log IE exp
j IRpk
j 1

 k

1

Dk-12 i,k()Dk-12

 022 , 2n

||  g2,k(r),

(L0m) For each k = 1, . . . , K , r > 0 , i = 1, . . . , n and for all   0,k(r) there exists a value Cm,k(r)  0 such that

Dk-12IE i,k()Dk-1  Cm,k(r)n-1.

24 Simultaneous bootstrap confidence sets

(IB) For each k = 1, . . . , K there exists a constant aB2 ,k > 0 s.t.
a2B,kDk2  Bk2. Denote aB2 d=ef max1kK aB2 ,k . (SD1) There exists a constant 0  v2  Cpsum/n such that it holds for all i = 1, . . . , n with exponentially high probability

H-1 gigi - IE gigi H-1  v2 ,

where

gi d=ef  i,1(1) , . . . ,  i,K (K )

H2 d=ef

n

IE
i=1

gigi

psum d=ef p1 + · · · + pK .

,

 IRpsum ,

(Eb) The i.i.d. bootstrap weights ui are independent of Y , and for all i = 1, . . . , n it holds for some constants gk > 0, k  1

IEui = 1, Var ui = 1, log IE exp {(ui - 1)}  022/2,

||  g.

5.3 Dependence of the involved terms on the sample size and cardinality of the parameters' set

Here we consider the case of the i.i.d. observations Y1, . . . , Yn and x = C log n in order to specify the dependence of the non-asymptotic bounds on n and p . In the paper by

Spokoiny and Zhilova (2014) (the version of 2015) this is done in detail for the i.i.d. case,

generalized linear model and quantile regression. 
Example 5.1 in Spokoiny (2012a) demonstrates that in this situation gk = C n and 
k = C/ n . then Zk(x) = C pk + x for some constant C  1.85 , for the function Zk(x)

given in (B.3) in Section B.1. 

Similarly it can be checked that

g2,k (r)

from condition

(ED2) is proportional to n : due to independence of the observations

log IE exp

 k

1

Dk-1 2 k ()Dk-1  2

=

n
log IE exp
i=1

 n

1 k n

1

d-k 12i,k()d-k 12



2 nC
n

 for ||  g2,k(r) n,

zhilova, m.

25

where i,k() d=ef i,k() - IE i,k() , dk2 d=ef -2 IE i,k(k) and Dk2 = ndk2 in the i.i.d.

case. Function g2,k(r) denotes the marginal analog of g2,k(r) .

Let us show, that for the value k(r) from the condition (L0) it holds k(r) =

 Cr/ n .

Suppose

for

all





0,k (r)

and





IRpk

:



=1

Dk-1 3 IELk()Dk-1 

C , then it holds for some   0,k(r) :

Dk-1D2()Dk-1 - Ipk = Dk-1(k - ) 3IELk()Dk-1

= Dk-1(k - ) DkDk-13IELk()Dk-1

 r Dk-1

Dk-1

3 IELk()Dk-1

  Cr/ n.

 Similarly Cm,k(r)  Cr/ n + C in condition (L0m) .
The next remark helps to check the global identifiability condition (Lr) in many

situations. Suppose that the parameter domain k is compact and n is sufficiently 
large, then the value bk(r) from condition (Lr) can be taken as C{1 - r/ n}  C . Indeed, for  : Dk( - k) = r

-2 {IELk() - IELk(k)}  r2 1 - r Dk-1 Dk-1 3IELk()Dk-1



r2(1

-

 Cr/ n).

Due to the obtained orders, the conditions (B.1) and (B.9) of Theorems B.1 and B.5 on ba 
concentration of the MLEs k, k require r0,k  C pk + x .

A Approximation of the joint distributions of 2 -norms

Let us previously introduce some notations: 1K d=ef (1, . . . , 1)  IRK ;
· is the Euclidean norm for a vector and spectral norm for a matrix;
· max is the maximum of absolute values of elements of a vector or of a matrix; · 1 is the sum of absolute values of elements of a vector or of a matrix.
Consider K random centered vectors k  IRpk for k = 1, . . . , K . Each vector equals to a sum of n centered independent vectors:

k = k,1 + · · · + k,n, IEk = IEk,i = 0  1  i  n. Introduce similarly the vectors k  IRpk for k = 1, . . . , K :
k = k,1 + · · · + k,n, IEk = IEk,i = 0  1  i  n,

(A.1) (A.2)

26 Simultaneous bootstrap confidence sets

with the same independence properties as k,i , and also independent of all k,i . The goal of this section is to compare the joint distributions of the 2 -norms of the
sets of vectors k and k , k = 1, . . . , K (i.e. the probability laws L ( 1 , . . . , K ) and L ( 1 , . . . , K ) ), assuming that their correlation structures are close to each other.
Denote

let also

pmax d=ef max pk, psum d=ef p1 + · · · + pK ,
1kK

2,max

d=ef

max
1kK

Var(j) ,

2,max

d=ef

max
1kK

Var(j) ,

zmax

d=ef

max
1kK

zk ,

zmin

d=ef

min
1kK

zk ,

z,max

d=ef

max
1kK

zk

,

z,min

d=ef

min
1kK

zk ,

 d=ef

p3max n

1/8
log9/16(K) log3/8(npsum)zm1/i8n

× max {,max, ,max}3/4 log-1/8(5n1/2).

(A.3)

The following conditions are necessary for the Proposition A.1

(C1) For some gk, k, c, c > 0 and for all i = 1, . . . , n , k = 1, . . . , K

sup log IE exp
kIRpk , k =1

  nk k,i/c

sup log IE exp
kIRpk , k =1

  nk k,i/c

 2k2/2,  2k2/2,

|| < gk, || < gk,

where c  C,max and c  C,max .

(C2) For some 2  0

max
1k1, k2K

Cov(k1 , k2 ) - Cov(k1 , k2 ) max  2 .

(A.4)

Proposition A.1 (Approximation of the joint distributions of 2 -norms). Consider the

centered random vectors

1, . . . , K

and

1, . . . , K

given in (A.1), (A.2). 

Let the

conditions (C1) and (C2) be fulfilled, and the values zk  pk +  and zk  0 be s.t.

zhilova, m.

27

C max{n-1/2, z,max}    Czm-a1x , then it holds with dominating probability

KK

IP

{
k=1

k

> zk}

- IP

{
k=1

k

> zk - zk }

 - 2,

KK

IP

{
k=1

k

> zk}

- IP

{
k=1

k

> zk + zk }

2

for the deterministic non-negative value

 2  12.5C

pm3 ax n

1/8
log9/8(K) log3/8(npsum) max {,max, ,max}3/4

+ 3.2C2

p3max n

1/4
pmaxzm1/i2n log2(K) log3/4(npsum) max {,max, ,max}7/2

 25C

pm3 ax n

1/8
log9/8(K) log3/8(npsum) max {,max, ,max}3/4 ,

where the last inequality holds for

2  4C

n pm13ax

1/8
log-7/8(K) log-3/8(npsum) (max {,max, ,max})-11/4 .

Remark A.1. The approximating error term  2 consists of three errors, which correspond to: the Gaussian approximation result (Lemma A.2), Gaussian comparison

(Lemma A.7), and anti-concentration inequality (Lemma A.8). The bound on  2 above implies that the number K of the random vectors 1, . . . , K should satisfy log K (n/p3max)1/12 in order to keep the approximating error term  2 small. This condition can be relaxed by using a sharper Gaussian approximation result. For instance,

using in Lemma A.2 the Slepian-Stein technique plus induction argument from the recent

paper by Chernozhukov et al. (2014b) instead of the Lindeberg's approach, would lead

to the improved bound: C

pm3 ax n

1/6
multiplied by a logarithmic term.

A.1 Joint Gaussian approximation of 2 -norm of sums of independent vectors by Lindeberg's method
Introduce the following random vectors from IRpsum :

 d=ef =

1 , . . . , K
n
i=1 i,

, i d=ef 1,i, . . . , K,i IE = IEi = 0.

, i = 1, . . . , n,

(A.5)

28 Simultaneous bootstrap confidence sets

Define their Gaussian analogs as follows:

i d=ef 1,i, . . . , K,i i  N (0, Var i), k,i  N (0, Var k,i),

,

 d=ef 1 , . . . , K

=

n
i=1 i,

  N (0, Var ),

k d=ef

n
i=1 k,i  N (0, Var k).

(A.6) (A.7) (A.8)

Lemma A.2 (Joint GAR with equal covariance matrices). Consider the sets of ran-
dom vectors j and j , j = 1, . . . , K defined in (A.1), and (A.5)­ (A.8). If the conditions of Lemmas A.4 are A.5 are fulfilled, then it holds for all ,  > 0 , zj  max  + pj, 2.25 log(K)/ with dominating probability

IP

K
j=1 j > zj

 IP

K j=1

j

>

zj

-



-

3

log(K ) 2

+ 3,(, ),

K K 3 log(K)

IP j=1 j > zj  IP j=1 j > zj +  + 2

- 3,(, )

for 3,(, )  C

1 3

+

 2

+

2 

p3max n

log(K )

log3(npsum)

1/2

given in (A.15).

Proof of Lemma A.2.

IP

K
j=1 j > zj

= IE 1I max1jK j 2 - zj2 > 0 .

Let us approximate the max1jK function using the smooth maximum:

h ({xj}) d=ef -1 log

K exj
j=1

for  > 0, xj  IR,

h

({xj })

-

-1

log(K )



max {xj
1jK

}



h

({xj })

.

(A.9)

The indicator function 1I{x > 0} is approximated with the three times differentiable function g(x) growing monotonously from 0 to 1 :



0,







16x3/3,





g(x)

d=ef

 0.5

+

2(x

-

0.5)

-

16(x

-

0.5)3/3,

  1 + 16(x - 1)3/3,     1,

x  0, x  [0, 1/4], x  [1/4, 3/4], x  [3/4, 1], x  1.

It holds for all x  IR and  > 0

1I {x > }  g(x/)  1I {x/ > 0} .

zhilova, m.

29

Therefore

IP max
1jK

j - zj > 

 IE 1I max
1jK

j 2 - zj2 >  2zj

 IEg max
1jK

j 2 - zj2 2zj 

 IEg

1 log



K exp  j 2 - zj2 j=1 2zj

 IEg max
1jK

j 2 - zj2

log(K ) +

2zj 



 IE 1I max
1jK

j 2 - zj2 > - log(K) 2zj 

 IP max
1jK

j

- zj

> -1.5 log(K) 

,

where the last inequality holds for zj  2.25 log(K)/ . Denote

z d=ef (z1, . . . , zK )  IRK , zj > 0.

Introduce the function F, (, z) : IRpsum × IRK  IR :

F, (, z) d=ef g

1 log


K exp  j 2 - zj2 j=1 2zj

Then by (A.10) and (A.11)

(A.10) (A.11) (A.12)

IP max
1jK

j - zj >   IEF, (, z)  IP max
1jK

(A.13)

j

- zj

> - 3 log(K) 2

. (A.14)

Lemma A.6 checks that F,  (·, z) admits applying the Lindeberg's telescopic sum device (see Lindeberg (1922)) in order to approximate IEF,  (, z) with IEF,  , z . Define for q = 2, . . . , n - 1 the following IRpsum -valued random sums:

q-1 n

Sq d=ef

i +

i,

i=1 i=q+1

n

S1 d=ef

i,

i=2

n-1

Sn d=ef

i.

i=1

30 Simultaneous bootstrap confidence sets

The difference F,  (, z) - F,  , z can be represented as the telescopic sum:

F,  (, z) - F,  , z =

n
i=1 F, (Si + i, z) - F, (Si + i, z) .

The third order Taylor expansions of F, (Si + i, z) and F, (Si + i, z) w.r.t. the first argument at Si , and Lemma A.6 imply for each i = 1, . . . , n :

F, (Si + i, z) - F, (Si + i, z) - F, (Si, z) (i - i)

-

1 2

(i

-

i)

2F, (Si, z)(i + i)

 C3(, ) max 6 1jK

Sj,i + j,i 3

i

3 max

+

max
1jK

Sj,i + j,i 3

i

3 max

,

where the value C3(, ) is defined in Lemma A.6, and the random vectors Sj,i  IRpj for j = 1, . . . , K are s.t. for all i = 1, . . . , n

Si = S1,i, S2,i, . . . , SK,i .

By their construction Si and i - i are independent, IEi = IEi = 0 and Var i = Var i , therefore

IEF, (, z) - IEF, (, z)

n
= i=1 IEH(Si + i, z) - IEH(Si + i, z)

 C3(, ) n IE max 6 1jK
i=1

Sj,i + j,i 3

i

3 max

+

max
1jK

Sj,i + j,i 3

i

3 max

.

Lemma A.5 implies for all i = 1, . . . , n with probability  1 - 2e-x

1/2

IE max
1jK

Sj,i + j,i 6

 C0 max
1jK

Var1/2(j ) 3

pmax log(K)(pmax + 6x),

and the same bound holds for IE max1jK Sj,i + j,i 6 1/2 . Denote

max,

d=ef

1 2

n

IE

i=1

i

6 max

1/2 + IE

i

6 max

1/2 .

By Lemma A.4 it holds for t = (x + log(psum))3

 2c0

6 n-3 with probability  1-e-x

i

6 max



t,

i

6 max



t.

If x = C log n , then the last bound on IEF, (, z) - IEF, (, z) continues with

zhilova, m.

31

probability  1 - 6 exp(-x) as follows

IEF, (, z) - IEF, (, z)

 C C3(, ) 3

pm3 ax

log(K

)max,

max
1jK

Var1/2(j) 3

C 3

1  2 3 + 2 + 

p3m/a2x n1/2

log1/2(K) log3/2

(npsum

)

max
1jK

Var1/2(j ) 3 202c2 3/2

d=ef 3,(, ).

(A.15)

The derived bounds imply:

K
IP j=1 j > zj

by (A.13)  IEF,  (, z - 1K )

by (A.15)  IEF,  , z - 1K + 3,(, )

by (A.14)  IP

K j=1

j

>

zj

-



-

3

log(K ) 2

+ 3,(, ),

and similarly

K
IP j=1 j > zj

 IP

K 3 log(K) j=1 j > zj + 2 + 

- 3,(, ).

(A.16)

The next lemma is formulated separately, since it is used for a proof of another result.

Lemma A.3 (Smooth uniform GAR). Under the conditions of Lemma A.2 it holds with dominating probability for the function F,  (·, z) given in (A.12):

1.1. IP

K
j=1 j > zj  IEF,  , z - 1K + 3,(, ),

1.2. IP

K
j=1 j > zj

 IEH, 

3 log(K) , z + 2 1K

- 3,(, );

2.1. IEF,  (, z)  IP

K j=1

j

>

zj

-

3

log(K ) 2

,

2.2. IEF,  (, z)  IP

K
j=1 j > zj +  .

32 Simultaneous bootstrap confidence sets

Proof of Lemma A.3. The first inequality 1.1 is obtained in (A.16), the second inequality 1.2 follows similarly from (A.14) and (A.15). The inequalities 2.1 and 2.2 are given in (A.13) and (A.14).

Lemma A.4. Let for some c, g1, 0 > 0 and for all i = 1, . . . , n , j = 1, . . . , psum log IE exp n|ji |/c  202/2, || < g1,

here ji denotes the j -th coordinate of vector i . Then it holds for all i = 1, . . . , n and m, t > 0

IP

max
1jpsum

|ji |m

>

t

 exp

nt2/m - 2c2 02

+

log(psum)

.

Proof of Lemma A.4. Let us bound the maxj |ji | using the following bound for the maximum:

max
1jpsum

|ji |



log

psum
exp
j=1

|ji |

.

By the Lemma's condition



IE exp

max
1jp

n c

|ji

|

 exp 202/2 + log psum .

Thus, the statement follows from the exponential Chebyshev's inequality.

Lemma A.5. If for the centered random vectors j  IRpj j = 1, . . . , K

sup log IE exp
IRpj ,
 =0



 j Var1/2 (j )

 022/2,

||  g

for some constants 0 > 0 and g  0-1 max1jK 2pj log(K) , then

IE max
1jK

j



C0

max
1jK

Var1/2 (j )

2pmax log(K),

1/2

IE max
1jK

j 6

 C0 max
1jK

Var1/2(j) 3

2pmax log(K)(pmax + 6x),

The second bound holds with probability  1 - 2e-x .

Proof of Lemma A.5. Let us take for each j = 1, . . . , K finite j -grids Gj()  IRpj on the (pj - 1) -spheres of radius 1 s.t

  IRpj s.t.  = 1 0  Gj() :  - 0  , 0 = 1.

zhilova, m.

33

Then

j

 (1 - j)-1 max
Gj (j )

 j

.

Hence, by inequality (A.9) and the imposed condition it holds for all 0 < µ < g/ max1jK Var1/2(j) :

IE max
1jK

j

 max

1 IE max max

1jK 1 - j 1jK Gj (j )



j





C 1 IE

 log

exp

µ 1jK Gj (j )

µ

j

 



1



 C log

IE exp

µ 1jK Gj (j )

µ

j



 C max log(Kcard {Gj(j)}) + C µ02 max

1jK

µ

2 1jK

Var(j )



log(K ) C 1mjaxK{pj} µ

+

C µ02 2

max
1jK

Var(j )

=

C0

1mjaxK{pj

}

max
1jK

Var1/2 (j )

2 log(K)

for

µ

=

C0-1

max {pj}
1jK

2 log(K)/ max
1jK

Var1/2(j) .

For the second part of the statement we combine the first part with the result of Theorem
B.3 on deviation of a random quadratic form: it holds with dominating probability for V2j d=ef Var j

j 2  Zq2f(x, Vj )  tr(V2j ) + 6x V2j  V2j (pj + 6x).

Lemma A.6. Let   IRpsum , j  IRpj for j = 1, . . . , K are s.t.  = 1 , . . . , K , and z d=ef (z1, . . . , zK ) s.t. zj  pj , then it holds for the function F,  (·, z) defined in (A.12):

2 F,  (, z)

1

 C2(, ) max
1jK

3 F,  (, z)

1

 C3(, ) max
1jK

j 2 , j 3 ,

C2(, ) d=ef C

1 2 + 

,

C3(, ) d=ef C

1  2 3 + 2 + 

.

34 Simultaneous bootstrap confidence sets Proof of Lemma A.6. Denote

s( ) d=ef

K exp  j 2 - zj2 j=1 2zj

,

h(s( )) d=ef -1 log {s( )} ,

(A.17)

then F,(, z) = g -1h (s( )) . Let q denote the q -th coordinate of the vector   IRpsum . It holds for q, l, b, r = 1, . . . , psum :

d1

dq F,(, z)

=

g 

-1h(s( ))

d dq h(s( )),

d2 1 dqdl F,(, z) = 2 g

-1h(s( ))

dd dq h(s( )) dl h(s( ))

1 +g


-1h(s( ))

d2 dqdl h(s( )),

d3 1 dqdldb F,(, z) = 3 g

-1h(s( ))

ddd dq h(s( )) dl h(s( )) db h(s( ))

1 + 2 g

-1h(s( ))

d2 d dqdb h(s( )) dl h(s( ))

d d2

d d2

+ dq h(s( )) dldb h(s( )) + db h(s( )) dqdl h(s( ))

1 +g


-1h(s( ))

d3 dqdldb h(s( )).

Let for 1  q  psum j(q) denote an index from 1 to K s.t. the coordinate q of the vector  = 1 , . . . , K belongs to its sub-vector j(q) .

d

11 d

1 q

dq h(s( )) =  s( ) dq s( ) = s( ) zj(q) exp

 j(q) 2 - zj2(q) 2zj(q)

,

zhilova, m.

35

d2 dqdl h(s( ))

=

1 

1 s(

)

d2 d q d l

s(

)

-

11 d

d

 s2( ) dq s( ) dl s( )



     

1 +
zj(q)

q 2 zj(q)

1 exp  j(q) 2 - zj2(q)

s( )

2zj(q)





         

-

 s2(

)

q

2
exp

2 j(q) 2 - zj2(q)

,

zj(q)

2zj(q)

q = l;









  



ql

=

 s( 

)

zj2(q)

exp

 j(q) 2 - zj2(q) 2zj(q)



          

-

 s2(

)

ql zj2(q)

exp

2 j(q) 2 - zj2(q) 2zj(q)

,

j(q) = j(l), q = l;









  -  

 s2(

)

ql zj(q)zj(l)

exp

 j(q) 2 - zj2(q) +  j(l) 2 - zj2(l)

2zj(q)

2zj(l)

,

j(q) = j(l).

By definition (A.17) of s( ) it holds for all   IRpsum :

1 exp  j 2 - zj2  1, K 1 exp  j 2 - zj2 = 1.

s( )

2zj

s( )
j=1

2zj

Therefore,



psum d

d

K


1

q,l=1

dq h(s( )) dl h(s( ))

 exp j=1 s( )zj

 j 2 - zj2 2zj



max
1jK

j

pj zj

2

 max
1jK

j

2

for

zj



 pj .

pj 2 
q q=1 

Similarly

psum

d2 dqdl h(s( ))

 C max
1jK

j 2,

q,l=1

psum

d2 d

d3

dqdl h(s( )) db h(s( )) + dqdldb h(s( ))

C

 + 2

max
1jK

j

3.

q,l,b=1

A.2 Gaussian comparison
The following Lemma shows how to compare the expected values of a twice differentiable function evaluated at the independent centered Gaussian vectors. This statement is used

36 Simultaneous bootstrap confidence sets

for the Gaussian comparison step in the scheme (3.1). The proof of the result is based on the Gaussian interpolation method introduced by Stein (1981) and Slepian (1962) (see also R¨ollin (2013) and Chernozhukov et al. (2013b) and references therein). The proof is given here in order to keep the text self-contained.

Lemma A.7 (Gaussian comparison using Slepian interpolation). Let the IRpsum -dimensional random centered vectors  and  be independent and normally distributed, f (Z) : IRpsum  IR is any twice differentiable function s.t. the expected values in the expression below are bounded. Then it holds

IEf () - IEf ( )

1 2

Var  - Var  max sup
t[0,1]

IE2f

  t+ 1-t

.
1

Proof of Lemma A.7. Introduce for t  [0, 1] the Gaussian vector process Zt and the deterministic scalar-valued function (t) :

Zt

d=ef

  t+ 1-t



IRpsum ,

(t) d=ef IEf (Z(t)),

then IEf () = (1) , IEf ( ) = (0) and

1
IEf () - IEf ( ) = |(1) - (0)|   (t) dt.
0

Let us consider  (t) :

d  (t) = dt IEf (Zt) = IE

{f (Zt)}

d dt Zt

= 1 IE 2t

 f (Zt)

-  1 IE 2 1-t



f (Zt)

.

(A.18)

Further we use the Gaussian integration by parts formula (see e.g Section A.6 in Talagrand (2003)): if (x1, . . . , xpsum) is a centered Gaussian vector and f (x1, . . . , xpsum) is s.t. the integrals below exist, then it holds for all j = 1, . . . , psum :

psum
IE {xjf (x1, . . . , xpsum)} = IE(xjxk)IE
k=1

d dxk f (x1, . . . , xpsum ) .

(A.19)

Let

j, j

denote the

j -th coordinates of



and

.

Let also

d dj

f

(Zt

)

denote the

partial derivative of the vectors f (Zt) w.r.t. the j -th coordinate of Zt . Then it holds

zhilova, m.

37

due to (A.19):

IE  f (Zt)

psum
= IE
j=1



j

d dj

f

(Zt

)

psum
= IE  j q IE
j,q=1

 psum = t IE

jq

IE

j,q=1

d2 dqdj f (Zt) .

dd d q dj f (Zt)

Similarly for the second term in (A.18):

IE  f (Zt)

 psum = 1 - t IE

 j q

IE

j,q=1

d2 dqdj f (Zt) ,

therefore

1 psum psum  (t) = 2

IE

jq

- IE

 j q

j=1 q=1

d2 IE dqdj f (Zt)

1 2

Var  - Var 

max

sup
t[0,1]

IE2f (Zt) 1 .

A.3 Simultaneous anti-concentration for 2 -norms of Gaussian vectors
Lemma A.8 (Simultaneous Gaussian anti-concentration). Let 1 , . . . , K  IRpsum be centered normally distributed random vector, and j  IRpj , j = 1, . . . , K . It holds for all zj  pj and 0 < j  zj , j = 1, . . . , K :
KK
IP j=1 j > zj - IP j=1 j > zj + j  ac ({j}) ,
where

ac ({j})  C  1  log(K/2) + C max {j} max log(2zj/j) ,

1jK

1jK

and  d=ef max1jK {j/zj}  1 is a deterministic positive constant. An explicit definition of ac ({j}) is given in (A.22).

38 Simultaneous bootstrap confidence sets

Proof of Lemma A.8.

KK
IP j=1 j > zj - IP j=1 j > zj + j

 IP

K j=1

j zj-1 - 1 > 0

- IP

K j=1

j zj-1 - 1 > 

= IP max
1jK

j zj-1 - 1

>0

- IP

max
1jK

j zj-1 - 1 > 

 IP 0  max
1jK

j zj-1 - 1   .

It holds

(A.20)

j = sup  j .
IRpj ,  =1
Let Gj(j)  IRpj (for 1  j  K ) denote a finite j -net on (pj - 1) -sphere of radius 1:
  IRpj s.t.  = 1 0  Gj(j) :  - 0  j, 0 = 1.
This implies for all j = 1, . . . , K

(1 - j) j

 max
Gj (j )



j

 j .

Let us take 1, . . . , K > 0 s.t.  j = 1, . . . , K

j j zj-1  ,

then

0  max
1jK

j zj

- max max  j

1jK Gj (j )

zj

 ,

and the inequality (A.20) continues as

(A.21)

IP 0  max
1jK

j zj-1 - 1  

 IP

max sup
1jK Gj (j )

 j zj

-1  .

The random values  jzj-1  N (0, zj-2 Var{ j}) . The anti-concentration inequality by Chernozhukov et al. (2014c) for the maximum of a centered high-dimensional

zhilova, m.

39

Gaussian vector (see Theorem A.9 below), applied to max1jK supGj(j)  jzj-1 , implies

IP

max sup
1jK Gj (j )

 j zj

-1 

 ac d=ef Cac 1  log -1

K j=1

{2/j

}pj

,

(A.22)

where the constant Cac depends on min and max of Var{ jzj-1}  IE j 2zj-2 

1 ; the sum

K j=1

{2/j

}pj

is proportional to cardinality of the set

{

j zj-1, 



pmin +1
Gj(j), j = 1, . . . , K} . If one takes j = 2C {j/(2zj)} pj+1 , then (A.21) holds with

exponentially high probability due to Gaussianity of the vectors j and Theorem 1.2 in

Spokoiny (2012b), hence

ac  Cac

1  C log

1 2

K j=1

{2/j

}pj

+1

 Cac



1  log(K/2) + C 1mjaxK{j}

max
1jK

log(2zj

/j

)

.

(A.23)

Theorem A.9 (Anti-concentration inequality for maxima of a Gaussian random vector,
Chernozhukov et al. (2014c)). Let (X1, . . . , Xp) be a centered Gaussian random vector with j2 d=ef IEXj2 > 0 for all 1  j  p . Let  d=ef min1jp j ,  d=ef max1jp j . Then for every > 0

sup IP max Xj - x   Cac 1  log(p/ ),

xIR

1jp

where Cac depends only on  and  . When the variances are all equal, namely  =  =  , log(p/ ) on the right side can be replaced by log p .

A.4 Proof of Proposition A.1

Proof of Proposition A.1. Let  d=ef 1 , . . . , K  IRpsum for psum d=ef p1 + · · · + pK (as in (A.5)), and similarly  d=ef 1 , . . . , K  IRpsum . Let also   N (0, Var )
and   N (0, Var  ) . Introduce the following value, which comes from Lemma A.7 on

Gaussian comparison:

2(, ) d=ef C2(, ) max sup
1jK t[0,1]

IE

 j t + j 1 - t

2

 C2(, ) max max
1jK

tr Var(j), tr Var(j)

.

(A.24)

40 It holds

Simultaneous bootstrap confidence sets

K
IP j=1 j > zj

by L. A.3


IEH, 

3 log(K) , z + 2 1K

- 3,(, )

by L. A.7, A.6
 IEH, 

3 log(K)  , z + 2 1K

-

1 2

2

2(,

)

-

3,(,

)

by L. A.3
 IP

K 3 log(K) j=1 j > zj +  + 2

-

1 2

2

2

(,

)

-

3,(,

)

by L. A.8
 IP

K
j=1 j > zj - zj - 

-

1 2

2

2

(,

)

-

3,(,

)

3 log(K) - 2ac zj + 2 + 

(A.25)

by L. A.2
 IP

K
j=1 j > zj - zj

-

1 2

2

2(,

)

(A.26)

3 log(K)

- 3,(, ) - 3,(, ) - 2ac zj + 2 + 

,

where 3,(, ) is defined similarly to 3,(, ) in (A.15):

3,(, ) d=ef

C3(, ) 3

p3m/a2x n1/2

log1/2(K) log3/2

(npsum)

202c2 2,max

3/2 .

(A.27)

By Lemma A.8 inequality (A.25) requires the following:

zj

+ 2 +

3 log(K) 



zj .The

bound in the inverse direction is derived similarly. Denote the approximating error term

obtained in (A.26) as

 2 d=ef

1 2

2

2(,

)

+

3,(,



)

+

3,

(,



)

+

2ac

3 log(K)

zj + 2 + 

.

Consider this term in more details, by inequality (A.23)

ac

3 log(K) zj + 2 + 

 max
1jK

3 log(K) zj + 2 + 

×

log1/2 (K ) C
zj

+

log1/2

(2zmax)

-

log1/2

3 log(K) zj + 2 + 

.

zhilova, m.

41

Let

us

take



=

log(K ) 

,

then

ac



log1/2 (K ) 5C
zmin

+ C max
1jK

zj zj

log1/2 (K )

+ C (5 + z,max) log1/2 (2zmax) + - log (z,min + 5) ,



log1/2 (K ) 5C

+

C

max

zj log1/2(K)

zmin

1jK zj

+ 2C (5 + z,max) - log (z,min + 5)



log1/2 (K ) 5C zmin

+ C max
1jK

zj zj

log1/2(K) + 2C (5 + z,max)

- log (5)

 5C log1/2(K) + 2.4 log1/2 5n1/2 + C max zj log1/2(K)

zmin

1jK zj

 6C

log1/2(K) + 0.4 log1/2 5n1/2 zmin

,

(A.28)

where the second inequality holds for z,min + 5  1/(2zmax) , and the last one holds for z,max   and   n-1/2 .

3,(, )

+

3,(, )

by (A.27)


log5/2 (K ) C 3

pm3/a2x n1/2

log3/2(npsum)

3,max + 3 ,max

, (A.29)

2(, )

by (A.24)


C2

log(K 2

)

max
1jK

max

tr Var(j), tr Var(j)



C2

log(K 2

)

pmax

max

2,max, 2,max

.

After minimizing the sum of the expressions (A.28) and (A.29) w.r.t  , we have

 2  12.5C

p3max n

1/8
log9/8(K) log3/8(npsum) max {,max, ,max}3/4

+ 3.2C2 pmaxzm1/i2n

pm3 ax n

1/4
log2(K) log3/4(npsum) max {,max, ,max}7/2

 25C

p3max n

1/8
log9/8(K) log3/8(npsum) max {,max, ,max}3/4 ,

where the last inequality holds for

2  4Cpm-1axzm-i1n/2

p3max n

-1/8
log-7/8(K) log-3/8(npsum) (max {,max, ,max})-11/4 .

42 Simultaneous bootstrap confidence sets

B Square-root Wilks approximations
This section's goal is to derive square root Wilks approximations simultaneously for K parametric models, for the Y and bootstrap worlds. This is done in Section B.3 below. Both of the results are used in the approximating scheme (3.1) for the bootstrap justification. In order to make the text self-contained we recall in Section B.1 some results from the general finite sample theory by Spokoiny (2012a,b, 2013). In Section B.2 we recall similar finite sample results for the bootstrap world for a single parametric model, obtained in Spokoiny and Zhilova (2014).

B.1 Finite sample theory

Let us use the notations given in the introduction: Lk() , k = 1, . . . , K are the loglikelihood processes, which depend on the data Y and correspond to the regular parametric families of probability distributions {IPk(),   k  IRpk } . The general finite sample approach by Spokoiny (2012a) does not require that the true distribution IP of
the data Y belongs to any of the parametric families {IPk()} . The target parameters k are defined as in (1.3) by projection of the true measure IP on {IPk()} . Let Dk2 denote the full Fisher information pk × pk matrices, which are deterministic, symmetric and positive-definite:

Dk2 d=ef -2IELk(k).

Centered pk -dimensional random vectors k denote the normalised scores: k d=ef Dk-1Lk(k).
Introduce the following elliptic vicinities around the true points k : 0,k(r) d=ef {  k : Dk( - k)  r} .

Let 1  k  K be fixed. The non-asymptotic Wilks approximating bound by Spokoiny
(2012a, 2013) requires that the maximum likelihood estimate k gets into the local vicinity 0,k(r0,k) of some radius r0,k > 0 with probability  1 - 3e-x , x > 0 . This is guaranteed by the following concentration result:

Theorem B.1 (Concentration of the MLE, Spokoiny (2013)). Let the conditions (ED0) , (ED2) , (L0) , (I) and (Lr) be fulfilled. If for each k = 1, . . . , K for the constants r0,k > 0 and for the functions bk(r) from (Lr) holds:

bk(r)r  2 Zqf(x, IBk) + 6kk Zk(x + log(2r/r0,k)) , r > r0,k

(B.1)

zhilova, m.

43

where the functions Zk(x) and Zqf(x, IBk) are defined in (B.3) and (B.4) respectively, then it holds for all k = 1, . . . , K

IP k / 0,k(r0,k)  3e-x.

The constants k, k and ak come from the imposed conditions (ED0) ­ (I) (from 
Section 5). In the case 5.3 r0,k  C pk + x .

Theorem B.2 (Wilks approximation, Spokoiny (2013)). Under the conditions of The-
orem B.1 for some r0,k > 0 s.t. (B.1) is fulfilled, it holds for each k = 1, . . . , K with probability  1 - 5e-x

2 Lk(k) - Lk(k) - k 2  k,W2 (r0,k, x), 2 Lk(k) - Lk(k) - k  k,W(r0,k, x)

for

k,W(r, x) d=ef 3r {(r) + 6k Zk(x)k} ,

k,W2 (r, x)

d=ef

2 3

2r + Zqf(x, IBk)

k,W(r, x),

Zk (x)

d=ef

 2 pk

+

 2x

+

4pk

(xg-k 2

+

1)g-k 1.

(B.2) (B.3)

In the case 5.3 it holds for r  r0,k :

k,W

(r,

x)



C

pk+ n

x

,

k,W2 (r, x)  C

(pk + x)3 . n

The constants gk and k(r) come from the imposed conditions (ED0) , (L0) (from Section 5). The function Zqf(x, IBk) , defined in (B.4), corresponds to the quantile function of deviations of the approximating random value k (see Theorem B.3 below).

The following theorem characterizes the tail behaviour of the approximating terms k 2 . It means that with bounded exponential moments of the vectors k (conditions (ED0) , (I) ) its squared Euclidean norms k 2 have three regimes of deviations: sub-Gaussian, Poissonian and large-deviations' zone.

Theorem B.3 (Deviation bound for a random quadratic form, Spokoiny (2012b)). Let condition (ED0) be fulfilled, then for gk  2 tr(IBk2) it holds for each k = 1, . . . , K :
IP k 2  Zq2f(x, IBk)  2e-x + 8.4e-xc,k ,

44 Simultaneous bootstrap confidence sets

where IBk2 d=ef Dk-1Vk2Dk-1 , (IBk) is a maximum eigenvalue of IBk2 ,



  

tr(IBk2)

+

8 tr(IBk4)x,



Zq2f(x, IBk)

d=ef

 tr(IBk2) + 6x(IBk),

x  2 tr(IBk4)/{18(IBk)}, 2 tr(IBk4)/{18(IBk)} < x  xc,k,



 |zc,k

+

2(x

-

xc,k )/gc,k |2

(IBk),

x > xc,k,

(B.4)

2xc,k d=ef 2xc,k(IBk) d=ef µczc2,k + log det Ipk - µcIBk2/(IBk) , z2c,k d=ef gk2/µc2 - tr (IBk2)/µc /(IBk), gc,k d=ef g2k - µc tr (IBk2)/ (IBk),
µc d=ef 2/3.

(B.5)

The matrices Vk2 come from condition (ED0) and can be defined as Vk2 d=ef Var {Lk(k)} .

By condition 

(I )

tr(IBk2)  a2kpk ,

tr(IB4)  a4kpk

and

(IBk)  ak2 .

In the case 5.3

gk = C n , hence xc,k = Cn , and for x  xc,k it holds:

Zq2f(x, IBk)  a2k(pk + 6x).

(B.6)

B.2 Finite sample theory for the bootstrap world

Introduce for each k = 1, . . . , K the bootstrap score vectors at the point   k :

ba k ()

d=ef

Dk-1



ab k ()

n
= Dk-1 i,k()(ui - 1).
i=1

Theorem B.4 (Bootstrap Wilks approximation, Spokoiny and Zhilova (2014)). Under
the conditions of Theorems B.1 and B.5 for each k = 1, . . . , K and some r20,k  0 s.t. (B.1) and (B.9) are fulfilled, it holds for each k with IP -probability  1 - 5e-x

ba IP

sup 2

ba Lk ()

-

ba Lk (k

)

-

ab k (k)

2



ba k,W2 (r0,k,

x)

 1 - 4e-x,

k

IP ab

sup 2

Lkba () - Lkab(k)

-

ba k (k)



ab k,W (r0,k ,

x)

 1 - 4e-x.

k

zhilova, m.

45

where the error terms kab,W(r, x), kab,W2(r, x) are deterministic and

ba k,W(r,

x)

d=ef

2k,W(r,

x)

+

36k r1,k (r,

x) Zk(x),

ba k,W2 (r, x)

d=ef

1 18

ab 12rk,W

(r,

x)

+

ba k,W

(r,

x)2

.

k,W(r, x) and Zk(x) are defined in (B.2) and (B.3) respectively and

1,k(r, x) =

1,k

d=ef

Cm,k (r) n

 + 2kk 2x,

(B.7) (B.8)

where Cm,k(r), k, k come from the imposed conditions (L0m) , (ED2) and (ED0) . For the case 5.3 and r  r0,k it holds:

ba k,W(r,

x)



C

pk+ n

x

 x,

ab k,W2 (r,

x)



C

(pk

+

x)3

 x.

n

and 1,k(r)  Cr/n + C x/n .
Theorem B.5 (Concentration of the bootstrap MLE, Spokoiny and Zhilova (2014)). Let the conditions of Theorems B.1 and B.7, (L0m) and (ED2m) be fulfilled. If the following holds for each k = 1, . . . , K , 1,k(r, x) defined in (B.8) and the IP -random matrices Bk2 d=ef Dk-1 Var ba {Lkba (k)} Dk-1 :

bk(r)r  2 Zqf(x, IBk) + Zqf(x, Bk) + 6k Zk(x)1,k(r0,k)r0,k + 12k(k + 1,k(r, x)) Zk(x + log(2r/r0,k)) for r > r0,k,

(B.9)

then for each k it holds with IP -probability  1 - 3e-x

ab IP

ab k / 0,k(r0,k)

 3e-x.

Lemma B.6 below is implied straightforwardly by Lemma B.7 in Spokoiny and Zhilova (2014).
Lemma B.6. Let the conditions of (Eb) , (L0m) and (ED2m) be fulfilled, then for each k = 1, . . . , K it holds for r  r0,k with IP -probability  1 - e-x

where

ba IP

sup

ba k ()

-

kba (k

)



ba ,k (r,

x)

 1 - e-x,

0,k (r)

ab ,k (r,

x)

d=ef

6k

Zk(x)1,k(r, x)r

In the case 5.3 it holds for the bounding term

ba  (r0,

x)



C

pk+ n

x

 x.

46 Simultaneous bootstrap confidence sets

Theorem B.7 (Deviation bound for the bootstrap quadratic form, Spokoiny and Zhilova

(2014)). Let conditions (Eb) , (I) , (SD1) , (IB) be fulfilled, then for each k = 1, . . . , K and gk  2 tr(Bk2) it holds:

ba IP

kab(k) 2  Zq2f(x, Bk)  1 - 2e-x - 8.4e-xc,k(Bk),

where

Bk2 d=ef Dk-1V2(k)Dk-1, Vk2(k) d=ef Var ab Lkab(k),

Zqf(x, ·) and xc,k(·) are defined respectively in (B.4) and (B.5). Similarly to (B.6) it holds for x  xc,k(Bk) :
Zq2f(x, Bk)  akab2(pk + 6x) for akab2 d=ef (1 + V2 ,k(x))(ak2 + a2B,k)

and V2 ,k(x) defined in (C.1) (see Section C.1 on Bernstein matrix inequalities).

B.3 Simultaneous square-root Wilks approximations

The statements below follow from the results from Sections B.1 and B.2 by probability union bound.

Lemma B.8 (Simultaneous concentration bounds).

1. Let conditions of Theorem B.1 be fulfilled and (B.1) hold for each k = 1, . . . , K with x = x1 + log(K) for some x1 > 0 , then

IP

K
k=1 k / 0,k(r0,k)

 3e-x1 .

2. Let conditions of Theorem B.5 be fulfilled and (B.9) hold for each k = 1, . . . , K with

x = x1 + log(K) for some x1 > 0 , then it holds with IP -probability  1 - 3e-x1

ba IP

K ba k=1 k / 0,k(r0,k)

 3e-x1 .

Lemma B.9 (Simultaneous Wilks approximations).

1. Let the conditions of part 1 of Lemma B.8 be fulfilled for some r0,k > 0 and x = x1 + log(K) , then it holds

IP

K k=1

2 Lk(k) - Lk(k) - k 2  k,W2 (r0,k, x1 + log(K))

 1 - 5e-x1 ,

IP

K k=1

2 Lk(k) - Lk(k) - k  k,W(r0,k, x1 + log(K))  1 - 5e-x1 .

zhilova, m.

47

2. Let the conditions of parts 1,2 of Lemma B.8 be fulfilled for some r0,k > 0 and x = x1 + log(K) , then it holds with IP -probability  1 - 5e-x1

ab K IP
k=1
ba K IP
k=1

sup 2

ab Lk ()

-

ba Lk (k)

k

-

ba k (k)

2



ab k,W2 (r0,k,

x1

+

log(K ))

sup 2 Lkba () - Lkba (k)

-

ab k (k)



ab k,W (r0,k ,

x1

+

log(K ))

k

 1 - 4e-x1 ,  1 - 4e-x1 .

Lemma B.10. Let the conditions of Lemma B.6 be fulfilled, then it holds with IP probability  1 - e-x

 ab IP  



K

 

sup

k=1 0,k(r),

rr0,k

ab k ()

-

kab(k

)





ba ,k (r,

x

+

 
log(K))  



1

-

e-x.

 

C Proofs of the main results
Before proving the statements from Section 3.2 we formulate below the Bernstein matrix inequality, which is necessary for the further proofs.

C.1 Bernstein matrix inequality

Here we restate the Theorem 1.4 by Tropp (2012) for the random psum × psum ma-

trix V2 d=ef Var ab L1ab(1) , . . . , LKab (K )

from the bootstrap world. Matrix V2

equals to the sum of independent matrices

ab Var



i,1(1)

ui, . . . , 

i,K (K )

ui

.

Let us denote

gi d=ef  i,1(1) , . . . ,  i,K (K )

H2 d=ef

n

IE
i=1

gigi

,

vi d=ef H-1 gigi - IE gigi

H -1 ,

 IRpsum ,

then

H2 = IEV2,

n i=1

vi2

=

H -1 V 2 H -1

-

I psum .

Define also the deterministic scalar value

v2 d=ef

n i=1

IE

vi4

.

48 Simultaneous bootstrap confidence sets

Theorem C.1 (Bernstein inequality for V2 ). Let the condition (SD1) be fulfilled, then it holds with probability  1 - e-x :

H-1V2H-1 - Ipsum  V2(x),

where the error term is defined as

V2(x) d=ef

2v2

{log(psum)

+

x}

+

2 3

v2

{log(psum)

+

x}

(C.1)

and is proportional to {log(psum) + x}/n in the case 5.3.

We omit here the proof of Theorem C.1, since it follows straightforwardly from Theorem 1.4 by Tropp (2012), and is already given in Spokoiny and Zhilova (2014).

C.2 Bootstrap validity for the case of one parametric model

Here we state the results on bootstrap validity from Spokoiny and Zhilova (2014), they will be used for some of the further proofs.

Theorem C.2. Let the conditions of Section 5 be fulfilled, then it holds for each k =

1, . . . , K ,

zk



max{2,

pk}

+

C(pk

+

 x)/ n

with probability

 1 - 12e-x :

IP

Lk(k) - Lk(k) > zk2/2

- IP ba

ab ab Lk (k )

-

ba Lk (k)

>

zk2/2

 full, k .

The error term full,k  C{(pk + x)3/n}1/8 in the case of i.i.d. model; see Section 5.3.
Theorem C.3 (Validity of the bootstrap under a small modeling bias). Assume the conditions of Theorem C.2. Then for   1 - 8e-x , it holds
IP Lk(k) - Lk(k) > (zkba ())2 /2 -   z, full, k .

The error term z, full, k  C{(pk + x)3/n}1/8 in the case of i.i.d. model; see Section 5.3.

Theorem C.4 (Performance of the bootstrap for a large modeling bias). Under the

conditions

of

Section

5

except

for

(SmB)

it

holds

for

zk



max{2,

 pk

}

+

C(pk

+

 x)/ n

with probability  1 - 14e-x

1.

IP

Lk(k) - Lk(k) > zk2/2

 IP ab

ba ab Lk (k )

-

L

ba (k)

>

zk2/2

+ b, full, k.

2.

ab zk ()



zk(

+

b, full,

k)

+ tr{Dk-1Hk2Dk-1} - tr{Dk-1(Hk2 - Bk2)Dk-1} - qf,1,k,

ba zk ()



zk(

-

b, full,

k)

+ tr{Dk-1Hk2Dk-1} - tr{Dk-1(Hk2 - Bk2)Dk-1} + qf,2,k.

zhilova, m.

49

The term b, full, k  C{(pk + x)3/n}1/8 in the case of i.i.d. model; see Section 5.3. The

positive values

qf,1,k, qf,2,k

are bounded from above with

(ak2

+

a2B,k

 )( 8xpk

+

6x)

for

the constants ak2 > 0, a2B,k  0 from conditions (I) , (IB) .

C.3 Proof of Theorem 3.1

Lemma C.5 (Closeness of L (

1

,...,

K

)

and L ab (

ba 1

,...,

ab K

) ). If the condi-

tions (ED0) , (I) , (SmB) , (IB) , (SD1) and (Eb) are fulfilled, then it holds with

probability

 1 - 6e-x

for all

zk  0

and

zk



 pk

+



s.t.

C

max {n-1/2,
1kK

zk }



  C 1mkinK{1/zk} (  is given in (A.3)):

IP

K

{
k=1

k

> zk}

- IP ab

K
{
k=1

ab k

> zk - zk }

 - 2,

IP

K

{
k=1

k

> zk}

- IP ab

K
{
k=1

ba k

> zk + zk }

  2.

for the deterministic nonnegative value

 2  25C

pm3 ax n

1/8
log9/8(K) log3/8(npsum)

a2 + a2B

1 + V2(x)

3/8 .

A more explicit bound on  2 is given in Proposition A.1, see also Remark A.1.

Proof of Lemma C.5. The statement follows from Proposition A.1 and Theorem C.1. Let ba
us take k := k and k := k . Define similarly to  in (A.5)

 d=ef 1 , . . . , K

 ab d=ef

ab ba 1 , . . . , K

.

(C.2)

Condition (A.4) rewrites for (C.2) as Var  - Var ba  ab max  2
for some 2  0 . Denote D2 d=ef diag D12, . . . , DK2 , V 2 d=ef Var L1(1) , . . . , LK (K )

.

D2 is a block-diagonal matrix and V 2 is a block matrix. Both of them are symmetric,

positive definite and have the dimension psum × psum . Let also

V2 d=ef Var ab

L1ba (1)

,

.

.

.

,



ab LK

(K

)

,

gi d=ef  i,1(1) , . . . ,  i,K (K )

 IRpsum ,

H2 d=ef

n

IE
i=1

gigi

,

B2 d=ef

n
i=1 IE {gi} IE {gi} .

50 Simultaneous bootstrap confidence sets

It holds

Var  = D-1V 2D-1, Var ab  ba = D-1V2D-1, H2 = IEV2, V 2 = H2 - B2.

Therefore Var  - Var ab  ba max = D-1 V 2 - V2 D-1 max  D-1 H2 - V2 D-1 max + D-1B2D-1 max  V2(x) D-1H2D-1 + D-1B2D-1  V2(x) + s2mb (a2 + a2B) =: 2 .

(C.3) (C.4)

Here inequality (C.3) follows from the matrix Bernstein inequality by Tropp (2012) (see
Section C.1). Inequality (C.4) is implied by conditions (IB) and (SmB) , and Cauchy-
Schwarz inequality. ab
Condition (C1) of Proposition A.1 is fulfilled for the vectors i,k and i,k due to conditions (ED0) , (I) and (SD1) , (Eb) , (SmB) , (IB) for c := a and c2 := a2 + aB2 v2 + max1in H-1IE gigi H-1 2 .

Proof of Theorem 3.1. Let us denote x2 d=ef x + log(K) . It holds with probability  1 - 12e-x

ba IP

K k=1

2Lkab(kab) - 2Lkba (k) > zk

L. B.9


ab IP

K k=1

ba k (k)



zk

+

ba W,k (r0,k ,

x2)

L. B.10


IP

ab

K k=1

kba (k)

ba ba > zk + W,k(r0,k, x2) + ,k(r0,k, x2)

L. C.5
 IP

K
k=1 k > zk - W,k(r0,k, x2)

- total

L. B.9
 IP

K k=1

2Lk(k) - 2Lk(k) > zk

- total,

for

total d=ef  2, ab
zk := W,k(r0,k, x + log(K)) + W,k(r0,k, x + log(K)) ab
+ ,k(r0,k, x + log(K))
 C pk + x+ log(K) x + log(K) in the case 5.3. n

(C.5) (C.6)
(C.7)

zhilova, m.

51

Definition of  2 is given in Proposition A.1, see also Remark A.1. The bound from Lemma C.5 says:

 2  25C

p3max n

1/8
log9/8(K) log3/8(npsum)

a2 + a2B

1 + V2(x)

3/8 .

For

zk

bounded as in (C.7) the conditions

C

max {n-1/2,
1kK

zk }







C

1mkinK {1/zk }

are fulfilled.

C.4 Proof of Theorem 3.2
Proof of Theorem 3.2. For the pointwise quantile functions zk() and zkba () it holds for each k = 1, . . . , K with dominating probability:

ab zk

(

+

full, k)



zk

()

,

ba zk

()



zk

(

+

full

k)

-

k

(C.8)

here full, k 

(pk

+

x)3

 /n

1/8 , it comes from Theorem C.2, and

k

  C(pk + x)/ n ,



k d=ef 0,

if c.d.f. of Lk(k) - Lk(k) is continuous in zk( + full, k); 

C(pk + x)/ n s.t. (C.9) is fulfilled, otherwise.

IP 2 Lk(k) - Lk(k) > zk( + full, k) - k   + full, k.

(C.9)

Indeed, due to Theorem C.2 and definition (1.5)

ba IP

2 Lkba (kab) - Lkba (k) > zk()

 IP 2 Lk(k) - Lk(k) > zk() + full, k   + full, k, therefore, by definition (2.3) zkab(+full, k)  zk() . The lower bound is derived similarly.
If there exist the inverse functions c-1(·) and c ba -1(·) , then it holds for   (0, 1) :

IP

K k=1

2Lk(k) - 2Lk(k)  zk()

 c-1(),

ab IP

K k=1

2Lkba (kab)

-

2Lkab(k )



ba zk

()

 c ba -1().

(C.10)

52 Simultaneous bootstrap confidence sets

Therefore, it holds

c ab-1( + full, max)

 IP ba

K k=1

2Lkab(kba )

-

2Lkab(k )



ab zk

(

+

full,

k)

by (C.8)


ba IP

K k=1

2Lkab(kab) - 2Lkba (k)  zk ()

by Th. 3.1
 IP

K k=1

2Lk(k) - 2Lk(k)  zk ()

- total

by L. C.6 and (C.10)
 c-1() - total - ac,LR,

here ac,LR  total (by Lemma C.6) and

full, max

d=ef

max
1kK

full,

k

 C{(pmax + x)3/n}1/8 in the case 5.3.

(C.11)

Thus

c ab-1( + full, max)  c-1() - total - ac,LR,

ba c ()



c(

+ total

+

ac,LR) +

full, max.

(C.12)

Hence it holds

IP

K k=1

2Lk (k )

-

2Lk (k )



ba zk ()

by (C.8)
 IP

K k=1

2Lk(k) - 2Lk(k)  zk ( + full, k) - k

by L. C.6

and (C.10)


c-1(

+

full, max)

+ ac,LR.

Therefore, if c()  full, max , then

IP

K k=1

2Lk (k )

-

2Lk (k )



ba zk (c()

-

full, max)

And by (C.12) for c ba ()  2full, max it holds

  + ac,LR.

IP

K k=1

2Lk (k )

-

2Lk (k )



ba zk

(c

ab ()

-

2full,

max)

 total + 2ac,LR.

-

zhilova, m.

53

Similarly for the inverse direction:

c ab-1()  IP ab  IP ba

K k=1

2Lkba (kba )

-

2Lkba (k

)



ba zk

()

- 1,k

K k=1

2Lkba (kab) - 2Lkab(k)  zk ( + full, k) - 1,k - k

 IP

K k=1

2Lk(k) - 2Lk(k)  zk ( + full, k)

 c-1( + full, max) + total + ac,LR,

 where 0  1,k  C(pk + x)/ n . This implies

+ total + ac,LR

c ba -1()  c-1( + full, max) + total + ac,LR,

c

ba ()



c ( -

total

- ac,LR)

-

full, max.

(C.13)

IP

K k=1

2Lk (k )

-

2Lk (k )



ba zk (

+

full,

k)

by (C.8)
 IP

K k=1

2Lk(k) - 2Lk(k)  zk ()

 c-1() - ac,LR.

IP

K k=1

2Lk (k )

-

2Lk (k )



ab zk (c()

+

full, max)

  - ac,LR.

And by (C.13)

IP

K k=1

2Lk (k )

-

2Lk (k )



ab zk (c

ba ()

+

2full,

max)

 -total - 2ac,LR.

-

for

z, total d=ef total + 2ac,LR  3total.

(C.14)

Conditions

of Theorem

3.1 include

zk



 C pk

,

therefore,

it

has to be

checked

that

zkab()



 C pk

.

It holds by

Theorem

B.4,

Proposition A.1,

Lemmas

B.6

and C.7

with

probability  1 - 12e-x :

ab IP

2 Lkab(kab) - Lkab(k) > C pk -

 2xpk + C(pk + x)/ n

 1 - 8e-x,

54 Simultaneous bootstrap confidence sets

Taking 1 - 8e-x   , we have

ab zk ()



C

pk -

 2xpk + C2(pk + x)/ n.

Inequalities for c ba () had been already derived in (C.12) and (C.13) with

c d=ef total + ac,LR.

(C.15)

Lemma

C.6.

Let

the

conditions

from

Section

5.1

be

fulfilled,

and

the

values

zk



 pk

and

zk  0

be s.t.

C

max {n-1/2,
1kK

zk }







C

min
1kK

{1/zk}

( 

is given in (A.3)),

then it holds with probability  1 - 12e-x

IP

K k=1

2Lk(k) - 2Lk(k)  zk

-IP

K k=1

2Lk(k) - 2Lk(k)  zk + zk  ac,LR,

where

ac,LR  12.5C

p3max n

1/8
log9/8(K) log3/8(npsum)a3/4.

Proof of Lemma C.6. This statement's proof is similar to the one of Theorem 3.1 (see
Section C.3). Here instead of the bootstrap statistics we consider only the values from the Y -world. Let us denote x2 d=ef x + log(K) . It holds with probability  1 - 12e-x

IP
L. B.9
 IP
Pr. A.1
 IP
 IP

K k=1

2Lk(k) - 2Lk(k) > zk

K
k=1 k > zk - W,k(r0,k, x2)

K
k=1 k > zk + zk + W,k(r0,k, x2)

K k=1

2Lk(k) - 2Lk(k) > zk + zk

+ ac,LR + ac,LR ,

where

ac,LR  12.5C pm3 ax/n 1/8 log9/8(K) log3/8(npsum)a3/4.

Similarly to (C.5) and (C.6) the term ac,LR is equal to  2 from Proposition A.1 with 2 := 0 , zk := zk + 2W,k(r0,k, x + log(K)) .

zhilova, m.

55

Lemma C.7 (Lower bound for deviations of a Gaussian quadratic form). Let   N (0, Ip) and  is any symmetric non-negative definite matrix, then it holds for any x>0
IP tr  - 1/2 2  2 x tr(2)  exp(-x).

Proof of Lemma C.7. It is sufficient to consider w.l.o.g. only the case of diagonal matrix  , since it can be represented as  = U diag{a1, . . . , ap}U for an orthogonal matrix U and the eigenvalues a1  · · ·  ap ; U   N (0, Ip) .
By the exponential Chebyshev inequality it holds for µ > 0 ,  > 0

IP tr  - 1/2 2    exp(-µ/2)IE exp µ tr  - 1/2 2 /2 .

log IE exp

µ

tr  -

1/2 2

/2

1 2

p

{µaj - log(1 + ajµ)} ,

j=1

therefore

IP tr  - 1/2 2    exp - 1 µ + 2

p
j=1 {log(1 + ajµ) - µaj}

 exp - 1 µ - µ2 2

p j=1

aj2

/2

 exp -2/ 4

p j=1

aj2

.

If x := 2/ 4

p i=1

a2j

, then  = 2

x

p j=1

a2j

.

C.5 Proof of Theorem 3.3

Proof of Theorem 3.3. Let us denote x2 d=ef x + log(K) . By Lemmas B.9, B.10 and C.5 it holds with probability  1 - 12e-x

ab IP  IP ab

K k=1

2Lkab(kba ) - 2Lkab(k) > zk

K k=1

kab(k )

ab ab > zk + W,k(r0,k, x2) + ,k(r0,k, x2)

 IP

K
k=1 k > zk - W,k(r0,k, x2)

- b, total

(C.16)

 IP

K
k=1 k > zk - W,k(r0,k, x2)

- b, total

(C.17)

 IP

K k=1

2Lk(k) - 2Lk(k) > zk

- b, total,

56 Simultaneous bootstrap confidence sets

here k d=ef Dk-1Hk2Dk-1 1/2(Var k)-1/2k , and b,total is given below. Using the same notations as in the proof of Lemma C.5, we have
 d=ef 1 , . . . , K = D-1H2D-1 1/2(Var )-1/2,

and by Theorem C.1 and by conditions (I) , (IB) , it holds with probability  1 - e-x
Var  - Var ba  ba max = D-1 H2 - V2 D-1 max  V2(x) D-1H2D-1 max  V2(x)(a2 + a2B).

Thus, inequality (C.16) follows from Proposition A.1 applied to the sets of vectors

1ba (1),

.

.

.

,

ba K

(K

)

and

1, . . . , K .

The error term

b,total

is equal to

total

from

Theorem C.3 (see (C.5), (C.6)) with s2mb := 0 , thus

b,total  25C

p3max n

1/8
log9/8(K) log3/8(npsum)

a2 + a2B

1 + V2(x) 3/8 .

Inequality (C.17) is implied by definitions of k and matrices Hk2, Vk2 , indeed: Dk-1Hk2Dk-1 -1/2 Var k Dk-1Hk2Dk-1 -1/2
 Dk-1Hk2Dk-1 1/2 DkHk-2Vk2Hk-2Dk Dk-1Hk2Dk-1 1/2  1,

therefore, k  k . The second inequality in the statement is proven similarly to (C.12). It implies
together with Theorem C.4 the rest part of the statement having

b,c d=ef b, total + ac,LR.

(C.18)

References
Arlot, S., Blanchard, G., and Roquain, E. (2010). Some nonasymptotic results on resampling in high dimension, II: Multiple tests. The Annals of Statistics, 38(1):83­99.

zhilova, m.

57

Benjamini, Y. (2010). Simultaneous and selective inference: current successes and future challenges. Biometrical Journal, 52(6):708­721.
Beran, R. (1988). Balanced simultaneous confidence sets. Journal of the American Statistical Association, 83(403):679­686.
Beran, R. (1990). Refining bootstrap simultaneous confidence sets. Journal of the American Statistical Association, 85(410):417­426.
Bickel, P. J. and Rosenblatt, M. (1973). On some global measures of the deviations of density function estimates. The Annals of Statistics, pages 1071­1095.
Bonferroni, C. E. (1936). Teoria statistica delle classi e calcolo delle probabilita. Pubblicazioni del R Istituto Superiore di Scienze Economiche e Commerciali di Firenze.
Cao, H. and Kosorok, M. R. (2011). Simultaneous critical values for t-tests in very high dimensions. Bernoulli, 17(1):347­394.
Chernozhukov, V., Chetverikov, D., and Kato, K. (2013a). Gaussian approximations and multiplier bootstrap for maxima of sums of high-dimensional random vectors. The Annals of Statistics, 41(6):2786­2819.
Chernozhukov, V., Chetverikov, D., and Kato, K. (2013b). Supplement to "Gaussian approximations and multiplier bootstrap for maxima of sums of high-dimensional random vectors".
Chernozhukov, V., Chetverikov, D., and Kato, K. (2014a). Anti-concentration and honest, adaptive confidence bands. The Annals of Statistics, 42(5):1787­1818.
Chernozhukov, V., Chetverikov, D., and Kato, K. (2014b). Central limit theorems and bootstrap in high dimensions. arXiv preprint arXiv:1412.3661.
Chernozhukov, V., Chetverikov, D., and Kato, K. (2014c). Comparison and anticoncentration bounds for maxima of Gaussian random vectors. Probability Theory and Related Fields, 162:47­70.
Claeskens, G. and Van Keilegom, I. (2003). Bootstrap confidence bands for regression curves and their derivatives. Annals of Statistics, pages 1852­1884.
Dickhaus, T. (2014). Simultaneous Statistical Inference: With Applications in the Life Sciences. Springer.
Hall, P. (1991). On convergence rates of suprema. Probability Theory and Related Fields, 89(4):447­455.

58 Simultaneous bootstrap confidence sets
Hall, P. (1993). On Edgeworth expansion and bootstrap confidence bands in nonparametric curve estimation. Journal of the Royal Statistical Society. Series B (Methodological), pages 291­304.
Hall, P. and Horowitz, J. (2013). A simple bootstrap method for constructing nonparametric confidence bands for functions. The Annals of Statistics, 41(4):1892­1921.
Hall, P. and Pittelkow, Y. (1990). Simultaneous bootstrap confidence bands in regression. Journal of Statistical Computation and Simulation, 37(1-2):99­113.
Ha¨rdle, W. (1989). Asymptotic maximal deviation of M-smoothers. Journal of Multivariate Analysis, 29(2):163­179.
Ha¨rdle, W. and Marron, J. (1991). Bootstrap simultaneous error bars for nonparametric regression. The Annals of Statistics, pages 778­796.
He, X. (1997). Quantile curves without crossing. The American Statistician, 51(2):186­ 192.
Johnston, G. J. (1982). Probabilities of maximal deviations for nonparametric regression function estimates. Journal of Multivariate Analysis, 12(3):402­414.
Kim, K. I. and van de Wiel, M. A. (2008). Effects of dependence in high-dimensional multiple testing problems. BMC bioinformatics, 9(1):114.
Koenker, R. (2005). Quantile regression. Number 38. Cambridge university press.
Koenker, R. and Bassett Jr, G. (1978). Regression quantiles. Econometrica: Journal of the Econometric Society, pages 33­50.
Leek, J. T. and Storey, J. D. (2008). A general framework for multiple testing dependence. Proceedings of the National Academy of Sciences, 105(48):18718­18723.
Lindeberg, J. W. (1922). Eine neue Herleitung des Exponentialgesetzes in der Wahrscheinlichkeitsrechnung. Mathematische Zeitschrift, 15(1):211­225.
Liu, W. (2010). Simultaneous inference in regression. CRC Press.
Liu, Y. and Wu, Y. (2011). Simultaneous multiple non-crossing quantile regression estimation using kernel constraints. Journal of nonparametric statistics, 23(2):415­437.
Manly, B. F. (2006). Randomization, bootstrap and Monte Carlo methods in biology, volume 70. CRC Press.
Miller, R. G. (1981). Simultaneous statistical inference. Springer.

zhilova, m.

59

Nadaraya, E. A. (1964). On estimating regression. Theory of Probability & Its Applications, 9(1):141­142.
Neumann, M. H. and Polzehl, J. (1998). Simultaneous bootstrap confidence bands in nonparametric regression. Journal of Nonparametric Statistics, 9(4):307­333.
Qu, Z. (2008). Testing for structural change in regression quantiles. Journal of Econometrics, 146(1):170­184.
R¨ollin, A. (2013). Stein's method in high dimensions with applications. In Annales de l'Institut Henri Poincar´e, Probabilit´es et Statistiques, volume 49, pages 529­549. Institut Henri Poincar´e.
Romano, J. P. and Wolf, M. (2005). Exact and approximate stepdown methods for multiple hypothesis testing. Journal of the American Statistical Association, 100(469):94­ 108.
Shao, J. and Tu, D. (1995). The jackknife and bootstrap. Springer. Sida´k, Z. (1967). Rectangular confidence regions for the means of multivariate normal
distributions. Journal of the American Statistical Association, 62(318):626­633.
Slepian, D. (1962). The one-sided barrier problem for Gaussian noise. Bell System Technical Journal, 41(2):463­501.
Spokoiny, V. (2012a). Parametric estimation. Finite sample theory. The Annals of Statistics, 40(6):2877­2909.
Spokoiny, V. (2012b). Supplement to "Parametric estimation. Finite sample theory".
Spokoiny, V. (2013). Bernstein-von Mises Theorem for growing parameter dimension. arXiv preprint arXiv:1302.3430.
Spokoiny, V. and Willrich, N. (2015). Bootstrap tuning in ordered model selection. In preparation.
Spokoiny, V. and Zhilova, M. (2014). Bootstrap confidence sets under model misspecification. To appear in the Annals of Statistics. arXiv:1410.0347.
Spokoiny, V. G. and Zhilova, M. M. (2013). Uniform properties of the local maximum likelihood estimate. Automation and Remote Control, 74(10):1656­1669.
Stein, C. M. (1981). Estimation of the mean of a multivariate normal distribution. The Annals of Statistics, pages 1135­1151.

60 Simultaneous bootstrap confidence sets
Talagrand, M. (2003). Spin glasses: a challenge for mathematicians: cavity and mean field models, volume 46. Springer.
Tropp, J. A. (2012). User-friendly tail bounds for sums of random matrices. Foundations of Computational Mathematics, 12(4):389­434.
Wasserman, L. (2006). All of nonparametric statistics. Springer Science & Business Media.
Watson, G. S. (1964). Smooth regression analysis. Sankhy¯a: The Indian Journal of Statistics, Series A, pages 359­372.
Westfall, P. H. (1993). Resampling-based multiple testing: Examples and methods for p-value adjustment, volume 279. John Wiley & Sons.
Working, H. and Hotelling, H. (1929). Applications of the theory of error to the interpretation of trends. Journal of the American Statistical Association, 24(165A):73­85.

SFB 649 Discussion Paper Series 2015

For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.

001 002
003
004 005
006 007 008 009 010 011 012 013 014 015 016 017
018 019 020 021

"Pricing Kernel Modeling" by Denis Belomestny, Shujie Ma and Wolfgang Karl Härdle, January 2015. "Estimating the Value of Urban Green Space: A hedonic Pricing Analysis of the Housing Market in Cologne, Germany" by Jens Kolbe and Henry Wüstemann, January 2015. "Identifying Berlin's land value map using Adaptive Weights Smoothing" by Jens Kolbe, Rainer Schulz, Martin Wersing and Axel Werwatz, January 2015. "Efficiency of Wind Power Production and its Determinants" by Simone Pieralli, Matthias Ritter and Martin Odening, January 2015. "Distillation of News Flow into Analysis of Stock Reactions" by Junni L. Zhang, Wolfgang K. Härdle, Cathy Y. Chen and Elisabeth Bommes, January 2015. "Cognitive Bubbles" by Ciril Bosch-Rosay, Thomas Meissnerz and Antoni Bosch-Domènech, February 2015. "Stochastic Population Analysis: A Functional Data Approach" by Lei Fang and Wolfgang K. Härdle, February 2015. "Nonparametric change-point analysis of volatility" by Markus Bibinger, Moritz Jirak and Mathias Vetter, February 2015. "From Galloping Inflation to Price Stability in Steps: Israel 1985­2013" by Rafi Melnick and till Strohsal, February 2015. "Estimation of NAIRU with Inflation Expectation Data" by Wei Cui, Wolfgang K. Härdle and Weining Wang, February 2015. "Competitors In Merger Control: Shall They Be Merely Heard Or Also Listened To?" by Thomas Giebe and Miyu Lee, February 2015. "The Impact of Credit Default Swap Trading on Loan Syndication" by Daniel Streitz, March 2015. "Pitfalls and Perils of Financial Innovation: The Use of CDS by Corporate Bond Funds" by Tim Adam and Andre Guettler, March 2015. "Generalized Exogenous Processes in DSGE: A Bayesian Approach" by Alexander Meyer-Gohde and Daniel Neuhoff, March 2015. "Structural Vector Autoregressions with Heteroskedasticy" by Helmut Lütkepohl and Aleksei Netsunajev, March 2015. "Testing Missing at Random using Instrumental Variables" by Christoph Breunig, March 2015. "Loss Potential and Disclosures Related to Credit Derivatives ­ A CrossCountry Comparison of Corporate Bond Funds under U.S. and German Regulation" by Dominika Paula Galkiewicz, March 2015. "Manager Characteristics and Credit Derivative Use by U.S. Corporate Bond Funds" by Dominika Paula Galkiewicz, March 2015. "Measuring Connectedness of Euro Area Sovereign Risk" by Rebekka Gätjen Melanie Schienle, April 2015. "Is There an Asymmetric Impact of Housing on Output?" by Tsung-Hsien Michael Lee and Wenjuan Chen, April 2015. "Characterizing the Financial Cycle: Evidence from a Frequency Domain Analysis" by Till Strohsal, Christian R. Proaño and Jürgen Wolters, April 2015.

SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2015

For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.

022 023
024 025 026 027 028 029
030 031

"Risk Related Brain Regions Detected with 3D Image FPCA" by Ying Chen, Wolfgang K. Härdle, He Qiang and Piotr Majer, April 2015. "An Adaptive Approach to Forecasting Three Key Macroeconomic Variables for Transitional China" by Linlin Niu, Xiu Xu and Ying Chen, April 2015. "How Do Financial Cycles Interact? Evidence from the US and the UK" by Till Strohsal, Christian R. Proaño, Jürgen Wolters, April 2015. "Employment Polarization and Immigrant Employment Opportunities" by Hanna Wielandt, April 2015. "Forecasting volatility of wind power production" by Zhiwei Shen and Matthias Ritter, May 2015. "The Information Content of Monetary Statistics for the Great Recession: Evidence from Germany" by Wenjuan Chen and Dieter Nautz, May 2015. "The Time-Varying Degree of Inflation Expectations Anchoring" by Till Strohsal, Rafi Melnick and Dieter Nautz, May 2015. "Change point and trend analyses of annual expectile curves of tropical storms" by P.Burdejova, W.K.Härdle, P.Kokoszka and Q.Xiong, May 2015. "Testing for Identification in SVAR-GARCH Models" by Helmut Luetkepohl and George Milunovich, June 2015. " Simultaneous likelihood-based bootstrap confidence sets for a large number of models" by Mayya Zhilova, June 2015.

SFSBF6B4694, 9S,pSapnadnaduaeureSrtrSatßraeß1e, 1D,-D10-1107187B8eBrleinrlin htthpt:t/p/:/s/fbs6fb4694.w9.iwwiiw.hiu.h-bue-brleinrl.idne.de
ThTishrisesreasrecahrcwhawsassupsuppoprtoerdtebdybtyhethDeeDuetsucthseche ForFsocrhsuchnugnsgesgmeeminesicnhsachftatfht rtohuroguhgthhethSeFSBF6B4694"9Ec"oEnconmoimc RicisRki"s.k".

