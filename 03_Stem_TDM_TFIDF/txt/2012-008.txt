BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2012-008
Does Basel II Pillar 3 Risk Exposure Data help to Identify Risky Banks?
Ralf Sabiwalsky*
* Freie Universität Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

Does Basel II Pillar 3 Risk Exposure Data help to Identify Risky Banks?

Ralf Sabiwalsky
February 2, 2012
Abstract
Basel II Pillar 3 reports provide information about banks' exposure towards a number of risk factors, such as corporate credit risk and interest rate risk. Previous studies nd that the quality of such information is likely to be weak. We analyze the marginal contribution of pillar 3 exposure data to the quality of equity volatility forecasts for individual banks. Our method uses (local in time) measures of risk factor risk using a multivariate stochastic volatility model for ve risk factors, and uses measures of bank sensitivity with respect to these risk factors. We use two sets of sensitivity measures. One takes into account pillar 3 information, and the other one does not. Generally, we generate volatility forecasts as if no market prices of equity were available for the bank the forecast is made for. We do this for banks for which such data is, in fact, available so that we can conduct ex post - tests of the quality of volatility forecasts. We nd that (1) pillar 3 information allows for a better-than-random ranking of banks according to their risk, but (2) pillar 3 exposure data does not help reduce volatility forecast error magnitude.
Keywords: Risk Reporting, Stochastic Volatility, Risk Factors JEL Classication: G17, G21
Assistant Professor of Finance, Freie Universität Berlin, Boltzmannstr. 20, 14195 Berlin, Germany, rs@wacc.de. This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 Economic Risk, and this support is gratefully acknowledged.
1

1 Introduction
Banks' stock returns are driven by systematic risk and by idiosyncratic risk. The proportion of systematic risk is likely to be substantial since banks' assets are diversied and sensitive with respect to systematic risk factors. Among such factors are corporate equity returns, interest rates and aggregate credit risk. Thus, knowing the risk inherent in such risk factors should make it possible to make good forecasts of system-wide bank stock return volatility. However, there is also individual variation in bank volatility, too. Determinants of this individual variation include bank-specic sensitivity with respect to systematic risk factors on the one hand and idiosyncratic risk on the other hand. In Europe, banks are obliged by European law to publish standardized reports on their risk exposure (Basel II pillar 3 reports). Because of this, we analyze a sample of European banks. This article aims at nding out whether pillar 3 disclosures have the potential to improve estimates of bank-specic future volatility.
Estimates of the future volatility of a bank's equity returns are useful for a number of problems. These problems include (a) investment decisions with regard to the bank's equity, (b) interbank lending decisions, where equity return risk is an indicator of default risk due to the strong impact of asset quality and risk management practices on the return distribution, (c) regulators' assessment of the stability of the nancial system and (d) the valuation of derivatives written on the bank's equity. For a number of banks, empirical volatility and option-implied volatility can be used as estimates of equity volatility. However, for parts of banks, in adverse market conditions (e.g. due to low liquidity or trading restrictions) or for validation purposes, an analyst might wish or have to estimate volatility using information which does not rely on market data relating to the bank in question. Furthermore, there are a number of banks for which such data is not available at all. In such situations, using knowledge on the risk inherent in systematic risk factors and about the exposure of a bank with respect to these risk factors could be useful for assessing bank-specic risk. Whether this is indeed the case is an empirical question, and this article is an attempt answer it.
On the one hand, pillar 3 disclosures on risk exposure should help dierentiating between banks that are very sensitive with respect to certain risk factors and banks which are robust against risk factor volatility. Consider two banks, one of which hedges most of its net interest rate risk (low interest rate market value at risk), while the second one leaves open most of its net interest rate risk (high interest rate market value at risk). When interest rate volatility increases, the rst bank would exhibit only a modest increase in equity volatility, while the second bank would exhibit a substantial increase. On the other hand, while pillar 3 rules ensure a minimum level of comparability between disclosures, the methodologies that dierent banks use for calculating risk disclosures vary. Consider the situation where dierences between measures of risk exposure are larger across dierent calculation methodologies than across banks. Then using pillar 3 disclosures could make volatility forecasts using individual risk exposure data worse than forecasts which ignore such data. Our results indicate that the latter situation is true.
2

2 Priors on the Usefulness of Banks' Disclosures about Risk
Exposure
Operating a bank means taking on nancial risks. Typically, the methodologies developed for managing nancial risks and the internal organization of banks' risk management units reect a distinction between market risk and credit risk which is stricter than the interrelation between these two risk types would suggest. This has resulted in the use of risk measures which separately assess market risk and credit risk. For the purposes of this study, we dene risk as the extent to which the future value of a bank's equity is stochastic. We dene nancial risk (as opposed to strategic, operational, legal and other risks) as the stochasticity of future equity returns which results from sensitivity of the bank's future cashows towards changes in the values of nancial contracts that the bank has already entered into. We further distinguish between sources of nancial risks that go beyond the distinction between credit risk and market risk. We focus on large banks operating in the retail, corporate and wholesale markets. We concentrate on ve sources for the risk of changes in the value of a bank's nancial contracts:
1. changes of the likelihoods that corporate borrowers will be able to full their obligations (corporate credit risk),
2. changes of the likelihoods that sovereign borrowers will be able to full their obligations (sovereign credit risk),
3. changes of interest rates (interest rate risk),
4. changes of stock prices of nonnancial companies (stock market risk),
5. changes to the value of mortgage backed securities (MBS market risk).
Assessing the total risk of a bank can be accomplished in two or three steps. The rst step will consist of (a) an assessment of the vulnerability of the bank's existing contracts with respect to these ve (and possibly other) risk factors and (b) an assessment of the capability of the bank's risk management methodology to handle the risks arising from contracts that the bank will enter into in the future. The second step will require an analysis of idiosyncratic risks which arise, in particular, from the bank's competitive position. In addition, possibly as a third step, an analysis of the regulatory environment will be helpful, and regulation-induced risks to a bank's future protability will hit all banks in the same jurisdiction, but dierent banks may be dierently well prepared to cope with regulatory changes.
Banks are obliged to publish nancial reports and make regulatory disclosures. The aim of such publications is, among others, to inform creditors about their nancial risk position. That is, such publications should help nancial analysts and rating agencies to nd out how vulnerable the bank is with respect to changes in risk drivers. We argue that the ve risk factors listed above represent very important risk drivers. Now consider the goal to estimate the volatility of a bank's equity returns over one period ahead, where this could be a day, a month, a year or some other time interval of interest. We consider this to be an elementary task an analyst wishes to complete as part of a bank risk analysis.
3

We ask the question whether disclosures made by banks, following state of the art methodology, help the analyst in completing this task. We restrict our analysis to the data that can be used to assess the sensitivity of the bank with respect to the ve risk drivers listed above, i.e. we explicitly exclude the analysis of idiosyncratic risk. The usefulness of risk disclosures is a critical information for analysts who use such information to take investment decisions. Furthermore, regulators' decisions concerning regulatory measures require estimates of their potential eect on banks' risk taking behaviour. Banks' disclosures about risk should only be used for such an assessment when they are of sucient quality. That is, when potential inconsistencies between the risk measurement and disclosure methodologies among dierent banks and / or over time are smaller in magnitude than the actual dierences in risk (see González, 2005 on the analysis of the relationship between regulatory measures and banks' risk-taking behaviour).
In the remainder of this section, we will rst discuss why this is an important question to ask, i.e. we present arguments in support and arguments in contradiction to the hypothesis that mandatory risk disclosures are useful for volatility estimation. Second, we will present a methodology which allows for an assessment of the usefulness of risk disclosures.
To facilitate the discussion, we will rst specify the risk disclosure data that we consider helpful for an assessment of banks' nancial risks. First consider loans given out to borrowers of varying credit quality. A deterioriation in average probabilities of default over all rating classes will lead to a severe deterioration of the expected net present value of interest and principal payment from borrowers in low quality rating classes, while for high rating classes, the eect will be much less pronounced. Thus, for assessing the sensitivity of the bank's equity with respect to changes in credit quality, we suggest that the credit exposure of a bank in non-investment grade rating classes is a valid indicator. In their Basel II pillar 3 report, banks have to disclose by rating class their credit exposure. The disclosed exposures must be broken down by borrower type, which implies that the non-investment grade corporate and sovereign credit exposure are disclosed separately (see BIS 2007, part 4, sec. II, Table 5b and 6d). We hypothesize that
H1 the higher a bank's corporate credit exposure in non-investment grade rating classes, the more vulnerable its equity returns are with respect to aggregate corporate credit risk and
H2 the higher a bank's sovereign credit exposure in non-investment grade rating classes, the more vulnerable its equity returns are with respect to aggregate sovereign credit risk.
We now turn to interest rate risk, which generally arises from trading activities and from banking book transactions. Many large banks transfer banking book interest rate exposure to the trading book by internal transactions, such that total interest rate risk is solely managed through managing the net interest rate exposure in the trading book. For such banks, and only for them, interest rate risk in the banking book can be read from risk disclosures about interest rate risk in the trading book. Banks can choose to hedge most of their interest rate exposure or to leave open the net position, depending on the market risk management strategy. When a bank's strategy is to hedge most of its interest rate exposure, interest rate volatility will not translate into substantial variation in the value of its nancial contracts for this bank. Now consider the components of the value of a bank's equity.
4

Part of it results from nancial contracts the bank has already entered into. When interest rate risk is fully hedged, this component is not sensitive with respect to interest rate volatility. Part of the equity value, however, results from the expectation that the bank will be able to enter into protable contracts in the future. The interest rate risk arising from future contracts will not generally be fully hedged, even if the strategy is to hedge interest rate risk from existing contracts. Banks use dierent measures for interest rate sensitivity. They present the change in value of existing contracts that would arise from prespecied changes of certain interest rates (sensitivity measures). Further, they disclose a quantile of the prot/loss distribution of their trading book under the assumption that variability is only induced by interest-rate risk (VaR measures), as required by BIS (2007), part 4, sec. II, Table
11e.1 Sensitivity measures cannot be used to compare dierent banks because the interest rate changes
that they use are not generally identical. In contrast, VaR disclosures could by comparable, because pillar 3 regulations require the use of a set of predened parameters for the analysis. However, for some banks, banking book interest rate is not made part of the VaR analysis. Disclosures for interest rate risk which remains in the banking book follow the management approach and thus are not useful for comparing more than a very small number of banks, since costly imprecise adjustments are required for making such disclosures comparable (BIS 2007, part 4, sec. II, Table 14b requires to publish income shocks that would result from interest rate shocks of magnitudes identical to those being used for management's analysis of this risk). When we restrict our focus on the component of equity value that arises from a positive net present value of the set of existing contracts, we can hypothesize that
H3 the higher a bank's exposure to interest rate risk, measured by the interest rate VaR, the more sensitive its equity value is with respect to changes of interest rates.
A similar conclusion can be drawn for equity market risk. We suggest that changes in the level of aggregate stock indices leads to changes of the equity value of a bank in as far as the bank has open trading positions subject to stock market risk. The extent to which a bank has such open positions could possibly be inferred from observing its equity market risk VaR from trading activities, which is disclosed according to BIS (2007), part 4, sec. II, Table 11e. Further insight could be gained by observing the exposure to equity in the banking book (BIS 2007, part 4, sec. II, Table 13e). We can (and do) exclude stock market risk specic to the nancial sector when dening the time series for risk factor no. 4 (stock market risk), because otherwise we would measure volatility which is partly driven by the idiosyncratic risk of the banks in our sample. We cannot exclude stock market risk specic to the nancial sector when assessing the equity market VaR for a bank, since only aggregate stock market VaR are disclosed. We hypothesize that this inavoidable imprecision is not material, so that we can write down
H4 the higher a bank's exposure to stock market risk, measured by the stock market VaR, the more sensitive its equity value is with respect to aggregate nonnancial stock market returns.
Mortgage backed securities have attracted considerable attention following the nancial crisis of 2007/2008. This was due to substantial holdings of such instruments in bank's books. Many banks provide detailed
1Generally, pillar 3 requirements are binding law in the European Union, see European Parliament and European
Council (2006), where binding means that member states are obliged to introduce them into national law.
5

disclosures about their exposure to such instruments. Yet, while the data presented is detailed, it is dicult to obtain a measure of bank's exposure to MBS that is comparable across all banks without a cost-intensive analysis of each individual bank's report. Pillar 3 requires the disclosure of exposure in securitizations by rating class. We argue that the exposure to non-investment grade securitization positions provides an indicator for the vulnerability of banks' equity value with respect to MBS market volatility, since a substantial portion of securitizations exposures pertain to MBS transactions. Securitization disclosures follow BIS (2007), part 4, sec. II, Table 9g. We hypothesize that
H5 the higher a bank's exposure to non-investment grade securitizations, the more sensitive it is with respect to volatility in the MBS market.
The aggregate hypothesis we state is
H6 volatility forecasts that take into account bank - specic risk exposure data are better than volatility forecasts that do not.
At rst sight, the usefulness of such risk disclosures for volatility estimation - i.e. the validity of hypotheses H1 to H5 - should be self-evident. A more detailed analysis, however, reveals that there is substantial prior evidence against their validity. We will rst discuss the quality of disclosures regarding exposure to low-quality credit risk. Then, we will discuss the quality of VaR disclosures in their role as an indicator of (a) the risk factor - specic sensitivity of the value of a banks' portfolio of existing contracts and of (b) a bank's strategy to manage factor-specic risk, i.e. whether the bank has the general goal to hedge net exposure to a risk factor or not.
Most large banks operating under the Basel II regime apply internal ratings systems to assign exposure to rating classes. Internal ratings systems require approval by supervisory bodies before their output can be used to calculate risk-weighted assets. This ensures a minimum level of coherence between systems used by dierent banks. Yet, it is far from certain that the same borrower will be assigned the same rating by two dierent banks. This is because rst, the size and quality of historical data used for calibrating ratings systems varies among banks. Second, given a historical dataset, rating analysts enjoy methodological discretion when designing rating models. Third, before a rating is calculated for a specic borrower, the bank's analyst applies adjustments to the borrower's nancial data, and these adjustments follow both bank-specic general rules and also considerations specic to the individual analyst. Fourth, many ratings systems use qualitative data to account for characteristics of the borrower that are not measurable by nancial data but at the same time exhibit predictive power for defaults. As an example, the analyst might be asked to assign a grade to the ability of the management of the borrower. Such assessment is subjective and unlikely to result in coherent results among dierent lenders. As a consequence, it remains an empirical question whether disclosures on rating-specic exposure data by two banks is coherent enough to allow for a comparison of these two banks' credit risk sensitivity. Cary and Hrycay (2001) analyze the quality that can reasonably be expected for rating systems. They argue that ratings are subject to bias, instability and gaming (see also Jacobson et al., 2006). In line with their arguments, empirical evidence suggests that the potential for meaningful comparisons between banks is limited. Carey (2001) compares ratings of
6

rms that have been assigned a rating by several U.S. banks. He nds variation in assigned ratings. Jacobson et al. (2006) analyze the rating systems of two Swedish banks and rms who have borrowed from both banks and nd that internal rating systems at dierent banks provide dierent ratings in a substantial number of cases.
Value at Risk estimates require reasonable knowledge about the shape of the prot/loss distribution far away from the center of the distribution. Banks can choose from dierent methodologies to extract knowledge on this distribution from data on existing contracts and from historical and from current market pricing data. A large number of dierent approaches to modelling relevant stochastic processes and stochastic dependencies exist. Supervisors ensure a minimum quality of internal VaR models by requiring an extra capital charge if backtesting results are weak, but they do not require that for a unique portfolio of transactions, models from dierent banks provide the same VaR result. Furthermore, banks do not necessarily have incentives to report accurate VaR. On the one hand, Lucas (2001) argues that due to Basel II regulations, it can be rational to understate VaR for some banks. On the other hand, underestimated VaR result in a high number of exceptions to be reported to the supervisor and possibly to the capital market. Pérignon et al. (2008) argue that thus, banks might overestimate VaR as this preserves high reputation. As a consequence, it is not unlikely that two banks would obtain two substantially dierent VaR estimates for the same portfolio of contracts. This assertion is reinforced by the nding that the data used for backtesting VaR models is not generally appropriate, see Frésard et al. (2011). Furthermore, banks continuously strive to improve their methodology for measuring risk. Thus, dierent VaR estimates might be calculated for one bank at two dierent points in time for a xed hypothetical portfolio of contracts. If this were the case, it would be detrimental to the usefulness of risk-factor specic VaR estimates in the assessment of a bank's sensitivity with respect to the risk factor. Previous empirical evidence, again, is not very promising. Pérignon et al. (2008) consider VaR disclosures of several banks and argue that these overstate the true VaR by between 19% and 79%. Since the magnitude of overstatement need not be equal among dierent banks, VaR of dierent banks might not be comparable. They further argue that there is considerable evidence that VaR models fail to accurately predict quantiles of the loss distribution (see Cassidy/Gizycki 1997, Berkowitz/O'Brien 2002 and Berkowitz et al. 2006). Yet, overstated VaR do not imply that monitoring of trading risks is generally conservative. Wong (2008) shows that even though VaR might be overstated, tail risk can be severe. In particular, he nds that four out of six large commercial US banks exhibit trading loss distributions with fatter-than-normal tails.
Pérignon/Smith (2010a) nd that VaR disclosure standards have improved over time between 1996 and 2005. However, accuracy of VaR disclosures, in terms of the t between implied frequency of exceedances and observed frequency of exceedances has not improved over time. Furthermore, Pérignon/Smith (2010b) compare the magnitude of the diversication eect as disclosed by US banks to the magnitude of the diversication eect as empirically estimated in their paper. They nd that the disclosed values and their empirical estimates match. Since they have, however, in the companion paper (2010a) showed that disclosed VaR are higher than what empirically observed trading prot/loss distributions imply, they conclude that the disclosed VaR are biased.
7

From this analysis we conclude that it is an empirical question whether the quality of credit risk exposure and VaR disclosures is high enough to render this information useful for the task of forecasting individual bank equity volatility or to compare two banks in terms of their risk sensitivity. If there were only one risk factor, then banks with higher exposure should be more risky than banks with lower exposure, and the analysis would be straightforward. There are, however, a number of relevant risk factors. When bank A has higher exposure with respect to risk factor 1, but bank B has higher exposure with respect to risk factor 2, then the analysis must make use of data on the relative risk associated to both risk factors. An obvious attempt to account for that would be to follow the procedure applied in value relevance research, which aims at nding out how useful the disclosure of certain components of accounting income is. This is typically accomplished by testing ex post for correlation between accounting income ratios (or unexpected income surprises) and stock returns (see Holthausen/Watts, 2001 and Barth et al., 2001). However, we are interested in the question whether risk disclosures are
materially useful for the purpose its target group is likely use it for. Therefore, we will apply the
following methodology. The main idea is: disclosed risk measures are useful if they help an analyst to assess the risk for changes of the value of assets and/or liabilities which eventually translate into net changes of the value of its equity. Provided the bank is listed on the stock exchange, a simple measure for this risk is volatility of the bank's stock returns over future periods. However, if the bank is listed on the stock exchange, a detailed analysis of risk disclosures might not be so relevant since market data (historical returns, option-implied volatilities) can provide reasonable estimates of future volatility. When, in contrast, a bank is not listed on the stock exchange, then its risk disclosures are a major source of information about the bank's risk. An analyst who wishes to assess a nonlisted bank's future equity volatility could use risk disclosure data to nd out about the bank's sensitivity with respect to important risk factors and about the bank's idiosyncratic risk. Then she could combine this knowledge with good estimates of the future volatility of the risk factors to obtain an estimate of the bank's future
equity volatility even if it is not listed on the stock exchange. If this volatility is high, there is a high
likelihood that the bank's equity will drop below regulatory minimum capitalization requirements, which could eventually trigger a default. This is exactly what we do: We use a sophisticated approach to rank banks that are listed on the stock exchange according to their future estimated equity volatility,
taking into account risk disclosures, but without using capital market data about these banks. That is,
we treat these banks as if they were not listed on the stock exchange. We call these banks the forecast sample, and we compare our forecasts to the realized volatility for these banks. Then we
use a related approach to estimate future equity volatility, but here we ignore all information that is
specic to the banks in the forecast sample. If using pillar 3 disclosure data results in better volatility estimates compared to estimates that ignore pillar 3 information, then we would conclude that pillar 3 information provides useful information. We proceed as follows: First, we collect data on the exposure of 12 large European stock-listed banks with respect to ve risk factors: corporate credit spreads, sovereign credit spreads, equity market (excluding nancials) risk in the trading book, interest rates and the U.S. mortgage backed securities market. Second, we estimate the parameters of a model for the joint dynamics of the risk factors in a multivariate stochastic volatility model (the factor model). Third, we divide the sample into 6 (learning sample) + 6 (forecast sample) banks. For the learning sample, we estimate a factor stochastic volatility model (the stock model), where we estimate the
8

sensitivity of bank equity returns with respect to these risk factors and with respect to the interaction between these risk factors and risk factor exposure. We estimate the complete model and a restricted variant of the model where interaction parameters are restricted to be zero. Generally, all sensitivity parameters are restricted to be identical for the 6 learning banks. Fourth, we use the estimated dynamics of the risk factors and the estimated sensitivity parameters to forecast equity volatility for the forecast sample banks. We assess the quality of these volatility forecasts for the complete model and the restricted model. We forecast daily volatility over monthly intervals, but not entire return distributions, since we have only about 3 years of data (pillar 3 reports have not been published before 2008, and previous (voluntary) disclosures were so heterogeneous such that a reasonable empirical assessment is likely to be unreliable).

3 Models
We entertain two models. The rst one is a multivariate model for risk factor returns. The second one is a factor model for the stock returns. This two-layer structure has been chosen upon the observation that there exist a small number of factors that substantially inuence bank stock returns and that these factors are not stochastically independent. For an introduction to volatility modelling in general, and stochastic volatility modelling in particular, see Andersen et al. (2006).

3.1 Factor Model
The measurement equation for the (demeaned) daily returns of F risk factors is ct = HtRt,

(1)

where ct is an F × 1 vector of logreturns and R is an F × F lower triangular matrix with ones on the diagonal and (possibly nonzero) entries rij , 1  j < i  F below the diagonal. t is an F × 1 vector of normals, where both its entries are independent and also t, t are independent whenever t = t . This structure allows for straightforward estimation of the correlations between factors, since R is
the Cholesky decomposition of the covariance matrix of the factor disturbances where the parameters
below the diagonal are entirely free, and at the same time the implied covariance matrix RtRt is positive denite. H is a diagonal matrix with the latent volatility states on the diagonal, i.e.

 exp(0.5xt,1) 0 . . .

0

 0







Ht

:=

 







0
...
0 0

exp(0.5xt,2) · · ·

0

0

 

... . . .

...

...

 . 



0

· · · exp(0.5xt,F -1)

0 

0 ···

0 exp(0.5xt,F )

9

(xt,i)i=1,...,F =: xt is the F - dimensional latent log-variance state. Its evolution is specied as

xt = µx + x(xt-1 - µx) + Qt.

(2)

µx is an F × 1 vector of long-term mean log-variances, x  (0, 1) is adjustment speed towards these means,  is a diagonal matrix which contains the volatilities of volatility j > 0, j = 1, ..., F on its diagonal. t is an F × 1 vector of normals, where its entries are independent and also t, t are independent whenever t = t . In general, (contemporaneous) leverage eects can be modelled by specifying the joint distribution of t and t as (in block notation)

t  N 0, I L t L I

,

where L is diagonal with entries j , j = 1, ..., F on the diagonal, where j = 1, ..., F : j  (-1, 1). Q
is the (lower triangular) Cholesky decomposition of the covariance matrix of the state disturbances. By
including elements below the diagonal, correlated volatility evolutions can be specied. In the model
used for the empirical analysis, however, we specify L = Q = I .2

3.2 Stock Model

Two variants of the factor stochastic volatility model for a number of S stock returns are specied; an unrestricted variant and a restricted variant. Note that risk factors are indexed by j = 1, ..., F and bank stocks are indexed by i = 1, ..., S. Conditional on the risk factor returns, returns of any two
stocks are assumed independent. Thus, the volatility states in the stock model are associated purely to idiosyncratic volatility, and, we can specify the univariate dynamics separately for each stock. The
unrestricted measurement equation for the (demeaned) daily return of stock i over period t, yt,i, is

F
yt,i = (j + j at,i,j )ct,j + exp(0.5vt,i) t,i.
j=1

(3)

j measures the average sensitivity of stock returns with respect to risk factor j across all stocks in the learning sample. at,i,j is the exposure of bank i with respect to risk factor j as reported in the pillar 3 report for the last disclosure period ending before period t. j measures the interaction between the returns of risk factor j and banks' exposure to that risk factor, as an average across all banks in the learning sample. vt,i is the latent log-variance state. is standard normal, independent over time and
across stocks. The dynamics of the state are modelled as

vt,i = µv,i + v(vt-1,i - µv,i) + v,it,i,

(4)


 where Corr( t,i, s,k) =
0

if i = k and t = s,
in all other cases.

2It is left for later versions of this paper to nd out whether relaxing this restriction would improve model performance.

10

µv,i is long-term mean log-variance, v,i  (0, 1) is adjustment speed towards this mean, and v,i > 0 is volatility of volatility. In the restricted variant, j = 1, ..., F : j = 0.

3.3 Parameter and State Estimation
3.3.1 Overview
A particle Markov chain Monte Carlo method is applied for estimating the parameters of the models (see Andrieu et al., 2010, for an overview on the technique). Three model components (factor model, unrestricted stock model, restricted stock model, see sections 3.1 and 3.2) are estimated separately. The procedure proceeds following the idea of Pitt et al. (2010). The approach has been chosen since it allows for the establishment of a xed estimation framework that can exibly handle a large set
of dierent variants of state space models. All parameters are transformed onto the real line (for ,
the logit transformation is used, for correlation parameters, minus 1 plus 2 times a logit variable is used, and for strictly positive parameters, their logarithm is estimated). The idea is: we implement the Metropolis Hastings algorithm (MH) to draw samples from the posterior distribution of the parameters, and for evaluating the simulated likelihood in each iteration of the MH, we use the auxiliary particle lter (ASIR) from Pitt and Shephard (1999). We use a single component MH, i.e. we update one component of the parameter vector at a time.
In the following, the estimation procedure is described for a general state space model. We use y for the observations and v for the latent states as in the stock model, but the method applies also to the factor model where c denotes the observations and x denotes the latent states. We use p(·|·) for a generic conditional density dened by its arguments. The measurement density is
given by

p(yt|vt, )
and the state transition density is given by

(5)

p(vt|vt-1, ),

(6)

where  is the vector of D parameters (the composition of  depends on the model component whose parameters we estimate). We further specify a prior distribution on the parameters, p(), and an initial distribution for the states, p(v0|). Our priors are the normal distribution with mean 0 and variance 10 for µ·, r·, · and ·; a truncated normal between 0 and 1 with location 0.9 and scale 0.1 for · and a truncated normal between -1 and 1 with location 0 and scale 106 for ; and an inverse gamma with parameters 0.01 and 0.01 for ·². p(v0|) is a uniform distribution around µ·. Parameters are
estimated by drawing samples from their posterior distribution using the MH. We use the notation
y1:t whenever we mean {y1, ..., yt}, and this notation also applies to other variables (such as x1:t). We aim at drawing from the distribution p(|y1:T ). Generally, we would thus dene a Markov chain with stationary distribution proportional to p(y1:t|)p(). However, the likelihood p(y1:t|) is not known

11

in closed form due to the latent states. Thus, we use a simulated likelihood which is obtained from ltering the state space model. We use the well-known auxiliary particle lter (ASIR) from Pitt and Shephard (1999).

3.3.2 Single Component Adaptive Metropolis Hastings Algorithm

We denote the vector of parameters in the g-th iteration of the Markov chain by g . Throughout the MH algorithm, we separately make one-dimensional proposals for the elements in . We denote the m - th element of g by g,m, and we dene g,-m := (g,1, ..., g,m-1, g,m+1, ..., g,D) and g+,-m := (g,1, ..., g,m-1, g-1,m+1, ..., g-1,D). The Metropolis Hastings algorithm proceeds as follows for g = 1, .., G where 0 can be chosen arbitrarily.
g = 1, ..., G; m = 1, ..., D :

1. draw ~m from proposal density qg (m|·),

2. run the ASIR and calculate the simulated likelihood,

3. dene



 
g,m :=

~m

 

g-1,m

w. prob. g,m = min

1, · Ap^(yt|y1:t-1,~m,g+,-m)p(~m)
p^(yt |y1:t-1 ,g-1,m ,g+,-m )p(g-1,m )

g,m

w. prob. 1 - g,m.

,

The proposal density qg (m|·) changes over the course of the MH (hence its index) and so does Ag,m, a generic expression by which we denote the ratio of proposal densities. For small g, we choose random walk proposals, and for large g - when something has been learnt about p(|y) - we choose independent
sampling. In particular, we adapt the scheme suggested and described in detail by Pitt et al. (2010) to the single component MH.
We start with the adaptive random walk of Roberts and Rosenthal (2009) for the rst 800 iterations.
Hence, g = 1, ..., 800; m = 1, ..., D : Ag,m = 1. We draw from

qg(m|·) = qg(m|g-1,m, g+,-m) = g(m|g-1,m, 1I, g+,-m)+(1-g)(m|g-1,m, 22,g-2, g+,-m).
(7)
Here, 1 = 0.01/D, 2 = 2.38²/D and 2,g-2 is the sample covariance matrix of 1:g-2. Now let z be an arbitrary vector of dimension D with elements zm, m = 1, ..., D and let b be an arbitrary vector of dimension D - 1. Then we dene (zm|µ, , b) as the conditional normal density for z with mean vector µ and covariance matrix  evaluated at zm conditional on (z1, ..., zm-1, zm+1, ..., zD) = b. We set the weight g = 1 until 400 proposals have been accepted; then, up to the 800th acceptance, we choose g = 0.05. From the 801th acceptance, we use an independent sampling scheme, where

4
qg(m|·) = qg(m|g, g, g+,-m) = g,lfl(m|g,l, g+,-m)
l=1

(8)

12

A =and where g,m

qg qg

(m (~m

|g |g

,g ,g

,g+,-m ,g+,-m

) )

.

That is,

we use a mixture of four proposal densities

each denoted

by fl, l = 1, ..., 4; where the parameters of any fl are stacked in g,l. Until the 1200th acceptance, we

set g,1 = 0.8, g,2 = 1 - g,1, g,3 = g,4 = 0, f1(m|g,l) = (m|0, 1,g, g+,-m) and f2(m|g,l) =

(m|0, 10·1,g , g+,-m). 1,g is the sample covariance matrix of the sampled parameter vectors 1, 2, ...

updated at regular intervals. Until the 1600th acceptance, we set g,1 = 0.15, g,2 = 0.05, g,3 = 0.7,

g,4 = 0.1, and f1, f2 remain unchanged. f3 is a mixture of normals updated from the sampled set

0, 1, ... at regular intervals following the k-harmonic means approach (Hamerly/Elkan, 2002) using

the algorithm of Bradly/Fayyad (1998) for initialization. f4 is identical to f3 except for the covariance
matrices which are 20 times as large. After the 1600th acceptance, we replace f1 by f3 and set f2

equal to f1 but with covariance matrices multiplied by 10, and we keep f1 and f2 xed afterwards.

f3 is obtained again as an estimated mixture of normals, updated regularly, and f4 is identical to f3

with covariances 20 times as large. Finally, as parameter estimates we take ^ :=

G g=g¯+1

g

,

where

g¯ = 10, 000 is the end of the burn-in period and G = 20, 000 is the total number of PMCMC iterations.

3.3.3 Simulated Likelihood

Our implementation of the ASIR proceeds as follows for one specic choice of parameters :

1. Initialize k = 1, ..., n particles by drawing v0k  p(v0|) and by setting w¯1k = 1/n for k = 1, ..., n. 2. For t = 1, ..., T - 1:

(a) k = 1, ..., n compute tk+1 = p(yt+1|vtk+1)w¯tk where vtk+1 = E vt+1|vtk ,

(b) resample (by stratied sampling) the particles so that particle k is chosen with probability

¯tk+1 = tk+1/

n i

ti+1,

and

note

that

each

vtk

is

redened

by

this

resampling,

(c) k = 1, ..., n draw vtk+1 p(vt+1|vtk, ),

(d)

k = 1, ..., n compute wtk+1 =

p(yt+1 |vtk+1 ) p(yt+1 |vtk )

and w¯tk+1 = wtk+1/

n i

wti+1.

Note that in step (c), we do not condition on yt+1, which has worked well in the implementation of
Johannes et al. (2009) for a univariate stochastic volatility model. It works well in our multivariate framework, too. Pitt et al. (2010) write down the simulated likelihood

where

T
p^(y1:T |) = p^(y1) p^(yt|y1:t-1, )
t=2

(9)

p^(yt|y1:t-1, ) =

1 n

n

wtk

k=1

1 n

n

qtk

k=1

and show that this is an unbiased estimator of the likelihood.

(10)

13

3.4 Forecasting

For assessing the quality of forecasts, it is essential to carefully specify the information set used for making each forecast. To do so, we dierentiate between the cross-sectional dimension and the time dimension. We further distinguish between knowledge on latent volatility states and on model param-
eter estimates. We assign indices i = 1, ..., S to all banks in the sample where the indexing reects the ranking of banks with respect to their size (total assets). Let S be even. We dene two forecast samples, F1 := {1, 3, 5, ..., S - 1} and F2 := {2, 4, ..., S}. We dene two learning samples, L1 := F2 and L2 := F1. When making forecasts for banks in F1 we use data from L1, and when making forecasts for banks in F2, we use data from L2.
With respect to the cross-sectional dimension, we treat the banks in the forecast sample as if we had no information about their stock prices. That means, both latent volatility states and model parameters are estimated without knowledge about their returns. With respect to the time dimension, for making a forecast for a specic time interval, we collect latent volatility states estimated with data available up to the last day before the beginning of this time interval. For making reasonable volatility estimates, good estimates of the parameters of the stochastic volatility models are essential. Since pillar 3 information has not been available before 2009, we use estimates of the parameters taken from estimation of the models over the complete sample period January 2009 until November 2011.

We check the quality of volatility forecasts for daily volatility over monthly (20 trading day) intervals
by comparing them to empirical volatility for all banks in the forecast sample. We need an estimate
of risk factor latent volatility and for idiosyncratic volatility of each bank in the forecast sample as
starting values of the latent states in the forecasting simulation. We use the ltered volatility states of
the factor model and the average ltered idiosyncratic volatility state across all banks in the learning
sample, both taken from the last day before the beginning of the estimation period.
We denote by ^(f ) the set of parameter estimates for the factor model, by ^(L1) the set of parameter estimates for the unrestricted stock model obtained using L1 and by ^(L2) the set of parameter estimates for the unrestricted stock model using L2. ^(L1,restricted) and ^(L2,restricted) are the estimates obtained under the restriction j = 0, j = 1, ..., F.
Then, we lter the factor model and the stock models and dene estimates of the latent risk factor
logvariances vector for day t as follows:

n
x^t := w¯tk xkt |(f) ,
k=1

(11)

where the xtk|(f ) are observed after completion of step 2d of the ASIR for day t. Similarly, we dene

v^t(Lh)|F

:=

2 S

iLh

n k=1

w¯tk

vtk,i|F

where h  {1, 2} and F 

^(L1), ^(L2), ^(L1,restricted), ^(L2,restricted)

.

Now let t be the rst day of a forecast interval of size 20 days. We rst simulate (M times)

the risk factor volatilities, using the estimated risk factor latent logvariances from t - 1 as start-

ing values, by sequential updating them according to (2) over 20 trading days. At the same time,

we simulate the risk factor returns using the simulated logvariances and (1). We simulate univari-

ate idiosyncratic volatility states according to (4), using the average idiosyncratic volatility state

14

of the banks in the learning sample as starting value, and use these states for all banks in the
forecast sample. Then, using the M generated paths of the risk factors and of the idiosyncratic

volatility, we simulate bank stock returns, using the risk-factor data and bank-specic exposure

data for the forecast sample. Simulation follows (3). Here we use the average mean logvariance

parameter estimate µ^v :=

S i=1

µ^v,i

across

all

banks

in

the

learning

sample

for

sequential

sim-

ulation of (2). We use u = 1, ..., M simulations and obtain the sets of simulated stock returns

y(u,i)|x^t-1, v^tL-21, ^(L2)

,  =t,...,t+20;iL1;u=1,...,M

y(u,i)|x^t-1, v^tL-11, ^(L1)

and an =t,...,t+20;iL2;u=1,...,M

other pair of such sets with ^(L1), ^(L2) replaced by ^(L1,restricted), ^(L2,restricted). We calculate the

volatility forecast associated to the end of day t - 1 and bank i as



^t2-1,i|F

:=

1 M

M

1 t+19  20 - 1

u=1

 =t

(y(u,i)|x^t-1, v^tL-h1, F )

-

1 20

t+19
(y(u,i)|x^t-1, v^tL-h1, F )

 =t

2 ,

where the empirical counterpart is

s^2t-1,i

:=

1 20 - 1

t+19

 =t

1 t+19

y,i - 20

y,i

 =t

2

and where h = 2 when i  F1 and h = 1 when i  F2. We assess the quality of forecasts by calculating
the unrestricted bias

iF1

^t2-1,i|^(L2) - s^t2-1,i +
iF2

^t2-1,i|^(L1) - s^t2-1,i

and the unrestricted root mean squared error

iF1

^t2-1,i|^(L2)

2
- s^t2-1,i +

iF2

^t2-1,i|^(L1)

2
- s^t2-1,i

as well as the restricted counterparts where ^(L1), ^(L2) are replaced by ^(L1,restricted), ^(L2,restricted).

4 Data
4.1 Bank Samples
We select the twelve largest (measured by by total assets, at end of 2008) European banks that are listed on a stock exchange and for which pillar 3 reports are available from their website. Most banks start reporting for the 2008 nancial year, thus our sample is January 2009 until October 2011. This provides us with a large group of important banks, for which it holds that they are all subject to the same set of disclosure rules. We group these banks by total assets and group together the largest, the third largest, ..., the eleventh-largest bank into a subsample that we denote by 1,3,.... This
15

subsample has six members. We group together the remaining six banks into another subsample that we denote by 2,4,.... When forecasting for the banks in sample 2,4,.. we use sample 1,3,... as learning sample, and vice versa. This procedure ensures that no size eect interferes with the distinction between learning and forecasting samples. The banks in our sample are Royal Bank of Scotland (RBS), Deutsche Bank (DB), BNP Paribas (BNP), Barclays (BARC), HSBC, Crédit Agricole (CRAG), UBS, Société Générale (SG), ING, Santander Central Hispano (SAN), Lloyds (LLYD), Credit Suisse (CS). Bank stock returns are daily logreturns, which are demeaned and multiplied by 100, from Thomson Reuters Datastream.
4.2 Factor Returns
We use the following ve factors, which we believe are the most important systematic risk drivers for equity returns of European large banks. (1) As corporate credit risk factor, we use the average of sector-specic 5 year - maturity CDS spread indices, as published by Thomson Reuters Datastream, for the following sectors: Auto, Basic Resources, Chemicals, Construction and Materials, Food and Beverages, Industrial, Media, Oil & Gas, Retail, Technology, Telecommunications, Travel and Leisure, Utilities. We do not include spreads for companies in the nancial sector. (2) As sovereign credit risk factor, we use a 5 year - maturity CDS index, as published by Thomson Reuters Datastream, for EU sovereigns. (3) For the equity market, we use sector specic MSCI total return stock indices for companies in the European Monetary Union. We translate all of the following index series so that their value is 100 on December 31, 1999: Energy, Materials, Consumer Discretionary, Consumer Staples, Healthcare, IT, Services, Utilities. We calculate a nonnancial stock index by averaging these normalized indices. (3) As interest rate, we use the yield of the 10 year German Bundesanleihe. (4) For mortgage backed security risk, we use the prices of the iShares exchange traded fund on Barclay's mortgage backed security index. Since this is a price index, we use a total return ETF time series. Since we are interested in factor risk, we calculate daily log-changes to these risk factors, and we demean them and multiply them by 100.
4.3 Exposure Data
We retrieve exposure data from the pillar 3 reports of all banks in our sample. (1) Exposure towards corporate credit risk is measured as total credit exposure in corporate clients with non-investment grade ratings. Since banks use dierent rating scales, and we use exposure data from the standardized approach and from IRB approaches, we dene as non-investment grade any rating where the associated one-year PD is greater than 1%. For calibration, bank-specic disclosures on PDs are used for ratings in the IRB approaches, and Moody's Investors Service (2011a) is used for ratings in the standardized approach. The reason for concentrating on lower quality exposure only is that the sensitivity of the fair value of loans with lower grade ratings towards changes in credit quality is much stronger than for loans with higher grade ratings. (2) Exposure towards sovereign credit risk is measured as total credit exposure in sovereign borrowers with a rating that is associated to a one-year PD of more than 0.05%. For calibration, Moody's Investors Service (2011b) is used. As a measure of exposure to (3) equity risk
16

respectively (4) interest rate risk, we use the end-of-year Value at Risk of equity respectively interest
rate risk in the trading book.3 We use VaR for a 1 trading day interval at the 99% condence level.
When the trading horizon and/or the condence level for a bank's VaR disclosures is dierent, we adjust the disclosed VaR to match our requirements. We do this by assuming a normal distribution for the prot/loss. We add the exposure to equity risk in the banking book to the equity risk exposure. Since the VaR measure is structurally dierent from the banking book equity exposure data, we need to scale one of them. We choose to multiply VaR by 1000. (5) As a measure of exposure to mortgage backed security risk, we use the sum of securitization exposures in noninvestment grade rating classes. Exposures in the standardized approach are included when it can be observed in the report that their risk weight is above 100%. The exposure data obtained by this procedure is divided by total regulatory capital to adjust for size. Finally, for each risk factor, we normalize the data by dividing each exposure by the average exposure across all banks and years. That is, for any risk factor, exposure above (below) 1 indicates above (below) average exposure.

5 Results

5.1 Descriptive Statistics

First, we present summary statistics for the time series of factor changes and bank-specic stock returns. The empirical distributions of risk factor changes, as shown in table 1, vary greatly. Sovereign spread changes are highly leptokurtic, which corresponds to high variance in the latent variance process (see table 2). Returns of the MBS index exhibit very low volatility, which is surprising at rst sight, but has to be seen in the light of the developments on the MBS market prior to the beginning of the
sample period. The majority of losses on the MBS market occured before the beginning of 2009.4

Std. Dev. Skewness Kurtosis

Corporate Spread
0.0272 -0.30 4.85

Sovereign Spread
0.0506 -1.02 20.19

Stock Market
0.0142 -0.14 1.76

Interest Rate
0.0187 -0.17 2.06

MBS Market
0.0019 -0.22 1.57

Table 1: Factor Returns Time Series

Table 2 shows characteristics of the return distributions for the twelve banks in the complete sample,
ordered by size. 5 There is notable variation in standard deviations: the largest bank is the bank with

the riskiest returns, the bank with the lowest standard deviation is HSBC. Some return series exhibit

substantial excess kurtosis, which in part results from extreme changes of prices that followed news

about doubts regarding banks' nancial strength. It is also important to note that the return series

exhibit substantial variation in volatility over time. A measure of this variability is parameter v in the

??3See sec.

, no. 1. Since in some banks, daily VaR is volatile, an average VaR could be better an indicator for

interest rate risk exposure, since this could indicate more accurately whether the bank's strategy is to hedge interest

rate risk or not.
4See also sec. ??.
5These banks represent the twelve largest European banks ranked by total assets. On position 11 is HBOS, which is

owned by Lloyds, and therefore position 11 is chosen for Lloyds.

17

Figure 1: Rolling 20-day window daily bank stock return volatility

stock model (see table 6). Figure 1 shows the average of the rolling window daily standard deviation of all 12 bank stock return series for a window size of 20 days over the sample period January 2009 until October 2011.

RBS DB BNP BARC HSBC CRAG UBS SG ING SAN LLYD CreditSuisse

Std. Dev.
0.0629 0.0322 0.0345 0.0488 0.0240 0.0345 0.0311 0.0380 0.0426 0.0277 0.0567 0.0284

Skewness
-9.89 0.49 0.55 1.35 -0.44 0.21 -0.18 -0.20 0.02 0.46 -3.58 0.21

Kurtosis
195.82 5.84 6.94 28.46 11.44 4.00 3.96 6.83 5.98 6.66 59.87 3.65

Table 2: Stock Returns Time Series

In table 3 we report the exposure measures for all factors and all banks in the sample. Exposure measures are averaged over the complete sample period. The numbers are normalized such that average exposure towards one factor across all banks is one. Since exposures are adjusted for size, they might be used to obtain some insight into the relative sensitivity of banks towards each separate factor. This insight requires, however, that the exposure measures are comparable. This data cannot be used to draw immediate conclusions with respect to total risk for individual banks, because volatility varies across factors, and factors are not independent. The model that we apply is a framework capable of extracting knowledge from the joint evolution of factors and the bank-specic exposures to these factors.

18

RBS DB BNP Barclays HSBC CreditAgricole UBS SocieteGenerale ING Santander Lloyds CreditSuisse

Corporate Spread
0.79 1.45 1.12 0.61 0.71 0.80 0.82 1.23 1.76 0.91 1.01 0.85

Sovereign Spread
0.13 0.58 1.05 0.58 2.93 0.61 2.15 1.84 1.14 0.14 0.03 0.70

Stock Market
0.43 2.30 1.52 0.66 0.27 1.21 1.51 1.45 0.33 0.37 0.09 2.04

Interest Rate
0.63 2.74 0.63 0.84 0.36 0.90 1.02 0.51 0.69 0.38 0.30 3.16

MBS Market
0.52 1.64 0.37 3.67 0.38 0.30 0.68 1.81 0.76 0.21 0.96 0.40

Table 3: Factor Sensitivities

5.2 Model Parameters

Table 4 contains estimates of the parameters in (2). µx measures the mean towards which latent log-variance reverts, and x is the speed of reversion.6 There are remarkable dierences among the estimates for dierent factors. The µx estimates generally reect the average variances of the factor re-
turn series. Sovereign spread changes exhibit remarkably high volatility of volatility, which corresponds
to high excess kurtosis, and which certainly reects severe uncertainty of changing degree regarding the
soundness of various European sovereign borrowers during the estimation period. We use the mean of
the discrete posterior distributions of parameters as estimates, and we the standard deviation of these
distributions in parentheses. Hypothesis tests where estimates are tested on being dierent from zero
are not meaningful for the parameters in table 4. From inspection of standard errors we can, however,
infer that we can have reasonable condence in the estimates for most parameters, when comparing
the standard deviations to the scale on which parameters are dened (µx is dened on the real line, x is between 0 and 1, and x2 is positive and real). Meanwhile, some of the x2 distributions exhibit
substantial dispersion around the mean.

Corporate Spread Sovereign Spread
Stock Market Interest Rate MBS market

µx
0.8725 (0.1455)
0.6402 (0.0837) -0.0251 (0.0649)
0.1656 (0.1332) -1.7023 (0.0956)

x
0.9768 (0.0086)
0.0196 (0.0107)
0.5856 (0.0938)
0.8747 (0.1065)
0.5818 (0.0672)

x2
0.0079 (0.0098)
0.9094 (0.1841)
0.0942 (0.059) 0.0338 (0.03) 0.2374 (0.1176)

Table 4: Factor Evolution Parameters
6Note that x is log-variance, hence negative values indicate that the corresponding variance level is below 1.

19

Estimates of elements in matrix R in (1) and shown in table 5.

Corporate Spread

CORP 1

SOV 0

EQU 0

INT 0

MBS 0

Sovereign Spread Stock Market Interest Rate MBS market

0.7187*** (0.0882)
-0.7937*** (0.0704)
-0.7217*** (0.0692) 0.1047** (0.0505)

1
-0.0163 (0.0623) -0.1116* (0.0598)
0.0973 (0.0661)

0
1
0.4916*** (0.0673) -0.1521** (0.0803)

0
0
1
-0.3061*** (0.0629)

0 0 0 1

Table 5: Decomposition of Factor Correlation Matrix

Table 6 shows estimates for the parameters in (4) and for . Variation in the bank-specic means in
equation (4) correspond to the variation of return standard deviations: correlation between estimated standard deviations and means, estimated without/with exposure data, is 82.3%/60.8%. Estimated mean reversion speed is similar to estimates from stochastic volatility models for stock indices, see e.g.
Chib et al. (2002). The estimate for  is negative, which is evidence of a leverage eect in the sense
that negative stock returns are likely to be accompanied by volatility increases. The estimates are
close to the those from Omori et al. (2007) who nd a leverage eect of -0.36 for index returns on
the Japanese stock market.

µv for
RBS BNP HSBC UBS ING LLYD
v v 

exposure data no yes

4.6877 (1.4612)
3.1951 (0.7752)
2.8391 (0.1922)
2.7853 (0.6696)
2.7586 (0.4652)
3.5665 (0.689) 0.9935 (0.0039) 0.0668 (0.0154) -0.3180 (0.1849)

3.4850 (0.7064)
2.8649 (0.5162)
2.2082 (0.6264)
2.8618 (0.3735)
2.8280 (0.4534)
3.4739 (0.6121)
0.9896 (0.0027)
0.0778 (0.0135) -0.2674 (0.2087)

µv for
DB BARC CRAG
SG SAN
CS
v v 

exposure data no yes

2.5561 (0.8516)
2.9849 (0.436) 2.6435 (0.9551) 3.2387 (1.3562) 2.1809 (0.6675) 2.6429 (0.3611) 0.9896 (0.0068) 0.0578 (0.0138) -0.3030 (0.2803)

3.4996 (0.2488)
3.5391 (0.398) 2.6180 (0.2975) 2.6534 (0.2685) 3.1234 (0.2055) 3.1242 (0.3074) 0.9935 (0.0024) 0.0476 (0.0069) -0.5466 (0.0916)

Table 6: Stock Evolution Parameters

20

Next we turn to the sensitivity estimates. Recall that we hypothesized that bank stock returns are driven by risk factors, and that the higher a bank's exposure to a risk factor, the stronger the impact. We focus on two criteria when analyzing the estimates. First, we test whether the sensitivity estimates for factors and for factor-exposure interactions are signicantly dierent from zero. For each parameter, we consider the sampled posterior distribution and count all realizations whose sign is the opposite of the sign of the estimate. We multiply this number by two and divide it by the total
number of realizations, which is 10, 000. That way, we obtain a p-value which is a simulated equiva-
lent to an asymptotic p-value. When the p-value is smaller than 1%/5%/10%, we indicate this with three/two/one asterisk(s) in table 7. Second, we observe whether the estimates from both samples banks 1,3,... versus banks 2,4,... - are of the same sign. If this is not the case for both sensitivity parameters for factors and for factor-exposure interactions, we must conclude that our samples are too small to obtain reasonable estimates for the sensitivity parameters. If we obtain estimates of comparable sign and magnitude from both samples for at least either of the two - factor sensitivities or factor-exposure sensitivities - we will be able to draw conclusions with respect to the hypotheses stated in section 2.


Corporate Spread Sovereign Spread
Stock Market Interest Rate MBS Market

Corporate Spread Sovereign Spread
Stock Market Interest Rate MBS Market

learning from 1,3,... exposure data
no yes

-0.1479*** (0.0298) -0.0107 (0.0101)
1.0278*** (0.0534) 0.0765** (0.0359) -0.4321** (0.1892)

-0.1068*** (0.0392) -0.0097 (0.0221)
0.8633*** (0.0763) -0.0106 (0.0554) -0.6012* (0.2711)

-0.0718 (0.0586) -0.0001 (0.0233) 0.2264*** (0.0639) 0.0811** (0.0405)
0.1908 (0.2012)

learning from 2,4,... exposure data
no yes

-0.1772*** (0.0226)
-0.0182*** (0.0073)
1.0385*** (0.0435)
0.1246*** (0.0269) -0.2988* (0.148)

-0.2744*** (0.0721) 0.0094 (0.0144)
0.9548*** (0.0699) 0.259*** (0.0366)
-0.3458*** (0.1509)

0.1010 (0.0698) -0.0403*** (0.0172)
0.0637 (0.0464) -0.0871*** (0.0177) -0.0206 (0.0729)

Table 7: Sensitivity Parameters

For four out of ve factors, we obtain estimates which are signicantly dierent from zero and of the same sign (in parentheses) for both samples: corporate credit spread changes (-), nonnancial stock market returns (+), interest rate changes (+) and returns on the market for mortgage-backed securities
21

(-). Evidence of a signicant (negative) relationship between sovereign credit spread changes and bank stock returns are observed only for the sample of banks 2,4,...; however, for the other sample the sign and the order of magnitude of the estimate is the same. For the rst four factors, the estimated sensitivities are hardly surprising. The sensitivity for the MBS market is negative, and some comments on this are in order. When MBS drop in value due to an impairment of the assets backing the issues, so does the equity value of banks that have invested into such assets. When MBS drop in value due to an increase of the interest rate, this increase itself has an eect on an bank's equity value. The direction and magnitude of this eect depend on the maturity structure of the bank's assets and liabilities. Since we observe a positive relationship between interest rate changes and bank stock prices
(the corresponding  estimate is positive), we could conclude that a negative  estimate for MBS securities is plausible. However, since the  estimate for MBS securities should only measure the MBS
eect on bank returns that is orthogonal to the interest rate eect, a puzzle remains. One possible explanation is that whenever banks are obliged to stand in for guarantees they have given to ensure liquidity of special purpose vehicles (SPV), this will be detrimental to their equity value since these cash injections are unlikely to be repaid. However, these injections will have a positive eect on the value of debt instruments issued by the SPV. This would result in a negative relationship between
bank stock returns and returns to MBS securities. Figure 2 shows the posterior distributions of the 
estimates taken from sample 2,4,... .
22

Figure 2: Distribution of Sensitivity Estimates
Things are not as straightforward when considering factor-exposure interactions. There is no factor for which the interaction sensitivity parameter is signicantly dierent from zero and of the same sign in both samples. Thus, we can provide no convincing evidence in support of any of the hypotheses H1 through H5. We can see from table 7 that for sovereign spreads and for nonnancial stock returns, the coecient is signicantly dierent from zero for one of the two samples and of the same sign in both samples. This indicates that the exposure data obtained from pillar 3 reports can contribute to some, albeit limited, extent to a careful assessment of an individual bank's sensitivity with respect to these two risk factors, providing limited support for hypothesis H3. The magnitude of this contribution will
23

be assessed in section 5.3. The sensitivity coecients for the interest rate exposure interactions are signicantly dierent from zero in both samples, but they are of opposite signs. We could, at rst sight, conclude that interest rate VaR of an arbitrary, nonlisted bank is of no value to an analyst who wishes to assess its vulnerability to interest rate changes. At second glance, it is obvious that the direction of the equity value reaction to interest rate changes is not known ex ante, since it depends on the assets' and liabilities' maturity structure. Our results show that banks of the same calibre vary considerably with respect to their net position, otherwise we would not obtain this result. We conclude that more decent (and costly) an analysis of interest rate exposure data is required to draw conclusions with respect to hypothesis H5. In sum, we conclude that risk exposure data is unlikely to
substantially improve volatility forecasts. Figure 3 shows the posterior distributions of the  estimates
for sample 2,4,... .
24

Figure 3: Distribution of Exposure-Sensitivity Interaction Parameters
5.3 Forecasting Results
Table 8 presents average bias and root mean squared error from the out-of-sample forecasts of daily variance over intervals of 20 trading days. We have predictions for 33 of such intervals. The left column contains results for forecasts that have been made without taking into account bank-specic information, i.e. where the forecasts are identical for all six banks. The right column contains results for forecasts which take into account bank-specic information, i.e. the right hand column reects the
25

attempt to obtain variance forecasts for individual banks where variation between banks is obtained solely from pillar 3 data. Forecasts are made for two samples, the sample containing the largest, third-largest, ..., and eleventh-largest bank and for the sample containing the second-largest, fourthlargest,..., and twelfth-largest bank. Results are presented separately for both groups. The forecast errors are then aggregated and also reported across the two samples. Generally, bias is positive for both samples. Variance was high especially at the beginning of the sample period. Variance forecasts rely on latent logvariance states at the beginning of the forecast horizon. When variance declines over the sample period on average, then for a given forecast period, the starting value for variance is more likely to be too high than too low. Thus, it is not surprising to see positively biased forecasts.
We concentrate now on H6, which asserts that using pillar 3 information helps to obtain good variance forecasts. In fact, for the rst sample, using pillar 3 disclosure data results in better estimates (bias
1.70, RMSE 9.58), both in terms of bias and in terms of RMSE, compared to the uniform forecast that ignores risk exposure data (bias 3.91, RMSE 9.94). For the second sample, the reverse is true (11.20/20.58 versus 8.05/17.19). (Note that return series have been scaled by 100, which is standard
in stochastic volatility modeling.) The improvement of forecasts achieved in the rst sample is of smaller magnitude than the deterioriation of forecasts in the second sample. This results in a negative aggregate impact of the use of pillar 3 information on the quality of variance forecasts. Consider the variance forecast for one randomly chosen bank. It is not possible to tell which of the two forecasts we should use. We therefore conclude that there is no robust evidence that the exposure data used in
this study is materially useful for predicting equity volatility of banks over 20 trading day periods.7

predicting for 1,3,... Bias
RMSE predicting for 2,4,...
Bias RMSE Combined Samples
Bias RMSE

Exposure data no yes

3.91 9.94

1.70 9.58

8.05 17.19

11.20 20.58

5.98 14.04

6.45 16.05

Table 8: Bias and RMSE for Variance Forecasting

Instead of forecasting variance, it is also possible to forecast a ranking of banks according to their risk using exposure data. For each 20-trading-day interval over which we have calculated a variance forecast, we rank the six banks in forecast according to the forecasts. Then we compare this ranking to the ranking that we obtain ex post upon observing the actual variances. We count the number of ranks that have been predicted correctly in each month. We do this separately for sample 1,3,... and for sample 2,4,... . We count the months for which we have predicted correctly 0/1/.../6 ranks and divide these numbers by the number of periods. We report the resulting frequencies in table 9.
7We repeated the forecasting procedure for 120 trading day horizons. The magnitude of errors change, but the relative
magnitudes do not change, i.e. the same conclusion is drawn from 120 trading day horizons..
26

To understand the numbers in this table, take the row for 2 recontres as an example. For sample
1,3,..., we report a rounded frequency of 0.3. That means in 0.3  33 = 10 periods, two rank has been
correctly predicted. In the second column, we provide the probabilities of obtaining 0/1/.../6 correct
rank predictions if these were made at random (the probabilities are the solution to the rencontre -
problem, where one rencontre means that one rank prediction correctly predicts one rank). If the exposure data allows us to make rank predictions that are more accurate than random predictions, then the observed frequency for one rencontre or more will be higher than the probability associated to this event given random rank predictions. We observe that model-based rank predictions for sample 1,3,... are better than random ranks. This corresponds to the reduction in prediction errors for this sample. However, we observe that also for sample 2,4,... using pillar 3 information provides better rank predictions than random rankings. From this we conclude that the exposure data we chose for this study does provide information about the relative sensitivity of banks with respect to the chosen risk factors. We have argued above that one important purpose of risk disclosures is helping market participants and regulators to estimate the magnitude of bank-specic bank specic equity risk. Our aggregate evidence to date indicates that pillar 3 exposure data is not accurate enough to be of material relevance for this task.

# Rencontres
0 1 2 3 4 5 6

random ranking
0.79 0.17 0.03 0.01 <0.01 <0.01 <0.01

prediction for 1,3,...
0.33 0.27 0.30 0.06 0.03 0.00 0.00

prediction for 2,4,...
0.61 0.30 0.06 0.03 0.00 0.00 0.00

Table 9: Comparison of Random and Exposure-Driven Rankings

6 Summary and Conclusion
A model is designed to assess the informational value of banks' risk disclosures in their Basel II pillar 3 reports. These disclosures are considered as having informational value when they help to forecast individual banks' future equity volatility. While this is why they are published, previous evidence indicates that the quality of such disclosures is weak, i.e. that risk exposure data might not be comparable between banks. We dene disjunct learning and forecast samples of European banks and use information from the learning samples to make volatility forecasts for the banks in the forecast samples. We do not use stock return information from the forecast samples. We generate forecasts using the sensitivity of learning sample bank returns with respect to ve risk factors (corporate credit risk, sovereign credit risk, nonnancial stock returns, interest rates, asset-backed securities) and (local in time) risk factor volatility. These forecasts are identical for all banks in the forecast sample since no bank-specic information is used. Then we generate another set of forecasts which take into account the information that pillar 3 risk disclosures provide on the sensitivity of bank returns with respect to the risk factors. After that, we do make use of stock return information for the forecast sample to
27

compare the quality of forecasts without / with pillar 3 information. The predictions are calculated in a multivariate stochastic volatility model framework on two levels, which is estimated using particle Markov chain Monte Carlo methods. We nd that pillar 3 information is capable of producing a ranking between banks in the forecast sample which is better than a random ranking, but that pillar 3 information does not help making good volatility forecasts. One important purpose of pillar 3 risk exposure disclosures is to help assessing the risk of banks in situations where prices of their equity are not available / reliable. We conclude that the quality of pillar 3 information is not sucient to full this purpose. It must, however, be noted that the size of our sample (12 banks), which is a result of the heavy computational burden of the model, imposes a limitation on our results.
28

7 References
Andersen, T.G., Bollerslev, T., Christoersen, P.F., Diebold, F.X. (2006): Volatility and Correlation Forecasting. Handbook of Economic Forecasting 1, 777-878.
Andrieu, C., Doucet, A., Holenstein, R. (2010): Particle Markov chain Monte Carlo methods. Journal of the Royal Statistical Society B 72, 269-342.
Barth, M.E., Beaver, W.H., Landsman, W.R. (2001): The relevance of the value relevance literature for nancial accounting standard setting: another view. Journal of Accounting and Economics 31, 77-104.
Berkowitz, J., O'Brien, J. (2002): How accurate are value-at-risk models at commercial banks? Journal of Finance 57, 10931111.
Berkowitz, J., Christoersen, P.F., Pelletier, D. (2006): Evaluating value-at-risk models with desk-level data. Management Science 57, 2213-2227.
Bank for International Settlements (BIS) (2006): International Convergence of Capital Measurement and Capital Standards, Part 3, Basel Committee on Banking Supervision.
Bradley, P.S., Fayyad, U.M. (1998): Rening Initial Points for K-Means Clustering. Proceedings of the 15th International Conference on Machine Learning, 91- 99.
Carey, M. (2001): Some Evidence on the Consistency of Banks' Internal Credit Ratings. In: Credit Ratings: Methodologies, Rationale and Default Risk, Risk Books, London.
Carey, M., Hrycay, M. (2001): Parameterizing credit risk models with rating data. Journal of Banking and Finance 25, 197270.
Cassidy, C., Gizycki, M. (1997): Measuring traded market risk: Value-at-Risk and Backtesting Techniques. Discussion Paper, Reserve Bank of Australia, November 1997.
Chib, S., Nardari, F., Shephard, N. (2002): Markov chain Monte Carlo methods for stochastic volatility models. Journal of Econometrics 108, 281-316.
European Parliament and European Council (2006): Directive 2006/48/EC of 14 June 2006 relating to the taking up and pursuit of the business of credit institutions. Ocial Journal of the European Union 2006, L 177/1 - 197.
Frésard, L., Pérignon, C., Wilhelmsson, A. (2011): The pernicious eects of contaminated data in risk management. Journal of Banking & Finance 35, 2569-2583.
González, F. (2005): Bank regulation and risk-taking incentives: An international comparison of bank risk. Journal of Banking & Finance 29, 1153-1184.
Holthausen, R.W., Watts, R.L. (2001): The relevance of the value-relevance literature for nancial accounting standard setting. Journal of Accounting and Economics 31, 3-75.
Jacobson, T., Lindé, J., Roszbach, K. (2006): Internal ratings systems, implied credit risk and the consistency of banks' risk classication policies. Journal of Banking & Finance 30, 1899-1926.
29

Johannes, M.S., Polson, N., Stroud, J.R. (2009): Optimal Filtering of Jump Diusions: Extracting Latent States from Asset Prices. The Review of Financial Studies 22, 2559-2599. Moody's Investors Service (2011a): European Corporate Default and Recovery Rates, 1985 - 1H 2011 (Excel Supplement). Moody's Investors Service (2011b): Sovereign Default and Recovery Rates, 1983-2010. Special Comment. Pitt, M.K., Silva, R.S., Giordani, P., Kohn, R. (2010): Auxiliary particle ltering within adaptive Metropolis-Hastings sampling. Working Paper, University of Warwick, June 2010. Lucas, A. (2001): An evaluation of the Basle guidelines for backtesting banks' internal risk management models. Journal of Money, Credit and Banking 33, 826846. Omori, Y., Chib, S., Shephard, N., Nakajima, J. (2007): Stochastic volatility with leverage: Fast and ecient likelihood inference. Journal of Econometrics 140, 425-449. Pérignon, C., Deng, Z.Y., Wang, Z.J. (2008): Do banks overstate their Value-at-Risk? Journal of Banking & Finance 32, 783-794. Pérignon, C., Smith, D.R. (2010a): The level and quality of Value-at-Risk disclosure by commercial banks. Journal of Banking & Finance 34, 362-377. Pérignon/Smith (2010b): Diversication and Value-at-Risk. Journal of Banking & Finance 34, 55-66. Pitt, M., Shephard, N. (1999): Filtering via Simulation: Auxiliary Particle Filters. Journal of the American Statistical Association 94, 590-599. Roberts, G.O., Rosenthal, J.S. (2009): Examples of adaptive MCMC. Journal of Computational and Graphical Statistics 18, 349367. Wong, W.K. (2008): Backtesting trading risk of commercial banks using expected shortfall. Journal of Banking & Finance 32, 14041415.
30

SFB 649 Discussion Paper Series 2012
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "HMM in dynamic HAC models" by Wolfgang Karl Härdle, Ostap Okhrin and Weining Wang, January 2012.
002 "Dynamic Activity Analysis Model Based Win-Win Development Forecasting Under the Environmental Regulation in China" by Shiyi Chen and Wolfgang Karl Härdle, January 2012.
003 "A Donsker Theorem for Lévy Measures" by Richard Nickl and Markus Reiß, January 2012.
004 "Computational Statistics (Journal)" by Wolfgang Karl Härdle, Yuichi Mori and Jürgen Symanzik, January 2012.
005 "Implementing quotas in university admissions: An experimental analysis" by Sebastian Braun, Nadja Dwenger, Dorothea Kübler and Alexander Westkamp, January 2012.
006 "Quantile Regression in Risk Calibration" by Shih-Kang Chao, Wolfgang Karl Härdle and Weining Wang, January 2012.
007 "Total Work and Gender: Facts and Possible Explanations" by Michael Burda, Daniel S. Hamermesh and Philippe Weil, February 2012.
008 "Does Basel II Pillar 3 Risk Exposure Data help to Identify Risky Banks?" by Ralf Sabiwalsky, February 2012.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

