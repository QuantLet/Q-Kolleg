BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2011-073
Calibration of selfdecomposable LÈvy
models
Mathias Trabs*
* Humboldt-Universit‰t zu Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universit‰t zu Berlin Spandauer Straﬂe 1, D-10178 Berlin

Calibration of self-decomposable L¥evy models
Mathias Trabs
Institute for Mathematics, Humboldt-Universit®at zu Berlin, Germany, trabs@math.hu-berlin.de.
We study the nonparametric calibration of exponential, self-decomposable L¥evy models whose jump density can be characterized by the k-function, which is typically nonsmooth at zero. On the one hand the estimation of the drift, the activity measure  := k(0+) + k(0-) and analog parameters for the derivatives are considered and on the other hand we estimate the k-function outside of a neighborhood of zero. Minimax convergence rates are derived, which depend on . Therefore, we construct estimators adapting to this unknown parameter. Our estimation method is based on spectral representations of the observed option prices and on regularization by cutting off high frequencies. Finally, the procedure is applied to simulations and real data.
Keywords: adaptation, European option, infinite activity jump process, minimax rates, non linear inverse problem, self-decomposability. AMS Classification (2010): 60G51, 62G20, 91B25. JEL Classification: C14, G13.
1. Introduction
Since Merton [20] introduced his discontinuous asset price model, stock returns were frequently described by exponentials of L¥evy processes. A review of recent pricing and hedging results for these models is given by Tankov [25]. The calibration of the underlying model, that is in the case of L¥evy models the estimation of the characteristic triplet (, , ), from historical asset prices is mostly studied in parametric models only. Remarkable exceptions are the nonparametric penalized least squares method of Cont and Tankov [10] and the spectral calibration procedure of Belomestny and Reiﬂ [3]. Both articles concentrate on models of finite jump activity. Our goal is to extend their results to infinite intensity models. More precisely, we study pure-jump self-decomposable L¥evy processes. For instance, this class was considered in the hyperbolic model (Eberlein, Keller and Prause [11]) or the variance gamma model (Madan and Seneta [19]). Moreover, self-decomposable distributions are discussed in the financial investigation using Sato processes (Carr et al. [8], Eberlein and Madan [12]). Our results can be applied in this context, too. The nonparametric calibration of L¥evy models is not only relevant for stock prices, for instance, it can be used for the Libor market as well (see Belomestny and Schoenmakers [4]). In the context of Ornstein-Uhlenbeck processes, the nonparamet-
The author thanks Markus Reiﬂ and Jakob S®ohl for providing many helpful ideas and comments. The research was supported by the Collaborative Research Center 649 "Economic Risk" of the German Research Foundation (Deutsche Forschungsgemeinschaft).
1

2

ric inference of self-decomposable L¥evy processes was considered by Jongbloed, van der Meulen and van der Vaart [15].
The jump density of self-decomposable processes can be characterized by

k(x) (x) = |x| ,

x  R \ {0},

(1.1)

with a non-negative so-called k-function k : R \ {0}  R+ which increases on (-, 0) and decreases on (0, ). While the Blumenthal-Getoor index, which was estimated by Belomestny [1], is zeroin our model, the infinite activity can be described on a finer scale by the parameter
 := k(0+) + k(0-).
Since k is typically nonsmooth at zero, we face two estimation problems: Firstly, to give a proper description of k at zero, we propose estimators for  and its analogs for the derivatives k(j)(0+) + k(j)(0-), with j  1, as well as for the drift , which can be estimated similarly. We prove convergence rates for their mean squared error which turn out to be optimal in minimax sense up to a logarithmic factor that depends on the precise setup. Secondly, we estimate the shape of the k-function outside of a neighborhood of zero. To this end, we construct an explicit estimator of k whose mean integrated squared error on the set R \ [-,  ], for any  > 0, converges with nearly optimal rates.
Owing to bid-ask spreads and other market frictions, we observe only noisy option prices. The definition of the estimators is based on the relation between these prices and the characteristic function of the driving process established by Carr and Madan [6] and on different spectral representations of the characteristic exponent. Smoothing is done by cutting off all frequencies higher than a critical value depending on a maximal permitted parameter . The whole estimation procedure is computationally efficient and achieves good results in simulations and in real data examples.
All estimators converge with a polynomial rate, where the maximal  determines the ill-posedness of the problem. Assuming sub-Gaussian error distributions, we provide an estimator with -adaptive rates. The main tool for this result is a concentration inequality for our estimator ^ which might be of independent interest.
This work is organized as follows: In Section 2 we describe the setting of our estimation procedure and give some details about self-decomposable processes. Subsequently, we derive the necessary representations of the characteristic exponent in Section 3. The estimation procedure is described in Section 4, where we also determine the convergence rates of our estimators. The construction of the -adaptive estimator of  is contained in Section 5. In view of simulations we discuss our theoretical results and the implementation of the procedure in Section 6. Applying the proposed calibration to real data, we compare our method with the spectral calibration of Belomestny and Reiﬂ [3]. All proofs are given in Section 7.

3

2. The model

2.1. Self-decomposable L¥evy processes

A real valued random variable X has a self-decomposable law if for any b > 0 there is an

independent random variable Zb such that X =d bX + Zb. Since each self-decomposable

distribution µ is infinitely divisible (Sato [22, Prop. 15.5]), we can define the correspond-

ing self-decomposable L¥evy process as the L¥evy process whose law at unit time equals

µ.

Self-decomposable laws can be understood as the class of limit distributions of converg-

ing scaled sums of independent random variables [22, Thm. 15.3]. This characterization

is of economical interest. If we understand the price of an asset as an aggregate of small independent influences and release from the n scaling, which leads to diffusion models,

we automatically end up in a self-decomposable price process. Owing to the infinite ac-

tivity, the features of market prices can be reproduced even without a diffusion part (cf.

Carr et al. [7]). Examples of pure-jump and self-decomposable models for option pricing

are the variance gamma model, studied by Madan and Seneta [19] and Madan, Carr and

Chang [18], and the hyperbolic model introduced by Eberlein, Keller and Prause [11].

Sato [22, Cor. 15.11] shows that the jump measure of a self-decomposable distribution

is always absolutely continuous with respect to the Lebesgue measure and its density can

be characterized through equation (1.1). Note that self-decomposability does not affect

the volatility  nor the drift  of the L¥evy process.

Assuming  to be finite and  = 0, the process Xt has finite variation and the char-

acteristic function of XT is given by the L¥evy-Khintchine representation:

T (u) := E[eiuXT ] = exp

T

iu +

 |eiux - 1| k(x) dx - |x|

.

(2.1)

Motivated by a martingale argument, we will suppose the exponential moment condition E[eXt ] = 1 for all t  0, which yields

0 =  +  (ex - 1) k(x) dx. - |x|

(2.2)

In particular, we will impose

-(ex

-

1)

k(x) |x|

dx

<

.

In

this

case

T

is

defined

on

the

strip {z  C| Im z  [-1, 0]}.

Besides L¥evy processes there is another class that is closely related to self-decompos-

ability. Dropping the condition of stationary increments while retaining the other prop-

erties of L¥evy processes, we obtain so-called additive processes. An additive process (Yt) which is additionally self-similar, that means for all a > 0 it satisfies (Yat) =d (aH Yt), for some exponent H > 0, is called Sato process. Sato [21] showed that self-decomposable dis-

tributions can be characterized as the laws at unit time of self-similar additive processes.

From the self-similarity and self-decomposability follows for T > 0

YT (u) = E[eiuYT ] = E[eiT H uY1 ] = exp

iT H u +


(eiux
-

-

1)

k(T -H |x|

x)

dx

.

4

Since our estimation procedure only depends through equation (2.1) on the distributional

structure of the underlying process, we can apply the estimators directly to Sato processes

using

Ts = 1, s = T H , and ks(∑) = k(T -H ∑)

instead of T ,  and k in the case of L¥evy processes.
Going back to a L¥evy process (Xt), the parameter  captures many of its properties such as the smoothness of the densities of the marginal distributions [22, Thm. 28.4] and
the tail behavior of the characteristic function of a self-decomposable distribution. Since the stochastic error in our model is driven by |T (u-i)|-1, we prove the following lemma in the appendix.

Lemma 2.1. Let (Xt) be a self-decomposable L¥evy process with  = 0 and k-function k such that the martingale condition (2.2) is valid.
i) If exk(x) L1 <  then there exists a constant C = C(T, exk(x) L1 , ) > 0 such that for all u  R with |u|  1 we obtain the bound
|T (u - i)|  C|u|-T .
ii) Let Ø, R > 0 then the constant C(T, R, Ø) holds uniformly for all functions k with   Ø and exk(x) L1  R.

2.2. Asset prices and Vanilla options
Let r  0 be the riskless interest rate in the market and S0 > 0 denote the initial value of the asset. In an exponential L¥evy model the price process is given by
St = S0ert+Xt ,
where Xt is a L¥evy process described by the characteristic triplet (, , ). Throughout these notes, we assume Xt to be self-decomposable with  = 0 and  < . On the probability space (, F, P) with pricing (or martingale) measure P the discounted process (e-rtSt) is a martingale with respect to its natural filtration (Ft). This property is equivalent to E[eXt ] = 1 for all t  0 and thus, the martingale condition (2.2) holds.
At time t = 0 the risk neutral price of an European call option with underlying S, time to maturity T and strike price K is given by
C(K, T ) = e-rT E[(ST - K)+],
where A+ := max{0, A}. Similarly, an European put has the price P (K, T ) = e-rT E[(K- ST )+]. In terms of the negative log-forward moneyness x := log(K/S0) - rT the prices can be expressed as
C(x, T ) = S0E[(eXT - ex)+] and P(x, T ) = S0E[(ex - eXT )+].

5

Carr and Madan [6] introduced the option function

O(x) :=

S0-1C(x, T ), S0-1P(x, T ),

x  0, x<0

and set the Fourier transform FO(u) :=

 -

eiuxO(x)

dx

in

relation

to

the

characteristic

function T through the pricing formula

F O(u)

=

1

- T (u - u(u - i)

i) ,

u  R \ {0}.

(2.3)

The properties of O were studied further by Belomestny and Reiﬂ [3, Prop. 2.1]: At any

x  R \ {0} the function O is twice differentiable with

|O (x)| dx  3 and the first
R

derivative O has a jump of height -1 at zero. Additionally, they showed that Assumption 1

ensures an exponential decay of the option function, i.e. |O(x)| e-|x| holds for x  R.

Assumption 1. We assume that C2 := E[e2XT ] is finite, which is equivalent to the moment condition E[St2] < .

Our observations are given by

Oj = O(xj) + jj, j = 1, . . . , N,

(2.4)

where the noise (j) consists of independent, centered random variables with E[j2] = 1 and supj E[4j ] < . The noise levels j are assumed to be positive and known. In
practice, the uncertainty is due to market frictions such as bid-ask spreads.

3. Representation of the characteristic exponent

Using (2.1) and (2.3), the shifted characteristic exponent is given by

(u)

:=

1 T

log(1

+

iu(1

+

iu)F O(u))

=

1 T

log(T (u

-

i))

= iu +  +


(ei(u-i)x
-

-

1)

k(x) |x|

dx

(3.1) (3.2)

for u  R. Note that the last line equals zero for u = 0 because of the martingale

condition (2.2). Throughout, we choose a distinguished logarithm, that is a version of

the complex logarithm such that  is continuous with (0) = 0. On the assumption

 -

(1



ex)k(x) dx

<

1

we

can

apply

Fubini's

theorem

to

obtain

1
(u) = iu +  + i(u - i)F(sgn(x)k(x))((u - i)t) dt,
0
1We denote A  B := min{A, B} and A  B := max{A, B} for A, B  R.

(3.3)

6

where the Fourier transform F(sgn ∑k) is well-defined on {z  C| Im z  [-1, 0]}. Typically, the k-function and its derivatives are not continuous at zero. Moreover, for
all non-zero k the function x  sgn(x)k(x) has a jump at zero. Therefore, the Fourier transform decreases very slowly. Let k be smooth on R \ {0} and fulfill an integrability condition which will be important later:

Assumption 2. Assume k  Cs(R \ {0}) with all derivatives having a finite right- and left-hand limit at zero and (1  ex)k(x), . . . , (1  ex)k(s)  L1(R).

Our idea is to compensate those discontinuities by adding a linear combination of the

functions

hj (x) := xj e-x1[0,)(x),

x  R, j  N  {0}.

For j  1 it holds hj  Cj-1(R) and all hj are contained in C(R \ {0}). Hence, we can find j, j = 0, . . . , s - 2, such that

s-2
g(x) := sgn(x)k(x) - jhj(x)  Cs-2(R)  Cs(R \ {0}).
j=0

These coefficients are given recursively by the following formula, which can be proved by straight forward calculations. We omit the details.

Lemma 3.1. Grant Assumption 2. The factors j, j = 0, . . . s - 2, satisfying g  Cs-2(R)  Cs(R \ {0}), can be calculated via

1 j = j!

k(j)(0+) + k(j)(0-)

-

j

(-1)m m! j-m,

m=1

especially 0 =  holds.

Hence, the Fourier transform in (3.3) can be written as F(sgn ∑k)(z) = Fg(z) +

s-2 j=0

jF hj(z),

where

integration

by

parts

yields

F hj(v - ti) =


ei(v+i(1-t))xxj
0

dx

=

j! (1 - t - iv)j+1 ,

v  R, t  [0, 1),

and |F g(u)| decreases as |u|-s because of the smoothness of g. From these preparations

we derive a representation of  which allows us to estimate  and 0, . . . s-2. A plug-in approach yields estimators for k(j)(0+) + k(j)(0-), j = 0, . . . , s - 2, using Lemma 3.1.

Since we only apply this representation when  is multiplied with weight functions having

roots of degree s - 1 at zero, the poles that appear in (3.4) do no harm.

Proposition 3.2. Let s  2. On Assumption 2 there exist functions D : {-1, 1}  C and  : R \ {0}  C such that |us-1(u)| is bounded in u and it holds

(u)

=

s-2
D(sgn(u)) + iu - 0 log(|u|) +

ij (j

- 1)!j uj

+ (u),

u = 0,

j=1

(3.4)

7

From the proof in Section 7.1 we deduce the form of the mapping D : {-1, 1}  C:

D(±1)

=





 i
2

-

s-2
(j

-

1)!j

+


g(x) ex/2 - 1 dx ± i F (ex/2g(x))(±v) dv. x

j=1

-

0

Proposition 3.2 covers the case s  2. For s = 1 we conclude from (3.2) and the martingale condition (2.2)

(u) = iu +


(eiux
-

-

1)ex

k(x) |x|

dx

=

iu

+

i

u
F
0

sgn(x)exk(x) (v) dv,

(3.5)

where the last equation follows from Fubini's theorem on the condition

 -

exk(x)

dx

<

, which is implied by Assumption 2. Hence,  is a sum of a constant from the integra-

tion, the linear drift iu and a remainder of order log |u|, which follows from the decay of the Fourier transform as |u|-1 (cf. Lemma 7.1). One can even show Corollary B.6 that

there exists no L2-consistent estimator of  for s = 1. Therefore, we concentrate on the

case s  2 in the sequel.

Equation (3.5) allows another useful observation. Defining the exponentially scaled

k-function

ke(x) := sgn(x)exk(x), x  R,

we obtain by differentiation



(u)

=

1 T

(i - 2u)F O(u) - (u + iu2)F xO(x) 1 + (iu - u2)F O(u)

(u)

=

i

+ iF ke(u).

(3.6)

Using this relation, we can define an estimator of ke.

4. Estimation procedure

4.1. Definition of the estimators and weight functions

Given the observations {(x1, O1), . . . , (xN , ON )}, we fit a function O~ to these data using linear B-splines

bj (x)

:=

x xj

- xj-1 - xj-1

1[xj-1

,xj

)

+

xj+1 xj+1

-x - xj

1[xj

,xj+1

]

,

j = 1, . . . , N,

and a function 0 with 0(0+) - 0(0-) = -1 to take care of the jump of O :

N
O~(x) = 0(x) + Ojbj(x), x  R.
j=1

8

We choose 0 with support [xj0-1, xj0 ] where j0 satisfies xj0-1 < 0  xj0 . Replacing O with O~ in the representations (3.1) and (3.6) of  and  , respectively, allows us to define
their empirical versions through

~(u) := 1 log T

v(u)(1 + iu(1 + iu)F O~(u))

,

~ (u)

:=

1 T

(i - 2u)F O~(u) - (u + iu2)F xO~(x) v(u)(1 + iu(1 + iu)F O~(u))

(u) ,

u  R,

where  is a positive function and we apply a trimming function given by

v(z) : C \ {0}  C,

z

z, z/|z|,

|z|  , |z| < 

to stabilize for large stochastic errors. A reasonable choice of  will be derived below. The function ~ is well-defined on the interval [-U, U ] on the event
A := {   : 1 + iu(1 + iu)F(O~(, ∑))(u) = 0 u  [-U, U ]}  .
For    \ A we set ~ arbitrarily, for instance equal to zero. The more O~ concentrates around the true function O the greater is the probability of A. So®hl [23] shows even that in the continuous-time L¥evy model with finite jump activity the identity P(A) = 1 holds.
In the spirit of Belomestny and Reiﬂ [3] we estimate the parameters  and j, j = 0, . . . s - 2, as coefficients of the different powers of u in equation (3.4). Using a spectral cut-off value U > 0, we define
U
^ := Im(~(u))wU (u) du
-U

and for 0  j  s - 2

U

     

Re(~(u))wUj (u) du,
-U

^j :=

     

U
Im(~(u))wUj (u) du,

-U

if j is even, otherwise.

Owing to (3.6), the nonparametric object ke can be estimated by

k^e(x) := F -1

- ^ - i~ (u)

u wk( U )

(x),

x  R.

The weight functions wU and wUj are chosen such that they filter the coefficients of interest. Moreover, wk should decrease fast in the spatial domain and should cut off high
frequencies:

9

Assumption 3. We assume: ∑ wU fulfills for all odd j  {1, . . . , s - 2}

U
uwU (u) du = 1,
-U

U
u-jwU (u) du = 0 and
-U

U
wU (±u) du = 0.
0

∑ wU0 satisfies for all even j  {1, . . . , s - 2}

U
log(|u|)wU0 (u) du = -1,
-U

UU

u-j wU0 (u) du = 0 and

wU0 (±u) du = 0.

-U 0

∑ For j = 1, . . . , s - 2 the weight functions wUj fulfill

U
u-j wUj (u) du =
-U

(-1) j/2 (j - 1)!

,

U
u-lwUj (u) du = 0 and
-U

U
wUj (±u) du = 0,
0

where 1  l  s - 2 and l is even for even j and odd otherwise. For even j we

impose additionally

U
log(|u|)wUj (u) du = 0.
-U

∑ wk is contained in Cm(R) for some m  2s + 1 and satisfies supp wk  [-1, 1] as well as wk  1 on (-ak, ak) for some ak  (0, 1).

Furthermore, we assume continuity and boundedness of the functions u  u-s+1wq1(u) for q  {, 0, . . . , s-2}.

The integral conditions can be provided by rescaling: Let wq1 satisfy Assumption 3 for

q  {, 0, . . . , s-2} and U = 1. Since 1 =

1 -1

uw1 (u)

du

=

U -U

uU -2w1(u/U ) du,

we

can

choose

wU (u)

:=

U

-2w1

(

u U

).

Similarly,

a

rescaling

is

possible

for

wU0 :

-1 = =

1
log(|u|)w1 0 (u) du =
-1

U -U

log(|u|)U

-1

w1 0

(

u U

)

du

-

log(U ) U

U -U

log(|u|)U

-1

w1 0

(

u U

)

du.

U -U

w1 0

(

u U

)

du

Therefore,

we

define

wU0 (u)

:=

U

-1

w1 0

(

u U

)

and

analogously

wUj (u)

:=

U

j

-1

w1 j

(

u U

).

The continuity condition in Assumption 3 is set to take advantage of the decay of the

remainder . In connection with the rescaling it implies

|wU (u)| U -s-1|u|s-1 and |wUj (u)| U -s+j |u|s-1, j = 0, . . . , s - 2.

(4.1)

In the sequel we assume that the weight functions satisfy Assumption 3 and the property (4.1).

10

4.2. Convergence rates

To ensure a well-defined procedure, an exponential decay of O, the identity (3.5) and to
obtain a lower bound of |T (u - i)|, we consider the class G0(R, Ø). Uniform convergence results for the parameters will be derived in the smoothness class Gs(R, Ø).

Definition 4.1. Let s  N and R, Ø > 0. We define
i) G0(R, Ø) as the set of all pairs P = (, k) where k is a k-function and the corresponding L¥evy process X given by the triplet (0, , k(x)/|x|) satisfies Assumption 1 with C2  R, martingale condition (2.2) as well as
  [0, Ø] and ke  R,
ii) Gs(R, Ø) as the set of all pairs P = (, k)  G0(R, Ø) satisfying addionally Assumption 2 with
|k(l)(0+) + k(l)(0-)|  R, for l = 1, . . . , s - 1, (1  ex)k(l)(x) L1  R, for l = 0, . . . , s.

In the class G0(R, Ø) Lemma 2.1 ii) provides a common lower bound of |T (u - i)| for

|u|



1.

Using

maxxR

1-cos(x) x



(0, 1],

we

estimate

roughly

for

u



(-1, 1)

\

{0}:

|T (u - i)| = exp

T



(cos(ux)

-

exk(x) 1)

dx

- x

 exp - T  ex/|u|k( x ) dx  exp - |u|

-TR .

Hence, the choice

(u) := Ø(u) :=

1 3

e-T

R

,

1 3

C(T

,

R,

Ø)|u|-T

Ø ,

|u| < 1, |u|  1,

satisfies

1 3

|T

(u

-

i)|



(u),

u  R,

(4.2)

where the factor 1/3 is used for technical reasons. As discussed above, we can restrict

our investigation to the case s  2.

Since the L¥evy process is only identifiable if O is known on the whole real line, we

consider asymptotics of a growing number of observations with

 := max (xj - xj-1)  0 and A := min(xN , -x1)  .
j=2,...,N
Taking into account the numerical interpolation error and the stochastic error, we analyze the risk of the estimators in terms of the abstract noise level
 := 3/2 + 1/2  l .

11

Theorem 4.2. Let s  2, R, Ø > 0 and assume e-A

2

and





2 l2



2 l

.

We

choose the cut-off value UØ := -2/(2s+2T Ø+1) to obtain the uniform convergence rates

sup EP [|^ - |2]1/2 2s/(2s+2T Ø+1) and
P =( ,k)Gs (R,Ø )

sup EP [|^j - j |2]1/2 2(s-1-j)/(2s+2T Ø+1), j = 0, . . . , s - 2.
P =( ,k)Gs (R,Ø )

As one may expect the rates for j, j = 0, . . . , s - 2, become slower as j gets closer to its maximal value because the profit from the smoothness of k decreases. Note that the cut-off for all estimators is the same.

Remark 4.3.

The

proof

in

Section

7.2

reveals

that

the

condition





2 l2



2 l

is

only used to estimate the remainder term. In the case s  3 our bound is not strict and

we can replace the constraint by the weaker one

r



2 l2



4-2r l

for some r 

3s + 2T Ø - 1 1, .

2s + 2T Ø + 1

In this setting j can be bounded away from 0 if A increases slowly enough whereas for

r = 1 the noise j

must tend to 0 for xj

 ±. Otherwise 



2 l2

could not be bounded

because

of

N



2A N

N



.

For





(0,

1 2

)

we

study

the

loss

of

the

exponentially

scaled

k-function

ke

in

the

norm

ke L2, :=

1/2
|ke(x)|2 dx .
R\[-, ]

In contrast to Gs(R, Ø) we assume Sobolev conditions on ke in the class Hs(R, Ø) in order to apply L2-Fourier analysis.

Definition 4.4. Let s  N and R, Ø > 0. We define Hs(R, Ø) as the set of all pairs P = (, k)  G0(R, Ø) satisfying additionally k  Cs(R \ {0}), EP [|XT eXT |]  R for corresponding L¥evy process X as well as
||  R, and ke(l) L2  R, for l = 0, . . . , s.

In the next theorem the conditions on A and  are stronger than for the upper bounds of the parameters which is due to the necessity to estimate also the derivative of . However, the estimation of  does not lead to a loss in the rate.

Theorem 4.5.

Let

s



1, R, Ø

>

0, 



(0,

1 2

)

and

assume

Ae-A

2 and (

j

2 l2

+

2

(xj j )j

2 l2

)



2 l

.

We

choose

the

cut-off

value

UØ

:=

-2/(2s+2T Ø+5).

Then

we

obtain for the risk of k^e the uniform convergence rate

sup

EP [

k^e - ke

2 L2

,

]1/2

P =( ,k)Hs (R,Ø )

2s/(2s+2T Ø+5).

Remark 4.6. The convergence rates in the Theorems 4.2 and 4.5 are minimax optimal up to a logrithmic factor, which is shown in Appendix B and C.

12
5. Adaptation

The convergence rate of our estimation procedure depends on the bound Ø of the true but unknown   R+. Therefore, we construct an -adaptive estimator. For simplicity we concentrate on the estimation of  itself whereas the results can be easily extended to , j, j = 1, . . . , s - 2, and ke. In this section we will require the following

Assumption 4. Let R > 0, s  2 and   [0, Ø] for some maximal Ø > 0. Furthermore,

we suppose e-A

2

and 



2 l2



2 l

.

These conditions only recall the setting in which the convergence rates of our parameter estimators were proven. Given a consistent preestimator ^pre of , let ~0 be the estimator using the data-driven cut-off value and the trimming parameter

U~ := U^pre := -2/(2s+2T ^pre+1) and

~(u) := Øpre (u) :=

1 2

e-T

R

,

|u| < 1,

1 2

CØpre

|u|-T

Øpre

,

|u|  1,

(5.1) (5.2)

respectively, with Øpre := ^pre + | log |-1. If ^pre is sufficiently concentrated around the true value, the adaptation does not lead to losses in the rate as the following proposition shows. Note that the condition ~0  [0, Ø] is not restrictive since any estimator ^ of   [0, Ø] can be improved by using (0  ^)  Ø instead.

Proposition 5.1. On Assumption 4 let ^pre be a consistent estimator which is independent of the data Oj, j = 1, . . . , N, and fulfills for   0 the inequality

P(|^pre - |  | log |-1)  d2

(5.3)

with a constant d  (0, ). Furthermore, we suppose ~0  [0, Ø] almost surely. Then ~0 satisfies the asymptotic risk bound

sup EP,^pre [|~0 - |2]1/2
P Gs (R,)

2(s-1)/(2s+2T +1)

where the expectation is taken with respect to the common distribution PP,^pre of the observations O1, . . . , ON and the preestimator ^pre .

To use ^0 on an independent sample as preestimator, we establish a concentration
result for the proposed procedure. Therefor, we require (j) to be uniformly sub-Gaussian (see e.g. van de Geer [27]). That means there are constants C1, C2  (0, ) such that the following concentration inequality holds for all t, N > 0 and a1, . . . aN  R

P

N
ajj  t  C1 exp - C2
j=1

t2

N j=1

aj2

.

(5.4)

13

Proposition 5.2. Additionally to Assumption 4 let (j) be uniformly sub-Gaussian fulfilling (5.4). Then there is a constant c > 0 and for all  > 0 there is an 0  (2s+2T Ø+1)/(2s-2), such that for all  < 0  1 the estimator ^0 satisfies
P(|^0 - |  )  ((7N + 1)C1 + 2) exp - c(2  1/2)-(s-1)/(2s+2T Ø+1) . (5.5)

Concentration (5.5) is stronger than in Proposition 5.1 needed. To apply the proposed

estimation procedure, let Spre and S be two independent samples with noise levels pre

and  as well as sample sizes Npre and N , respectively. Using Spre for the estimator
^pre, we construct adaptively ~0 on S. We suppose Npre grows at most polynomial in pre, that is Npre -prpe holds for some p > 0. This is fulfilled for polynomially strike distributions with a logarithmically growing domain as considered in Appendix B . To

satisfy (5.3), it is sufficient if there exists a power q > 0, which can be arbitrary small,

such that pre  q owing to the exponential inequality (5.5). Using 2 AN /N  1/N ,

we estimate

Npre N

p-rpe2  2-pq  0

for q < 2/p. Thus, relatively to all available data the necessary number of observations for the preestimator tends to zero.

6. Discussion and application
6.1. Numerical example
We apply the proposed estimation procedure to the variance gamma model (see [18]). In view of the empirical study of Madan, Carr and Chang [18] we choose the parameters   {0.05, 0.1, 0.2, 0.5},  = 1.2 and  = -0.15. The value of  is then given by the martingale condition (2.2):
 = 1 log(1 -  - 2/2). 
According to the different choices of , we set Ø = 40 as maximal value of . The deterministic design of the sample {x1, . . . , xN } is distributed normally with mean
zero and variance 1/3. The observations Oj are computed from the characteristic function T using the fast Fourier transform method of Carr and Madan [6]. The additive noise consists of normal centered random variables with variance |O(xj)|2 for some  > 0.
We estimate q  {, 0, 1, 2, ke}. Hence, we need s  4 (see Corollary B.6 ). We used maturity T = 0.25, interest r = 0.06, smoothness s = 6, sample size N = 100 and noise level  = 0.01, which generates values of  on average 0.168. The results of our Monte Carlo simulations are summarized in Tables 1 and 2.
In order to apply the estimation procedure, we need to choose the tuning parameters. Owing to the typically unknown smoothness s, let the weight functions satisfy Assumption 3 for some large value smax. The weights for the parameters can be chosen

14

 E[|^0 - |2]1/2 E[|~0 - |2]1/2

40 20.7998 20 5.8362 10 1.0505
4 0.1729

23.3589 7.7724 2.4534 1.1158

Table 1. 1000 Monte Carlo simulation of the variance gamma model with N = 100,  = 0.01 and   {0.05, 0.1, 0.2, 0.5}.

q

E[|q^ - q|2]1/2

E[|q~ - q|2]1/2



0.1408

0.0065

0 10.0000

1.0505

1 -94.1667

34.5066

2 4458.1250 1203.1827

0.0126 2.4534 85.9605 2741.7031

q

1/2 L2

E[

K^ - q

2 L2

]1/2

E[

q~ - q

2 L2

]1/2

ke 0.9556 0.3289

0.3368

Table 2. 1000 Monte Carlo simulations of the variance gamma model with N = 100,  = 0.01 and  = 0.2.

polynomial whereas a flat-top kernel function can be used as wk, as done by Belomestny [2]. The trimming parameter  is included mainly for theoretical reasons and is not important to the implementation. The most crucial point is the choice of the cut-off value U . For q^ we implement the oracle method U = argminV 0 |q^(V ) - q| and an adaptive estimator q~ based on the construction of Section 5. The sample size for the preestimator is chosen Npre = 25. This adaptation to  is a first step to a data-driven procedure and should be developed further.
6.2. Discussion
The rates show that the studied estimation problem is (mildly) ill-posed compared with classical nonparametric regression models. In order to understand the convergence rate of the estimators for  and j better, we rewrite equation (3.6) in the distributional sense, denoting the Dirac distribution at zero by 0, and differentiate representation (3.4)
s-2
 (u) = F i0 + ike (u) = i - ijj!ju-j-1 +  (u), u  R \ {0}.
j=0
Hence,  can be seen as Fourier transform of an s-times weakly differentiable function and estimating  from noisy observations of  corresponds to a nonparametric regression with regularity s. Since dividing by u on the right-hand side of the above equation corresponds to taking the derivative in the spatial domain, the estimation of j is similar to the estimation of the (j + 1)th derivative in a regression model. The convergence rate of ke is in line with the results of Belomestny and Reiﬂ [3] for  = 0. Outside a

15

neighborhood of zero estimating the k-function amounts to estimating the jump density
itself so that their rates equals ours in the case  = 0. For k^e(x) with x different zero the degree of ill-posedness is given by T  + 2. This can
be seen analytically by observing that the noise is governed by u2|T (u - i)|-1, which grows with rate T +2. From a statistical point of view a higher value of  leads to a more
active L¥evy process and hence, it is harder to distinguish the small jumps of the process
from the additive noise. The influence of the time to maturity T on the convergence rates
is an interesting deviation from the analysis of Belomestny and Reiﬂ [3]. The simulation
shown in Table 1 demonstrates the improvement of the estimation for small the values
of . The proposed estimator k^e does not take into account the shape restrictions of the k-
function. Therefore, it can be understood as estimator of the function |x|(x) for arbitrary
absolutely continuous L¥evy measures. Thus, the estimation procedure can be applied to
exponential L¥evy models with Blumenthal-Getoor index larger than zero, for example
tempered stable processes. However, the behavior of the L¥evy density at zero needs
different methods in these cases and should be studied further. For instance, Belomestny
[1] discusses the estimation of the fractional order for regular L¥evy models of exponential
type. In the self-decomposable framework we reduce the loss of k^e by truncating positive
values on R- and negative ones on R+. The monotonicity can be generated by a rearrangement of the function. Chernozhukov, Ferna¥ndez-Val and Galichon [9] show that
the rearrangement reduces weakly the error for increasing target functions on compact
subsets. This result carries over to our estimation problem, where ke is decreasing and we restrict its support to a possibly large interval.
To calibrate the self-decomposable model completely, we combine the estimator k^e, which works away from zero asymptotically optimal, and the estimators ^j, j  0, which provide a proper description of the true k-function at zero. Using only ^0 and ^1, this can be done as follows: Choosing some  > 0, we take the estimation of k^e(x) for |x|   and extend it continuously with linear functions on (-,  ) such that the result fits to
^j, j = 1, 2. We define the combined estimator as

 m-

(x

+



)

+

k^e(-

),

K^

(x)

:=

 m+(x

-



)

+

k^e(

),

k^e(x),

- < x < 0, 0  x < , |x|  

where m± are uniquely given by the conditions ^0 = K^ (0+) - K^ (0-) and 2^0 + ^1 = K^ (0+) - K^ (0-).

Since k is monoton, we force m±  0, which might lead to a violation of the second equation for large stochastic errors. Table 2 contains simulation results for the estima-
tors q^ and q~, q  {, 0, 1, 2, ke}, corresponding to oracle and -adaptive cut-off values, respectively. The optimal combination of estimators ^j and k^e should be developed further, for instance an exponential Taylor expansion could be used. However, taking ^j

16

T r Npre N
~ ~0 ~1 ~2

0.314 0.045
20 81
0.109 24.850 -59.595 9319.844

0.567 0.044
21 85
0.506 29.846 256.049 7570.380

Table 3.. Estimation based on ODAX from 29 May 2008.
Figure 1. Given ODAX data points from 29 May 2008 with T = 0.314 and the option function generated from the estimated model.

for higher j into account leads to a loss in the convergence rate and it is actually not clear how to decompose the estimators into the left and right limits of the derivatives of k. Assuming finite right- and left-hand limits of k and its derivatives at zero, one-sided kernels might estimate the k-function even in the neighborhood of zero optimally.
Even if the practitioner prefers specific parametric models that might achieve smaller errors and faster rates, the nonparametric method should be used as a goodness-of-fit test against model misspecification. This issue makes progress through study of confidence sets in the framework of L¥evy processes with finite activity done by S®ohl [24] and it would be interesting to derive confidence intervals for .
6.3. Real data example
We apply our estimation method to a data set from the Deutsche Bo®rse database Eurex2. It consists of settlement prices of put and call options on the DAX index with three and six months to maturity from 29 May 2008. The sample sizes are 101 and 106, respectively. The interest rate is chosen such that the put-call parity holds as best as possible for all pairs of put and call options with the same strike and maturity. The subsample for the preestimator consists of every fifth strike while the main estimation is done from the remaining data points. By a rule of thumb the bid-ask spread is chosen as 1% of the option prices. Therefore, we get noise levels  with values 0.0138 and 0.069 for the two maturities, respectively. Table 3 shows the result of the proposed method. The estimations of ke are presented in Figure 2, which show k^e without rearrangement as well as the estimated k-function which results from K^ . In Figure 1 the calibrated model is used to generate the option function in the case of three months to maturity, where the data points used for the preestimator are marked with triangles in the figure.
2provided through the Collaborative Research Center 649 "Economic Risk"

17
Figure 2. Estimation of ODAX data from 29 May 2008 with three (top) and six (bottom) months maturity. Left: Estimated function k^e. Right: Estimation of the k-function using K^ .
Finally, we compare the outcome of our estimation procedure with the spectral calibration of Belomestny and Reiﬂ [3], where the cut-off value is chosen by the penalized least squares criterion. The estimation results of the latter method applied to the same data set are presented in Table 4. We obtain that the higher  in the selfdecomposable model corresponds to a higher  in the L¥evy model with finite jump activity. The parameter  is even smaller for T = 0.567.
7. Proofs
7.1. Proof of Proposition 3.2
Standard Fourier analysis yields the decay of |Fg(u)|: Lemma 7.1. Let f  Cs-2(R)  Cs(R \ {0}) for s  2 and f  C1(R \ {0}) in case of s = 1, respectively. Furthermore, we assume finite left- and right-hand limits of f (s-1) and f (s) at zero and f (0), . . . , f (s)  L1(R). Then we obtain
|F f (u)| |u|-s for |u|  .

18
T 0.314 0.567 r 0.045 0.044 N 101 106
~ 0.112 0.127 ~ 0.160 0.100 ~ 1.381 0.546 Table 4. Estimation based on ODAX from 29 May 2008.

Especially, on Assumption 2 there is a constant Cg > 0 independent from t and u such

that

|F g(v - it)|  Cg|v|-s

for

t



[0,

1)

and

|v|



1 .

2

Proof. Part 1: Since f  Cs-2(R) has a piecewise continuous (s - 1)th derivative and all derivatives are in L1(R), standard Fourier analysis yields
F (f (s-1))(u) = (-iu)s-1F f (u).

Therefore, it is enough to show for f  C1(R \ {0}) with f, f  L1(R) that |F f (u)|  C|u|-1, |u|  1, where C > 0 does not depend on u. The integrability of f ensures the
existence of the limits of f for x  ±. Since f itself is absolutely integrable, those limits equal 0. Integration by parts applied to the piecewise C1-function verifies for u = 0:

|Ff (u)| =

0
eiuxf (x) dx +


eiuxf (x) dx

=

1 |f (0-) - f (0+) - F(f )(u)|

-

0

|u|



1 |u|

(|f (0-)

-

f (0+)|

+

f

L1 ) .

Part

2:

From

Part

1

and

the

Leibniz

rule

follow

for

t



[0, 1)

and

|v|



1 2

|Fg(v - it)|

1 = |v|s

F

 s-1 xs-1

etxg(x)

(v) g(s-1)(0-) - g(s-1)(0+) - F

s xs

etxg(x)

(v)



1 |v|s

s-1
F

etxg(l)(x)

(v)

l=0

s

g(s-1)(0-) - g(s-1)(0+) +

F etxg(l)(x) (v) .

l=0

Hence, it remains to bound |F

etxg(l)(x)

(v)| uniformly over t  [0, 1) and |v| 

1 2

,

where l = 0, . . . , s. For each j = 0, . . . s - 2 and l = 0, . . . s there is a linear combination

j

h(jl)(x) =

m(j,l)hm(x) with m(j,l)  R, m = 0, . . . , j. Thus, we can find j(l)  R, j =

m=0

0, . . . s - 2, such that the derivatives of g are given by

s-2
g(l)(x) = sgn(x)k(l)(x) + jj(l)hj(x), x  R \ {0}, l = 0, . . . , s.
j=0

19

Therefore,

we

obtain

for

all

t



[0, 1),

|v|



1 2

and

l

=

0, . . . , s

s-2
F etxg(l)(x) (v) = F sgn(x)etxk(l)(x) (v) + j j(l)F etxhj (x) (v)
j=0



(1  ex)k(l)(x)

L1

+

s-2

|1

j!|j j(l)| - t - iv|j+1

j=0

s-2
 (1  ex)k(l)(x) L1 + 2(j+1)j!|j j(l)|.
j=0

With this lemma at hand the representation (3.4) can be proved as follows: Owing to the symmetry (-u) = (u), u  R, it is sufficient to consider the case u > 0. We recall representation (3.3) of :

1
(u) = iu +  + i(u - i)F(sgn ∑k) ((u - i)t) dt.
0

To

develop

this

integral

further

we

consider

for





(0,

1 2

)

1-

 (u) :=

i(u - i)F(sgn ∑k) ((u - i)t) dt

0

s-2 1-

1-

=

i(u - i)jF hj((u - i)t) dt +

i(u - i)Fg((u - i)t) dt

j=0 0

0

=

-

s-2
(j

-

1)!j

-

0

log(

-

iu(1

-

 ))

+

s-2

(

(j - 1)!j - iu(1 -  ))j

j=1

j=1

1-
+ i(u - i)Fg((u - i)t) dt
0

To

calculate

the

last

integral

we

split

its

domain

in

[0,

1 2

]

and

(

1 2

,

1

-

 ].

By

assumption

and

choice

of

hj

we

obtain

|ei(u-i)txg(x)|



|(1  ex/2)g(x)|



L1,

for

0



t



1 2

,

and

thus, we can apply Fubini's theorem to the first part:

1/2  1/2

i(u - i)Fg((u - i)t) dt =

g(x)

i(u - i)ei(u-i)tx dt dx.

0

-

0

Since z  eizx is holomorphic, Cauchy's integral theorem yields

1/2

(u-i)/2

-i/2

(u-i)/2

i(u - i)ei(u-i)tx dt =

ieizx dz =

ieizx dz +

ieizx dz.

0 0 0 -i/2

20

Hence,

1/2 
i(u - i)Fg((u - i)t) dt = g(x)
0 -

1/2 u/2

etx dt +

ieivx+x/2 dv dx.

00

Another application of Fubini's theorem to the second term shows

1/2

i(u - i)Fg((u - i)t) dt

0

=

 ex/2 - 1 g(x) dx + i


F (ex/2g(x))(v) dv - i


F (ex/2g(x))(v) dv.

- x

0

u/2

(7.1)

The first two summands are independent from u whereas we can use Lemma 7.1 to estimate the last integral for u  1:


F (ex/2g(x))(v) dv  Cg
u/2

 |v|-s dv = 2s-1Cg |u|-s+1. u/2 s - 1

(7.2)

Also

the

integral

over

(

1 2

,

1

-



]

can

be

estimated

using

Lemma

7.1.

For

all





(0,

1 2

)

and for all u  1 we obtain uniformly:

1-

1

i(u - i)F g((u - i)t) dt  Cg|(u - i)u-s| t-s dt  |u|-s+1.

1/2 1/2

(7.3)

Thus, (7.1) yields

s-2
 (u) = - (j - 1)!j +
j=1

 ex/2 - 1 g(x) dx + i
- x


F (ex/2g(x))(v) dv
0

-

0

log(

- iu(1 -

 )) +

s-2

(

(j - 1)!j - iu(1 -  ))j

+

 (u)

j=1

(7.4)

with

 1-

 (u) : = -i F (ex/2g(x))(v) dv +

i(u - i)Fg((u - i)t) dt

u/2 1/2

 1-

= -i F (ex/2g(x))(v) dv +

i(u - i) F(sgn ∑k)((u - i)t)

u/2 1/2

s-2
-

j!j

(1 - i(u - i)t)j+1

dt.

j=0

(7.5)

Plugging the estimates (7.2) and (7.3) into equation (7.5), we obtain | (u)| |u|-s+1 uniformly over  > 0 and u  1.

21
For u > 0 there exists (u) := lim0  (u) because F (sgn ∑k) is defined on {z  C| Im(z)  [-1, 0]} and is continuous on its domain whereas the integral over the sum can be computed explicitly. Then the bound |u|-s+1 holds for (u), |u|  1, too. Also for small u  (0, 1) the term |us-1(u)| remains bounded since  has a pole at 0 of maximal order s - 2. Since all terms in (7.4) are continuous in  at 0 this equation is true for  = 0. Finally, we notice log(-iu) = log(| - iu|) + i arg(-iu) = log(|u|) - i/2 and insert (7.4) in (3.3).

7.2. Proof of the upper bounds

Let us recall some results of Belomestny and Reiﬂ [3]: Because of the B-spline interpo-

lation we obtain Ol(x) := E[O~(x)] =

N j=1

O(xj )bj (x)

+

0(x), x



R.

Furthermore,

the

decomposition of the stochastic error ~ -  in a linearization L and a remainder R,

L(u) := T -1T (u - i)-1(i - u)uF (O~ - O)(u), R(u) := ~(u) - (u) - L(u),

u  R, has the following properties:

Proposition 7.2. i) Under the hypothesis e-A 2 we obtain uniformly over all L¥evy triplets satisfying Assumption 1

sup |E[F O~(u) - F O(u)]| = sup |F Ol(u) - F O(u)| 2.

uR

uR

ii) If the function  : R  R+ satisfies (4.2) then for all u  R the remainder is
bounded by |R(u)|  T -1(u)-2(u4 + u2)|F (O~ - O)(u)|2.

Upper bound for  and j (Theorem 4.2):
Since Theorem 4.2 can be proven analogously to Theorem 4.2 of Belomestny and Reiﬂ [3], we only sketch the main steps. Note that in Gs(R, Ø) we can bound uniformly the constant Cg from Lemma 7.1. Let us consider  first. The definition of ^ and wU , the decomposition of ~ and representation (3.4) yield

UU
^ = Im(~(u))wU (u) du =  + Im((u) + L(u) + R(u))wU (u) du.
-U -U
Hence, we obtain

U2

E[|^ - |2]  3

(u)wU (u) du + 3E

-U

U2
L(u)wU (u) du
-U

+ 3E

U2
R(u)wU (u) du ,
-U

22

where all three summands can be estimated separately. The first one is a deterministic

error term. It can be estimated using the decay of (u) and the weight function property

(4.1):

U
(u)wU (u) du
-U

U
U -(s+1)|(u)us-1| du
-U

U -s.

A bias-variance decomposition, with the definition Var(Z) := E[|Z - E[Z]|2], of the linear

error term yields

E

U2
L(u)wU (u) du =
-U

U -U

T

(i - u)u T (u - i)

E[F

(O~

- O)(u)]wU (u) du

2

+ Var

U -U

T

(i - u)u T (u - i)

F

O~(u)wU

(u)

du

=: Lb2 + Lv.

Using the approximation result in Proposition 7.2, the bound of |T (u - i)|-1 given by -1 and property (4.1), we infer the estimate of the bias term:

U

|Lb| 2U -(s+1)

|T (u - i)|-1|u|s+1 du 2U T Ø+1.

-U

For the variance part we make use of the properties of the the linear spline functions bk as well as supp(wU )  [-U, U ] and the independence of (k). We estimate (Cov(Y, Z) :=
E[(Y - E[Y ])(Z - E[Z])]) as in [3]:

Lv =

U -U

U
Cov
-U

(i - u)u FO~(u), (i - v)v FO~(v)

T T (u - i)

T T (v - i)

wU (u)wU (v) du dv

N
= k2
k=1

U -U

T

(i - u)u T (u - i)

F

bk

(u)wU

(u)

du

2





2 l

U

2T

Ø+1

.

To estimate the remaining term R, we use Proposition 7.2, the property (4.1) of wU and the choice of . In addition the independence of (k) and the uniform bound of their
fourth moments comes into play.

U2
E R(u)wU (u) du
-U

UU -U -U

F (Ol - O)

4 

+

E

F (O~ - Ol)(u)F (O~ - Ol)(v) 2

u4wU (u)v4wU (u)2(v)2

(v)

du

dv

4

U -U

u4wU (u) (u)2

du

2
+

U -U

N k=1

k2|F bk(u)|2

u4wU (u) (u)2

du

2

U2

U2

4U -(s+1)

(u)-2|u|s+3 du

+

2



2 l2

U

-(s+1)

(u)-2|u|s+3 du

-U -U

U 4T Ø+6(8 + 4



4 l2

).

23

Therefore, the total risk of ^ is of order

E[|^ - |2]

U -2s + U 2T Ø+1(4U + 



2 l

)

+

U

4T

Ø+6(8

+

4



4 l2

)

uniformly over Gs(R, Ø). Since the explicit choice of U = UØ = -2/(2s+2T Ø+1) fulfills

U

-1 and 



2 l2



2 l

holds

by assumption, this bound simplifies to

E[|^ - |2] U -2s + U 2T Ø+12 + U 4T Ø+64.

Here UØ balances the trade-off between the first and the second term whereby the third
summand is asympotitically negligible. We obtain the claimed rate.
For j, j = 0, . . . , s - 2, the only difference to the analysis for ^ is the rescaling factor of wUj in (4.1). Since its square appears in front of every summand, we verify

E[|^j - j|2]

U -2(s-1-j) + U 2T Ø+2j+3(4U + 



2 l

)

+ U 4T Ø+2j+8(8 + 4



4 l2

)

U -2(s-1-j) + U 2T Ø+2j+32 + U 4T Ø+2j+84.

The explicit choice of U = UØ implies the result.

Upper bound for ke (Theorem 4.5):
Similarly to the uniform bound of the bias of FO~ in Proposition 7.2, we prove the following lemma.

Lemma 7.3. If Ae-A 2 holds, we obtain uniformly over all L¥evy triplets satisfying Assumption 1 and E[|XT eXT |] 1

sup |E[F x(O~ - O)(x) (u)]| = sup |F x(Ol - O)(x) (u)| 2.

uR

uR

Proof. We follow the lines of the proof of Proposition 6.1 in [3] with the slightly different estimation:

xN N xj

|x(Ol - O)(x) dx|  (|xj-1|  |xj|)

|Ol(x) - O(x)| dx

x1

j=2

xj-1

xj x

xj

 (|xj-1| + )|O (z)| dz dy dx + C0(|xj0-1|  |xj0 |)2

j{2,...,N }\{j0} xj-1 xj-1 xj-1

 xO (x) L1 2 + O L1 3 + 2C03.

Since the extrapolation errors can be bounded by 4C2(A + )e-A-, we obtain


|E[x(O~ - O)(x)]| dx
-
2C2(Ae-A + e-A) + xO (x) L1 2 + ( O

L1 + 2C0)3 + 4C2(A + )e-A-

24

It remains to bound xO (x) L1 . Recall from [3, Prop. 2.1] that O (x) = ex P(XT <
x) + fT (x) - 1{x>0} , x  R. Integration by parts yields

|xO (x)| dx = xex P(XT < x) + fT (x) - 1 dx
00 
 xex 1 - P(XT < x) dx + E |XT |eXT 1{XT >0}
0 
= 1 - P(XT < 0) + (x - 1)exfT (x) dx + E |XT |eXT 1{XT >0}
0
= P(XT  0) + E (2|XT | + 1)eXT 1{XT >0} .

We conclude analogously

0
|xO (x)| dx = P(XT < 0) + E (2|XT | + 1)eXT 1{XT <0} .
-
Therefore, it holds xO (x) L1  2+ 2E[|XT eXT |], which is bounded by assumption.

As we will see, the estimation of  in the definition of k^e is asymptotically negligible.
We thus set ^  0 in this section. To show Theorem 4.5 we define the function Wk := F -1wk which can be understood as a kernel with bandwidth U -1. By the properties of
the weight wk it satisfies for l = 1, . . . , m - 2:

wk (

u U

)

=

U

F

(Wk (U

x))(u),

xlWk(x) dx = (-i)lwk(l)(0) = 0,
R

Wk(x) dx = wk(0) = 1,
R
|x|l|Wk(x)| dx < .
R

We split the risk into a deterministic error, an error caused by  and a stochastic error,

EP [

k^e - ke

2 L2

,

]

=EP [ F -1

-

i~

(u)wk

(

u U

)

- ke

2 L2

,

]

EP

3 F -1
R\[-, ]

(-

-

i

u (u))wk( U

)

2
(x) - ke(x)

+ 3 F -1

u wk( U )

(x) 2 + 3 F -1

(-i~

(u)

+

i

u (u))wk( U

)

2
(x) dx

=3

F -1
R\[-, ]

F

ke

(u)wk

(

u U

)

2
(x) - ke(x) dx + 3||2

|U Wk(U x)|2 dx
R\[-, ]

+ 3E

F -1
R\[-, ]

~ (u) -  (u)

u wk( U )

2
(x) dx

=:D + G + S.

25

Using wk  Cm(R), we infer |Wk(x)| bounded by
G 6U 2||2

|x|-m for x   and thus, the addend G can be

|U x|-2m dx U -2m+2.



The deterministic term D can be estimated in the spatial domain, where we use the local

smoothness of ke. For pointwise convergence rates this was done by Belomestny [2]. We decompose

2

D=3

U ke  Wk(U ∑) (x) - ke(x) dx

R\[-, ]

2
 6 ke(x - y/U ) - ke(x) Wk(y) dy dx
R\[-, ] |y|>U 

2
+ 6 ke(x - y/U ) - ke(x) Wk(y) dy dx =: 6(D1 + D2).
R\[-, ] |y|U 

An application of the Cauchy-Schwarz inequality, of the estimate |y|>U |Wk(y)| dy  (U  )-m+2 R |y|m-2|Wk(y)| dy U -m+2 and of Fubini's theorem yield

D1 

|Wk(y)| dy

ke(x - y/U ) - ke(x) 2|Wk(y)| dy dx

R\[-, ] |y|>U 

|y|>U 

(U )-m+2

|ke(x - y/U )|2 + |ke(x)|2 |Wk(y)| dy dx

R\[-, ] |y|>U 

(U )-m+2

|Wk(y)|

|ke(x - y/U )|2 + |ke(x)|2 dx dy

|y|>U 

R\[-, ]

(U )-2m+4

ke

2 L2

.

Using a Taylor expansion, we split D2 in a polynomial part and a remainder:

D2  2
R\[-, ]

|y|U 

s-1

ke(j)(x) j!U j

(-y)j

2
Wk(y) dy dx

j=0

+2
R\[-, ]

|y|U 

x-y/U x

ke(s)(z)(x - y/U (s - 1)!

-

z)s-1

dzWk(y) dy

2

dx

=: 2D2P + 2D2R.

We estimate

D2P



s-1
s(U  )-2m+4

 2j (j!)2

j=0

s-1

U -2m+4

kej

2 L2

.

j=0

|ke(j)(x)|2 dx
R\[-, ]

2
|y|m-2|Wk(y)| dy
R

26

With twofold usage of Cauchy-Schwarz and with Fubini's theorem we obtain

D2R =
|x|>

|y|U 

y/U 0

ke(s)(x - z)(z - (s - 1)!

y U

)s-1

dzWk(y) dy

2
dx


|x|>

|y|U 

|y/U |

1/2

|ke(s)(x - sgn(y)z)|2 dz

0

∑

|y/U | 0

(z - ((s

|

y U

|)2s-2

- 1)!)2

dz

1/2
|Wk(y)| dy

2
dx

|y/U |
 |ke(s)(x - sgn(y)z)|2 dz|Wk(y)| dy
|x|> |y|U  0

∑

|y|U 

(2s

|y/U |2s-1 - 1)((s - 1)!)2

|Wk

(y)|

dy

dx

|y/U |

U -(2s-1)

|ke(s)(x - sgn(y)z)|2 dx dz|Wk(y)| dy

|y|U  0

|x|>

U -(2s-1)

ke(s)

2 L2

U -2s.

|y/U | |Wk(y)| dy
|y|U 

Therefore, we have D + G U -2s. To estimate the stochastic error S, we bound the term |~ (u)- (u)|. Let us introduce
the notation

~T (u - i) := v(u) 1 + (iu - u2)F O~(u) , ~T (u - i) := (i - 2u)F O~(u) - (u + iu2)F xO~(x) (u), u  R.
For all u  R where |~T (u - i)| > (u) we obtain ~T (u - i) = 1 + (iu - u2)F O~(u). For |~T (u - i)| = (u) the estimate |~T (u - i) - T (u - i)|  2(u) follows from (4.2). This yields

|~T (u - i) - T (u - i)|  |1 + (iu - u2)F O~(u) - T (u - i)| + (u)



|1

+

(iu

-

u2)F O~(u)

-

T (u

-

i)|

+

1 2

|~T

(u

-

i)

-

T (u

-

i)|.

Therefore, |~T (u - i) - T (u - i)|  2|1 + (iu - u2)F O~(u) - T (u - i)| holds for all u  R. We obtain a similar decomposition as Kappus and Reiﬂ [16],

|~ (u) -  (u)| = 1 T

~T (u - i) - T (u - i) ~T (u - i) T (u - i)

1 T |~T (u - i)|

|~T (u - i) - T (u - i)| + T | (u)||T (u - i) - ~T (u - i)|

27

1

(1 + 4u2)1/2 + 2T | (u)|(u2 + u4)1/2 |F (O~ - O)(u)|

2T (u)

+ (u2 + u4)1/2|F x(O~ - O)(x) (u)| .

Since | (u)|  || + ke L1  2R, we have

|~ (u) -  (u)|

1 (1 + u2)|F (O~ - O)(u)| + (u2 + u4)1/2|F x(O~ - O)(x) (u)| .

(u)

It follows with Plancherel's equality

S 3E

F -1 (~ (u) -  (u))wk(u/U )

2 L2

3 =
2

E |~ (u) -  (u)|2 |wk(u/U )|2 du
R

U u4 -U |(u)|2

E |F (O~ - O)(u)|2

+E

F x(O~ - O)(x) (u) 2

|wk(u/U )|2 du

=:S1 + S2.

Both terms can be estimated similarly. Thus, we only write it down for S2, where stronger conditions are needed. Lemma 7.3 and F (xbj(x))   2(xj + ), j = 1, . . . , N , yield

S2 

U u4 -U |(u)|2

x(Ol - O)(x)

2 

+

V

ar

F

xO~(x)

(u)

UN
|u|2T Ø+4 4 + j2|F xbj (x) (u)|2 du
-U j=1

(4 + 2

(xj j )

2 l2

+

4

j

2 l2

)U

2T

Ø+5

2U 2T Ø+5.

|wk(u/U )|2 du

Therefore, we have shown E

k^e - ke

2 L2 ,

U -2s + 2U 2T Ø+5. The claim follows

from the asymptotic optimal choice U = UØ = -2/(2s+2T Ø+5).

7.3. Proof of Proposition 5.1

Step 1: We consider deterministic approximate of . Let (a)>0 be such that there is a constant C > 0 with |a - |  C| log |-1. Let the estimator ^0 use the cut-off value U := U~a and the trimming parameter  := ~aØ , with aØ := a + C| log |-1, as defined
in (5.1) and (5.2). Then we can show the asymptotic risk bound

sup EP [|^0 - |2]1/2
P Gs (R,)

2(s-1)/(2s+2T +1)

as follows: By construction holds   aØ. Hence,  fulfills condition (4.2) for each pair P  Gs(R, ). Therefore, we deduce from Theorem 4.2:

EP |^0 - |2

U-2(s-1) + U2T +32 + U4T aØ+84

=4(s-1)/(2s+2T a+1) 1 + 4T (a-)/(2s+2T a+1) + (4s-8+8T (a-aØ))/(2s+2T a+1) . (7.6)

28

The first factor has the claimed order, which follows from

( - a) log   C

 (2s + 2T  + 1) log   (2s + 2T a + 1) log  + 2T C



4(s-1) 2s+2T a+1

log





4(s-1) 2s+2T +1

log  +

8(s-1)T (2s+1)2

C

 4(s-1)/(2s+2T a+1)

4(s-1)/(2s+2T +1).

Thus, the claim follows once we have bound the sum in the bracket of equation (7.6). For the second summand this is implied by

4T (a - )

log   4T |(a - ) log | 

4T C .

2s + 2T a + 1

2s + 1

2s + 1

To estimate the third term, we obtain from s  2 and  < 1

4s - 8 + 8T (a - aØ) log   -8T C| log |-1 log  

8T C .

2s + 2T a + 1

2s + 1

2s + 1

Step 2: Let P  Gs(R, ). Note that  satisfies the condition (4.2) on the set {|^pre-| < | log |-1}. Using the independence of ^pre and Oj, the almost sure bound ~0  Ø and
the concentration of ^pre, we deduce from step 1:

EP,^pre |~0 - |2 EP,^pre EP,^pre |~0 - |2 ^pre 1{|^pre-|<| log |-1} + 4Ø2P^pre |^pre - |  | log |-1
4(s-1)/(2s+2T +1) + 4Ø2d2.

Since the second term decreases faster then the first one for   0, we obtain the claimed rate.

7.4. Proof of Proposition 5.2

Let  < 1. Recall that the cut-off value of ^0 is given by U = -2/(2s+2T Ø+1). For  > 0 we obtain from the definition of the estimator and the decomposition of the stochastic error into linear part and remainder:

P(|^0 - |  ) = P

U
Re( + ~ - )(u)wU0 (u) du  
-U

P

U
(u)wU0 (u) du
-U

 3

+P

U
Re(L(u))wU0 (u) du
-U

 3

+P

U
R(u)wU0 (u) du
-U

 3

=: P1 + P2 + P3.

29

We will bound all three probabilities separately. To that end, let cj, j  N, be suitable non-negative constants not depending on ,  and N .
The event in P1 is deterministic. Hence, the same estimate on the deterministic error as in Theorem 4.2
U
(u)wU0 (u) du  c1U -(s-1) = c12(s-1)/(2s+2T Ø+1)
-U

yields P1 = 0 for all  < (1) := (/(3c1))(2s+2T Ø+1)/(2s-2).

To bound P2 we infer from the definition of L, the linear appearance of the errors in

O~ = Ol +

N j=1

j j bj

and

from

the

estimate

of

the

term

|Lb|

in

Theorem

4.2:

U
Re(L(u))wU0 (u) du =
-U

U
Re
-U

(i - u)u F(O~ - O)(u) T T (u - i)

wU0 (u) du



U -U

(u4 + u2)1/2 T |T (u - i)| |F (Ol

-

O)(u)wU0 (u)| du

+

U
Re
-U

(i - u)u N T T (u - i) j=1 j j F bj (u)

wU0 (u) du

 c22U T Ø+2 +

N
j j
j=1

U
Re
-U

T

(i - u)u T (u - i)

F

bj

(u)

wU0 (u) du

N

 c22(s-1)/(2s+2T Ø+1) +

aj j

j=1

where the coefficients are given by

aj := j

U
Re
-U

T

(i - u)u T (u - i)

F

bj

(u)

wU0 (u) du,

j = 1, . . . , N.

To apply (5.4), we deduce from F bj   2, the weight function property (4.1) and

the assumption 



2 l2



2 l

:

NN

a2j 

j2

j=1

j=1

U -U

(u4 + u2)1/2 T |T (u - i)|

|F

bj

(u)||wU0

(u)|

du

2

 c32U 2T Ø+4



2 l2

 c42U 2T Ø+4 = c42(s-1)/(2s+2T Ø+1).

This implies through the concentration inequality of (j)

P2  P

N

aj j

 6

j=1

+P

c22(s-1)/(2s+2T Ø+1)



 6

 C1 exp

- C2 2-2(s-1)/(2s+2T Ø+1) 36c4

30

for all  < (2) := (/(6c2))(2s+2T Ø+1)/(2s-2). It remains to estimate probability P3. The bound of R in Proposition 7.2 ii) yields

U
R(u)wU0 (u) du 
-U

U -U

u4 + u2 T (u)2

|F

(O~

- O)(u)|2|wU0 (u)| du

UU

2

u4 + u2 T (u)2

|F

(Ol

-

O)(u)|2|wU0

(u)|

du

+

2

u4 + u2 T (u)2

N2
jjF bj(u) |wU0 (u)| du.

-U -U j=1

The first addend gets small owing to Proposition 7.2 i):

U -U

u4 + u2 T (u)2

|F

(Ol

-

O)(u)|2|wU0

(u)|

du



F (Ol - O)

2 

U -U

u4 + u2 T (u)2

|wU0

(u)|

du

c54U 2T Ø+4  c52(s-1)/(2s+2T Ø+1).

For the second one we obtain

N 2N

N j-1

j j F bj (u) = j2j2|F bj (u)|2 + 2

jkjk Re F bj(u)F bk(-u) .

j=1

j=1

j=2 k=1

Thus,

U
R(u)wU0 (u) du
-U

N N j-1

 2c5(4s-6)/(2s+2T Ø+1) + 2 j22j j,j (U ) + 4

j kj kj,k(U )

j=1

j=2 k=1

with

j,k(U ) :=

U u4 + u2 -U T (u)2 Re

F bj(u)F bk(-u)

|wU0 (u)| du.

Denoting the diagonal term and the cross term as

N N j-1

DN := j2j2j,j (U ) and UN :=

j kj kj,k(U ),

j=1

j=2 k=1

respectively, we obtain

P3  P

2c52(s-1)/(2s+2T Ø+1)



 9

 + P 2DN  9

 + P 4UN  9 .

The first summand vanishes for  < (3) := (/(18c5))(2s+2T Ø+1)/(2s-2). To estimate the probabilities on DN and UN , we establish the bound

|j,k(U )| 

F bj  F bk 

U -U

u4 + u2 T (u)2

|wU0

(u)|

du



c62U 2T Ø+4

(7.7)

31

for j, k = 1, . . . , N . Hence,

N

j2j,j (U )

 c62



2 l2

U

2T

Ø+4



c72U 2T Ø+4



c72(s-1)/(2s+2T Ø+1),

j=1

which yields together with (5.4)

P

DN



 18

P P

sup |k|2
k=1,...,N

N
j2j,j (U )
j=1

 18

sup
k=1,...,N

|k |2



 -2(s-1)/(2s+2T Ø+1) 18c7

 C1N exp

- C2 -2(s-1)/(2s+2T Ø+1) . 18c7

To derive an exponential inequality for the U-statistic UN , we apply the martingale idea
of Houdr¥e and Reynaud-Bouret [14]: Because of the independence and the centering of the (j), the process (UN )N1 is a martingale with respect to its natural filtration (FNU ) (setting U1 = 0):

N -1

E[UN - UN-1|FNU-1] = E

N kN kN,k(U )|FNU-1 = 0.

k=1

We will apply the following martingale version of the Bernstein inequality:

Proposition 7.4 (Bernstein's inequality). Let (Mn, Fn) be a martingale with M0 = 0. For arbitrary t, Q, S > 0 the following holds true:

P(|Mn|  t)  2P( M n > Q) + 2P

max |Mk - Mk-1| > S
k=1,...,n

+ 2 exp

- t2

.

4(Q + tS)

Hence, we consider the increment, N  2,

N -1

|UN - UN-1| = |N |

N kN,k(U ) k

k=1

=:aN,k

for which we estimate using (7.7)

N -1

N -1

aN2 ,k = N2

k2N,k(U )2  c264U 4T Ø+8N2



2 l2

k=1

k=1

 c264



4 l2

U

4T

Ø+8



c274U 4T Ø+8



c274(s-1)/(2s+2T Ø+1).

(7.8)

32

Thus, by Assumption (5.4) we obtain for all S > 0

N -1

P(|UN - UN-1| > S) = P |N |

aN,kk > S

k=1



N -1



P |N | > S-(s-1)/(2s+2T Ø+1) + P

aN,kk > S(s-1)/(2s+2T Ø+1)

k=1

C1 exp

- C2S-2(s-1)/(2s+2T Ø+1)

+ C1 exp

-

C2 c72

S

-2(s-1)/(2s+2T

Ø+1)

.

The quadratic variation of UN is given by

N -1

2

U N - U N-1 = E (UN - UN-1)2 FNU-1 = N2

kkN,k(U ) .

k=1

W.l.o.g. we can assume

N j=2

j2

>

0.

Otherwise

follows

N j=2

j2

=

0

which

implies

j

=

0

for all j = 2, . . . , N and thus U N =

N j=2

U j - U j-1 = 0. Then P( U N > Q) = 0

would hold for Q > 0. Hence, we obtain:

N
P( U N > Q) = P
j=2

N
U j - U j-1 > Q  P
j=2

N j-1
 P  l2 kkj,k(U ) > Q .

j=2

k=1

U j - U j-1 >

j2
N k=2

k2

Q

To apply inequality (5.4) we estimate



2 l2

j-1 k=1

k2

j,k

(U

)2



c264



4 l2

U

4T

Ø+8



c724(s-1)/(2s+2T Ø+1) analogous to (7.8) and obtain

P( U N > Q)  C1N exp

-

C2 c27

Q-4(s-1)/(2s+2T Ø+1)

.

We deduce from Bernstein's inequality:

P

UN

 36

2P

U N >Q

+ 2P

max |Uk - Uk-1| > S
k=2,...,N

+ 2 exp

2 -
144(36Q + S)

2C1N exp

-

C2 c72

Q-4(s-1)/(2s+2T

Ø+1)

+ 4C1N exp

-

C2 c27 

S-2(s-1)/(2s+2T Ø+1) 1

+ 2 exp

By choosing Q = S and S = (s-1)/(2s+2T Ø+1) we get

- 2

.

144(36Q + S)



P

UN

 36

 (6C1N + 2) exp

- c8 min 1/2-(s-1)/(2s+2T Ø+1) q .
q=1,3

33

For all  < (3) we have -2(s-1)/(2s+2T Ø+1) >  (3) -2(s-1)/(2s+2T Ø+1)  1 and hence,

P3



P(DN



 )+
18

P(UN



 )
36



(7C1N

+

2) exp

- c81/2-(s-1)/(2s+2T Ø+1) .

Putting the bounds of P1, P2 and P3 together yields for a constant c  (0, ) and all  < 0  1 with 0 := min{(1), (2), (3)}

P(|^0 - |  )  (7C1N + C1 + 2) exp - c(2  1/2)-(s-1)/(2s+2T Ø+1) .

Appendix A: Proof of Lemma 2.1

Part i) The martingale condition yields

|T (u - i)| = exp

T

 -

cos(ux) - 1

exk(x) dx

.

|x|

W.l.o.g. we assume T = 1,  > 0 and u  1 because of the symmetry of the cosine. Step 1: Let k(0-) = 0. We split the integral domain into three parts:

|1(u - i)| = exp

1
+

u
+



(cos

x

-

1)

ex/uk(

x u

)

dx

.

01 u

x

Using the monotonicity of k and the constant C1 :=

1 0

1-cos x

x

dx



(0,

),

we

estimate

1
(cos

x

-

1)

ex/uk(

x u

)

dx



e1/uk(0+)

0x

1 0

cos

x x

-

1

dx



-C1ek(0+).

In the second part the dependence on u comes into play. The Taylor series of the exponential function together with dominated convergence yield:

u
(cos

x

-

1)

ex/uk(

x u

)

dx



k(0+)

1x

u cos x -

1 dx +



1x

x

k=1

u
(cos
1

x

-

xk-1 1) ukk!

dx

 k(0+)

min
v1

v cos x dx - log(u) - 2  1 (1 - u-k)

1x

k!k
k=1

 k(0+)(-C2 - 2e - log(u)).

=:-C2 0

Note

that

the

constant

C2

is

finite

since

x



cos(x) x

is

Riemann

integrable

on

[1, ).

We

obtain for the third part:


(cos

x

-

exk(x) 1)

dx



-2


exk(x) dx.

1 x1

34

This achieves the estimate

|1(u - i)|  exp k(0+)(-(C1 + 2)e - C2) - 2 exk(x) dx
1

u-k(0+).

Step 2: Suppose k(0+) = 0. By substituting x = -y we derive similarly:

-1

|1(u - i)|  exp -k(0-)(C1 + C2) - 2

exk(x) dx u-k(0-).

-

Step 3: Let k(0-) > 0 and k(0+) > 0. We split the integral domain into R+ and R- and deduce from steps 1 and 2 the estimate |T (u - i)|  C(T, exk(x) L1 , )u-T  for |u|  1 and with C(T, R, ) := exp(T (-(C1 + 2)e + C2) - 2T R). Part ii) follows
immediately from the explicit choice of C.

Appendix B: White noise model and lower bounds

To establish asymptotic lower bounds for the convergence rates of the estimators ^, ^j, j = 0, . . . , s - 2 and k^e, we consider the continuous white noise model

dZP (x)

=

OP (x)

dx

+

1 N

N (x)

dW (x),

x  [-AN , AN ],

(B.1)

with a two sided Brownian motion W , an option function OP induced by the pair P  Gs(R, Ø) and AN > 0 growing in N . Under certain conditions, we can apply the results of

Brown and Low [5] to show the asymptotic equivalence of the above considered regression

model

Oj = O(xj) + jj, j = 1, . . . , N,

(B.2)

and the white noise model (B.1) for N  . Setting N and  in relation to each other
allows us to derive lower bounds in terms of . To that end, we state the situation of (B.2) more precisely. Let N  N and HN :
[-AN , AN ]  [0, 1] be an increasing, absolutely continuous distribution function with

hN := HN > 0 a.e. on [-AN , AN ]

(B.3)

such that the strikes are given by xj = HN-1(j/(N + 1)) for j = 1, . . . , N . Furthermore, let j = (xj) for some function   L(R). We suppose that  is absolutely continuous satisfying the technical condition

d log (x)
dx

 C,

x  R,

(B.4)

for some constant C < . From Belomestny and Reiﬂ [3, Prop. 2.1] we know that

O is continuous on R \ {0} with a jump at zero of height -1. O L1  3 implies

|O (x)| = |

x 0

O

(x) dx|  3 for all x = 0 and thus, O

is uniformly bounded. Especially,

O is Lipschitz continuous for any P  Gs(R, Ø)  Hs(R, Ø). The equivalence result follows

immediately from Brown and Low [5, Thm. 4.1, Cor. 4.2].

35

Proposition B.1. Under the assumptions (B.3) and (B.4) the nonparametric regression model (B.2) with j  N (0, 1) iid. and the white noise model (B.1) are asymptotically equivalent in Le Cam's sense if N2 (x) = 2(x)/hN (x) for x  [-AN , AN ].
Remark B.2. Grama and Nussbaum [13] showed the asymptotic equivalence of location type regression models with non-Gaussian noise to regression models with Gaussian noise. Hence, the condition on the distribution of j in the preceding proposition can be relaxed to error laws with regular densities.

By Proposition B.1 asymptotic lower bounds in the regression model can be proved in the white noisesetting equivalently. To this end we need a uniform lower bound of the noise level N / N in terms of . Let the strike distribution be polynomial:

hN (x)  CN-1(|x| + 1)-q, x  [-AN , AN ],

(B.5)

for some q  0 and normalization constant CN . This is reasonable since in practice most of the traded options are almost at-the-money whereas only less ones are far in- or out-of-the-money. Moreover, we suppose a minimal noise through

2(x)



2 

(|x|

+

1)-p,

x  R,

(B.6)

where

p

>

1

is

necessary.

The

restriction

on

p

is

because

the

condition



(j )

2 l2

(j )

2 l

in

the

Theorem

4.2

implies

necessarily





L2(R)

which

is

due

to

Fatou's

lemma:

N



2 L2



lim inf
N 

2(x1) +

(xj - xj-1)2(xj )

 lim inf 
N 

(j )

2 l2

j=2

 2 .

In

the

same

way



(xj j )

2 l2

(j )

2 l

implies

even

x(x)  L2(R)

in

the

situation

of

Theorem 4.5. In view of the condition e-AN 2  4 and AN e-AN 2, respectively,

we assume addionally AN  log -1.

Lemma B.3. Let the properties (B.5) and (B.6) be satisfied. If AN  log -1 holds

then

we

obtain

2N (x) N

2(log -1)- for  := max{p, q}.

The proof of the lemma is straight forward and thus omitted. In the sequel we assume always that the model (B.1) satisfies the conditions of this lemma.

Remark B.4. For the estimators ^ and ^j with s  3 we can consider the case p  [0, 1)

because of Remark 4.3. In the situation of 0 = p = q we obtain  = 0 and hence, the

lower bounds proved in the next theorems imply that our estimation procedure achieves

exact

minimax

rates

for

the

parameters.

With

regard

to

k^e

the

condition



(xj j )

2 l2

(j )

2 l

yields



 p > 3.

36

Theorem B.5. Let s  N, s  2, R, Ø > 0 and j = 0, . . . , s - 2,. We obtain in the observation model (B.1) the asymptotic risk lower bounds

inf sup EP [|^ - |2]1/2
^ PGs(R,Ø)

inf sup EP [|^j - j|2]1/2
^j PGs(R,Ø)

inf sup EP [
k^e PHs(R,Ø)

k^e - ke

2 L2

,

]1/2

(log -1)-/2 2s/(2s+2T Ø+1), (log -1)-/2 2(s-1-j)/(2s+2T Ø+1) and (log -1)-/2 2s/(2s+2T Ø+5)

where the infimum is taken over all estimators, i.e. all measurable functions of the observation Z. The bound for ke holds for s = 1 as well.

As noticed these lower bounds are a logarithmic factor better then the convergence
rates in the last section in the case  > 0. The following corollary extends the result to the parameter s-1 := k(s-1)(0+) + k(s-1)(0-). Especially, the estimation of  in the case s = 1 is of interest.

Corollary B.6. Consider the situation of the Theorem B.5 where s = 1 is also possible. For s-1 we obtain asymptotically the risk lower bound
inf sup EP [|^s-1 - s-1|2]1/2 1
^s-1 PGs(R,Ø)
in the observation model (B.1). Hence, we cannot estimate s-1 consistently in the L2sense.

Appendix C: Proofs of lower bounds

First, we are interested in the distance of ZP0 and ZP1 with P0, P1  G0(R, Ø). Girsanvo's theorem implies the equivalence of the laws of ZP∑ and the likelihood ratio for P0 with respect to P1, given by Liptser and Shiryaev [17, Theorem 7.18], is:

(P0, P1) = exp -1 2

AN  (OP1 - OP0 )(x) N N (x)-1 dW (x)
-AN
AN
|OP1 - OP0 |2(x)N N (x)-2 dx .
-AN

37

Hence, we can bound the Kullback-Leibler divergence using the uniform bound of N/N2 , Parseval's identity and the pricing formula

KL(P1|P0) = EP1 log (P1, P0)

1 =
2

AN
|OP1 - OP0 |2(x)N N (x)-2 dx
-AN



 -2(log -1) - |F (OP1 - OP0 )(u)|2 du

 -2(log -1)



T,P0 (u - i) - T,P1 (u - i)

2
du.

- u(u - i)

(C.1)

C.1. Lower bound for :

Following the standard approach, we perturb a pair P0  Gs(R, Ø). Let P0 = (0, k0)
satisfies all conditions where norms and constants are strictly smaller then R and with  = Ø. Furthermore, let k0 do not decrease too rapidly, i.e., we assume k0 |x|-p and |k0| |x|-q for some p, q > 0, and |T (u - i)| |u|-T  hold exactly. Certainly such a pair exists.
Let  > 0 and consider P1 = (1, k1) given by

1 = 0 + 

and

F k1(x) - k0(x) ex (u) = -i(u - i)e-u2m/U2m |x|

where we will choose U > 1 and m  N properly. In the following we call the difference of

the

exponentially

scaled

jump

measures

g(x)

:=

k1

(x)-k0 |x|

(x)

ex

.

By

construction

g

is

real

valued and the martingale condition is valid:

1 +

(ex
R

-

1)

k1(x) |x|

dx

=

0

+



+

(ex
R

-

1)

k0(x) |x|

dx

+

F g(0)

-

F

g(i)

= 0 +  +

(ex
R

-

1)

k0(x) |x|

dx

-



=

0.

Also the moment assumption can be checked straight forward for  small enough:



EP1 [e2XT ] = EP0 [e2XT ] ∑ exp 2 +

(ex - e-x)g(x) dx

-

= EP0 [e2XT ] ∑ exp 2(1 - e(-1)m+1/U2m ) < e2EP0 [e2XT ]  R.

Using the Schwartz-functions 1 := F -1 - iue-u2m , 2 := F -1 - e-u2m  S (R) the inversion and scaling properties of the Fourier transform yield for u  R

uu F g(u) = U F 1( U ) + F 2( U ) = F

U 21(U x) + U 2(U x)

(u).

Hence, we have g(x) = U 21(U x) + U 2(U x)  S (R). Even e-xg(x)  S (R) holds because of F e-xj(x) (u) = F j(u + i) for u  R and j  {1, 2}.

38

If U 2 1 the disturbance |x|e-xg(x) and its derivative are bounded for all U  1, owing to the rescaling with U :

U xe-xj(U x)  U x(1  e-Ux)j(U x)  x(1  e-xj(x))   .

Since additionally |x|exg(x) is fast decreasing and k0 and k0 are bounded from below, the k-function k1 is non-negative and satisfies the monotonicity conditions provided  is
small enough. The continuity and polynomial decrease of j imply (1  e-x)j(l) L1 < , j = 1, 2. Furthermore, by construction (k1 - k0)(0) = 0 and the derivatives of the disturbance is
given by

(k1

-

k0)(m)(x)

=

dm dxm

|x|e-xg(x)

=

m

m (-1)l(|x| - l sgn x)e-xg(m-l)(x) l

l=0

m
=

m l

(-1)lU m-l+2(|x| - l sgn x)e-x 1(m-l)(U x) + U -12(m-l)(U x)

l=0

for m = 1, . . . , s and x = 0. Hence, (k0 - k1)(m)(0+) + (k0 - k1)(m)(0-) = 0 for m = 0, . . . , s and substituting y = U x yield

(1  ex)(k0 - k1)(s)(x) L1

s



Us

(1  e-y)|y|1s(y)

+
L1

s l

U s-l+1

(1  e-y)(|y| + l)1s-l(y)

L1

l=1

s

+ U s-1

(1  e-y)|y|2s(y)

+
L1

s l

U s-l

(1  e-y)(|y| + l)2s-l(y)

L1

l=1

U s

and even better bounds for derivatives of lower order. Thus, the norm restrictions are fulfilled by choosing U  -1/s. Additionally, U 2  (s-2)/s 1 is valid. Therefore,
P1  Gs(R, max) holds. From Tsybakov [26, Thm. 2.2] follows the lower bound

inf sup EP [|^ - |2] 2,
^ PGs(R,max)

once we have shown that the Kullback-Leibler divergence is asymptotically bounded. We
deduce from equation (C.1), the estimate |1 - ez|  2|z| for all z  C in a small ball around 0 and the assumed decrease |T (u - i)| |u|-T  for m  T  + 1

K L(P1 |P0 )

| log | 2


|T,P0 (u - i)|2 i(u - i) + F g(u) - F g(i) 2(u4 + u2)-1 du
-



= -2(log -1)2

|T,P0 (u - i)|2 1 - e-u2m/U2m 2u-2 du.

-



-2(log -1) 2U -2T -1

|u|-2T -2 1 - e-u2m 2 du

-

-2(log -1) (2s+2T +1)/s

Hence, KL(P1|P0) remains bounded if   2(log -1)- s/(2s+2T +1).

39

C.2. Lower bound for j:

We will need the following auxiliary lemma which is shown in Section C.4 separately:

Lemma C.1. Let j  {0, . . . , s - 1} and m  N. There is a family of functions (gU )U1  Cs(R \ {0}) or (gU )U1  Cj-1(R)  Cs(R \ {0}) for j = 0 or j  1,
respectively, such that each gU has compact support and satisfies the following conditions for some constants S, Umin > 1 and for all U  Umin:

i)

 -

ex/U -1 |x|

gU

(x)

dx

=

0,

ii)

 -

|

e2x -1 x

gU

(x)|

dx



S,

iii) gU (0+) + gU (0-)  0, gU(j)(0+) + gU(j)(0-) = 1 and |gU(l)(0+) + gU(l)(0-)|  S for

l = 0, . . . , s - 1,

iv) gU   S and -(1  ex)|gU(l)(x)| dx  S for l = 0, . . . , s as well as

v)

u-m

 -

eiux -1 |x|

ex/U

gU

(x)

dx

 S,

u  [-1, 1].

Now, we are in position to prove lower bounds for j. Since the convergence rates of j decrease for rising j and because of the recursion formula in Lemma 3.1, it is sufficient to consider k(j)(0+) + k(j)(0-) instead of j. Fix a j  {0, . . . , s - 2}. We argue analogously to the proof for the estimation of : Again we perturb a pair
P0 = (0, k0)  Gs(R, Ø) with exactly the same properties as above. To disturb P0 in a suitable way, we choose a family of functions (gU )U1  Cs(R \ {0}) or (gU )U1  Cj-1(R)  Cs(R \ {0}) for j = 0 or j  1, respectively, with the properties i) - v) from Lemma C.1 for some constants S, Umin > 1 and m  N, m  T  + 2. For  > 0 define P1 = (1, k1) as
1 := 0 and k1(x) := k0(x) - U -jgU (U x), x  R.

From i) follows the martingale condition as for :

0 = 0 +

(ex
R

-

1)

k0(x) |x|

dx

-

U -j

ex/U - 1 R |x| gU (x) dx = 1 +

(ex
R

-

1)

k1(x) |x|

dx.

As long as U -j+1 is bounded the perturbation and its derivative are bounded in U

such that the necessary monotonicity and non-negativity conditions of k1 follow as in the proof before. We derive the moment assumption using ii)

EP1 [e2XT ] = exp

- U -j

e2x - 1 R |x| gU (U x) dx

EP0 [e2XT ]  eSU-j EP0 [e2XT ].

40

Furthermore, the smoothness of gU and condition iii) yield
(k0 - k1)(j)(0+) + (k0 - k1)(j)(0-) =  and (k0 - k1)(s-1)(0+) + (k0 - k1)(s-1)(0-)  SU s-1-j .

Using the integrability condition iv), we estimate
(1  ex)(k1 - k0)(s) L1 = U -j (1  ex)(gU (U x))(s) L1 = U s-1-j (1  ex/U )gU(s)(x) L1  SU s-1-j
and better bounds for derivatives of lower order. Thus, P1  Gs(R, max) if we choose U  -1/(s-1-j) with a constant small enough (note U -j+1  (s-2)/(s-1-j) 1).
With respect to condition v), the uniform boundedness of gU , their compact support and the estimate (C.1) the Kullback-Leibler divergence is bounded by

K L(P1 |P0 )

T

2

|

log | 2


|T,P0 (u - i)|2
-

 -

eiux - |x|

1 ex(k1

-

k0)(x)

dx

2
(u4

+

u2)-1

du

|

log | 2

2U

-2j


|T,P0 (u - i)|2
-

 -

eiux - |x|

1 exgU (U x)

dx

2
(u4

+

u2)-1

du

|

log | 2

2U

-2j


|u|-2T -4
-

 -

eiux/U - |x|

1 ex/U gU (x) dx

2

du

|

log | 2

2U

-2T

-2j-3


|u|-2T -4
-

 -

eiux - |x|

1 ex/U gU (x)

dx

2

du

-2(log -1) (2s+2T +1)/(s-1-j).

Hence, the choice   2(log -1)- (s-1-j)/(2s+2T +1) yields the claim. Form this proof we can conclude Corollary B.6 as follows:
Using the same perturbation P1 of a pair P0  Gs(R, Ø) we obtain bounds for (k0 - k1)(s-1)(0+) + (k0 - k1)(s-1)(0-) and (1  ex)(k1 - k0)(s) L1 which depend only on . Thus, we choose U > 1 and  independently from each other and estimate the KullbackLeibler-distance as in the theorem:
KL(P1|P0) -2(log -1) 2U -2s-2T -1.
Therefore, for a small constant  and U  -2(log -1) 1/(2s+2T +1) the KullbackLeibler-divergence is bounded.

C.3. Lower bound for ke:
Choose some P0 = (0, k0)  Hs(R, Ø) such that the corresponding characteristic function decreases as |u|-T Ø but all integral norms and constants are strictly smaller than

41

R. For j  N let j  C(R) satisfy supp  = [0, 1] and j L2 = 1 as well as

j (x) dx = j (x)e-2-jx dx = 0 and
RR

|F j(u)u-|2 du < 
R

for some  > T Ø + 2 and have uniformly bounded norms j(m) L2 < C for a constant C > 0 and all j  1, m = 0, . . . , s. Such functions exist, for instance the last property
holds if j is the th derivative of an L2-function. Defining

jl(x) := 2j/2j(2jx - l) for j  1, l = 2j-1, . . . , 2j-1 - 1,

we obtain F jl(0) = F jl(i) = 0. For any r = (r2j-1 , . . . , r2j-1)  {-1, 1}2j-1 we consider the perturbed pair Pr = (0, kr) with

2j -1

kr(x) - k0(x) = e-x|x|

rljl(x),

l=2j-1

x  R.

Hence, ke,r(x) - ke,0(x) = x

2j -1 l=2j-1

rljl(x)

and

Pr

satisfies

the

martingale

condition

and (kr - k0)(0+) + (kr - k0)(0-) = 0. Assumption 1 with C2  R and EPr [XT eXT ] =

-iT,Pr (-i)  R hold for  sufficiently small. Using the disjoint support of jl for

different l, we calculate for m = 0, . . . , s:

2j -1

ke(m,r) - ke(m,0)

2 L2

=2

l=2j-1

dm dxm xjl(x)

2
= 2
L2

2j -1

l=2j-1

xj(ml )(x) + mj(ml -1)(x)

2 L2

2j -1
=222jm

2-j (y + l)j(m)(y) + m2-j j(m-1)(y)

2
.
L2

l=2j-1

We note that y = 2jx - l  [0, 1] implies x = 2-j(y + l)  [1/2, 1] and estimate

ke(m,r) - ke(m,0)

2 L2



222jm+j-1

2

j(m)

2 L2

+

2m2

j(m-1)

2 L2

22j(2m+1).

Since ke,r - ke,0 L1 2j/2 follows in the same way, choosing   2-j(s+1/2) ensures
Pr  Hs(R, Ø). Let r, r  {-1, 1}2j-1 with Hemming distance equal to one, that is rl = rl except for
one l0. Then, j,l0 (x) = 0 for |x| < 1/2 implies

ke,r - ke,r

2 L2 ,

= 42

xj,l0 (x)

2 L2

=

42

2-j(y + l0)j(y)

2 L2



2

j

2 L2

.

We will apply Assouad's lemma (see Tsybakov [26, Lem. 2.12]), which yields

inf sup EP [|k^e - ke|2]
k^e PHs(R,Ø)

2j-1 ke,r - ke,r

2 L2 ,

2-2js

42

if the Kullback-Leibler divergence for two alternatives with Hamming distance one remains bounded. This holds true by choosing 2-j  (log -1)-/2 2/(2s+2T Ø+5) since

KL(Pr |Pr)

-2(log -1)


T,Pr (u - i)F
-

ex(kr - kr)(x) |x|

(u)

2
(u4

+

u2)-1

du



-2(log -1)2

|u|-2T Ø-4 F jl0 (u) 2 du

-



= -2(log -1)22-j

|u|-2T Ø-4 F j (2-j u) 2 du

-

-2(log -1) 2-j(2s+2T Ø+5).

C.4. Proof of Lemma C.1

Let j  0 and define C-1(R) := RR. For a constant T > 1 consider the set

CT := f  Cs(R \ {0})  Cj-1(R) supp f = [-1, 1], f satisfies condition iii), f (l)  < T, l = 0, . . . , s  L2(R).

Certainly, CT is non-empty if T is greater then a minimal value. Thus, each g  CT satisfies the properties ii) - iv) for some S > T big enough. To handle conditions i) and v), we define the functions lU : [-1, 1]  R, x  sgn(x)xl-1ex/U , with l = 1, . . . , m - 1, and consider gU  CT which satisfies gU  lU , l = 1, . . . , m - 1, where we write f  g if f, g  L2[-1, 1] are orthogonal in the sense of L2[-1, 1]. Then dominated convergence
yields for u  [-1, 1]

 -

eiux - |x|

1 ex/U gU (x) dx

  |u|k k!
k=m


sgn(x)xk-1ex/U gU (x) dx
-

|u|m

 -

 k=m-1

|x|k (k + 1)!

ex/U

|gU

(x)|

dx



|u|m


e|x|(1  ex)|gU (x)| dx  2e2T |u|m.
-

Hence, condition v) is satisfied if S  2e2T . Furthermore, the orthogonality of gU and lU l = 1, . . . , m - 1, implies

ex/U - 1 |x| , gU

=

-



sgn(x)xk-1 k!(-U )k

ex/U

,

gU

.

k=m

=:(-U )-mUm(x)

Therefore, gU satisfies condition i) if gU  mU . It remains to prove CT  AU =  where AU := {Ul |l = 1, . . . , m}.

43

This can be done by contradiction using a separation argument: Assume CT  AU = . Since CT =  and AU are convex, the Hahn-Banach separation theorem and the Fr¥echet-Riesz representation theorem imply the existence of a function
U in the Hilbert space (L2[-1, 1], ∑, ∑ ) such that f, U  g, U for all f  CT , g  AU. Because AU  L2[-1, 1] is a subspace and the linear functional AU g  g, U  R is bounded from below, g, U = 0 holds for all g  AU. Since AU is finite, we conclude further
U  lin AU = lin AU and f, U  0, f  CT .

This leads to a contradiction if there exists an f  CT such that f, U > 0. To show

this, we define l  L2[-1, 1] via the pointwise limits l(x) := limU Ul (x) for x  R \ {0}, l = 1, . . . , m. These limits are linearly independent and non-zero. By the compactness

of the Let U

interval and the uniform boundedness of

=

m l=1

al

Ul

for

some

al



R, l

=

1, . . . ,

the functions m. Using the

lU this is also an L2 limit. Cauchy-Schwarz inequality,

we obtain for all f  CT :

f, U

mm
= al f, l - f, l - lU  |al| f, sgn(al)l
l=1 l=1
m  |al| f, sgn(al)l - 2T l - Ul L2
l=1

- f L2 l - Ul L2

Thus, for some  > 0 we choose T big enough such that for all e = (el)ml=1  {-1, 1}m there exists an fe  CT such that minl=1,...,m fe, ell >  . (This can be done by choosing

fe as a polynomial with 2s + 2 conditions at ±1 and 0 as well as m linear restrictions on

the coefficients of a Umin > 1 such

tthhaetpol>ynom2iTalmsainxcl=e 1w,..e.,mcancUl amlicnul-ate l

fe, ell explicitly.) L2 ensures fe, U

Choosing > 0 with

e = (sgn(al))lm=1.

References
[1] Belomestny, D. (2010). Spectral estimation of the fractional order of a L¥evy process. Ann. Statist. 38 317-351.
[2] Belomestny, D. (2011). Statistical inference for time-changed L¥evy processes via composite characteristic function estimation. Ann. Statist. To appear.
[3] Belomestny, D. and Reiﬂ, M. (2006). Spectral calibration of exponential L¥evy models. Finance Stoch 10 449≠474.
[4] Belomestny, D. and Schoenmakers, J. (2011). A jump-diffusion Libor model and its robust calibration. Quant. Finance 11 529-546.
[5] Brown, L. D. and Low, M. G. (1996). Asymptotic equivalence of nonparametric regression and white noise. Ann. Statist. 24 2384-2398.
[6] Carr, P. and Madan, D. B. (1999). Option valuation using the fast Fourier transform. J. Comput. Finance 2 61-73.

44
[7] Carr, P., Geman, H., Madan, D. B. and Yor, M. (2002). The Fine Structure of Asset Returns: An Empirical Investigation. J. Bus. 75 305-332.
[8] Carr, P., Geman, H., Madan, D. B. and Yor, M. (2007). Self-decomposability and option pricing. Math. Finance 17 31-57.
[9] Chernozhukov, V., Ferna¥ndez-Val, I. and Galichon, A. (2009). Improving point and interval estimators of monotone functions by rearrangement. Biometrika 96 559-575.
[10] Cont, R. and Tankov, P. (2004). Non-parametric calibration of jump-diffusion option pricing models. J. Comput. Finance 7 1-49.
[11] Eberlein, E., Keller, U. and Prause, K. (1998). New Insights Into Smile, Mispricing and Value At Risk: The Hyperbolic Model. J. Bus. 71 371≠406.
[12] Eberlein, E. and Madan, D. B. (2009). Sato processes and the valuation of structured products. Quant. Finance 9 27-42.
[13] Grama, I. and Nussbaum, M. (2002). Asymptotic equivalence for nonparametric regression. Math. Methods Statist. 11 1-36.
[14] Houdre¥, C. and Reynaud-Bouret, P. (2003). Exponential inqualities, with constants, for U-statistics of order two. In Stochastic inequalities and applications., ( Evariste Gin¥e and Christian Houdr¥e and David Nualart, ed.). Progress in Probability 55-69. Birkh®auser.
[15] Jongbloed, G., van der Meulen, F. H. and van der Vaart, A. W. (2005). Nonparametric inference for Lvy-driven Ornstein-Uhlenbeck processes. Bernoulli 11 759-791.
[16] Kappus, J. and Reiﬂ, M. (2010). Estimation of the characteristics of a L¥evy process observed at arbitrary frequency. Stat. Neerl. 64 314≠328.
[17] Liptser, R. S. and Shiryaev, A. N. (2001). Statistics of Random Processes 1. Springer.
[18] Madan, D. B., Carr, P. P. and Chang, E. C. (1998). The Variance Gamma Process and Option Pricing. Europ. Finance Rev. 2 79-105.
[19] Madan, D. B. and Seneta, E. (1990). The Variance Gamma (VG) Model for Share Market Returns. J. Bus. 63 511-524.
[20] Merton, R. C. (1976). Option pricing when underlying stock returns are discontinuous. J. Finan. Econ. 3 125 - 144.
[21] Sato, K.-I. (1991). Self-similar processes with independent increments. Probab. Theory Related Fields 89 285-300.
[22] Sato, K.-I. (1999). L¥evy Processes and Infinitely Divisible Distributions. Cambridge University Press.
[23] So®hl, J. (2010). Polar sets for anisotropic Gaussian random fields. Statist. Probab. Lett. 80 840 - 847.
[24] So®hl, J. (2011). Confidence sets in nonparametric calibration of exponential L¥evy models SFB 649 Discussion Paper report, Sonderforschungsbereich 649, Humboldt Universita®t zu Berlin, Germany. To appear.
[25] Tankov, P. (2011). Pricing and Hedging in Exponential L¥evy Models: Review of Recent Results. In Paris-Princeton Lectures on Mathematical Finance 2010. Lecture Notes in Mathematics 2003 319-359. Springer Berlin / Heidelberg.

45
[26] Tsybakov, A. B. (2009). Introduction to Nonparametric Estimation. Springer. [27] van de Geer, S. (2000). Empirical processes in M-estimation. Cambridge Univer-
sity Press.

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Localising temperature risk" by Wolfgang Karl H‰rdle, Brenda LÛpez Cabrera, Ostap Okhrin and Weining Wang, January 2011.
002 "A Confidence Corridor for Sparse Longitudinal Data Curves" by Shuzhuan Zheng, Lijian Yang and Wolfgang Karl H‰rdle, January 2011.
003 "Mean Volatility Regressions" by Lu Lin, Feng Li, Lixing Zhu and Wolfgang Karl H‰rdle, January 2011.
004 "A Confidence Corridor for Expectile Functions" by Esra Akdeniz Duran, Mengmeng Guo and Wolfgang Karl H‰rdle, January 2011.
005 "Local Quantile Regression" by Wolfgang Karl H‰rdle, Vladimir Spokoiny and Weining Wang, January 2011.
006 "Sticky Information and Determinacy" by Alexander Meyer-Gohde, January 2011.
007 "Mean-Variance Cointegration and the Expectations Hypothesis" by Till Strohsal and Enzo Weber, February 2011.
008 "Monetary Policy, Trend Inflation and Inflation Persistence" by Fang Yao, February 2011.
009 "Exclusion in the All-Pay Auction: An Experimental Investigation" by Dietmar Fehr and Julia Schmid, February 2011.
010 "Unwillingness to Pay for Privacy: A Field Experiment" by Alastair R. Beresford, Dorothea K¸bler and Sˆren Preibusch, February 2011.
011 "Human Capital Formation on Skill-Specific Labor Markets" by Runli Xie, February 2011.
012 "A strategic mediator who is biased into the same direction as the expert can improve information transmission" by Lydia Mechtenberg and Johannes M¸nster, March 2011.
013 "Spatial Risk Premium on Weather Derivatives and Hedging Weather Exposure in Electricity" by Wolfgang Karl H‰rdle and Maria Osipenko, March 2011.
014 "Difference based Ridge and Liu type Estimators in Semiparametric Regression Models" by Esra Akdeniz Duran, Wolfgang Karl H‰rdle and Maria Osipenko, March 2011.
015 "Short-Term Herding of Institutional Traders: New Evidence from the German Stock Market" by Stephanie Kremer and Dieter Nautz, March 2011.
016 "Oracally Efficient Two-Step Estimation of Generalized Additive Model" by Rong Liu, Lijian Yang and Wolfgang Karl H‰rdle, March 2011.
017 "The Law of Attraction: Bilateral Search and Horizontal Heterogeneity" by Dirk Hofmann and Salmai Qari, March 2011.
018 "Can crop yield risk be globally diversified?" by Xiaoliang Liu, Wei Xu and Martin Odening, March 2011.
019 "What Drives the Relationship Between Inflation and Price Dispersion? Market Power vs. Price Rigidity" by Sascha Becker, March 2011.
020 "How Computational Statistics Became the Backbone of Modern Data Science" by James E. Gentle, Wolfgang H‰rdle and Yuichi Mori, May 2011.
021 "Customer Reactions in Out-of-Stock Situations ≠ Do promotion-induced phantom positions alleviate the similarity substitution hypothesis?" by Jana Luisa Diels and Nicole Wiebach, May 2011.
SFB 649, Spandauer Str. 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
022 "Extreme value models in a conditional duration intensity framework" by Rodrigo Herrera and Bernhard Schipp, May 2011.
023 "Forecasting Corporate Distress in the Asian and Pacific Region" by Russ Moro, Wolfgang H‰rdle, Saeideh Aliakbari and Linda Hoffmann, May 2011.
024 "Identifying the Effect of Temporal Work Flexibility on Parental Time with Children" by Juliane Scheffel, May 2011.
025 "How do Unusual Working Schedules Affect Social Life?" by Juliane Scheffel, May 2011.
026 "Compensation of Unusual Working Schedules" by Juliane Scheffel, May 2011.
027 "Estimation of the characteristics of a LÈvy process observed at arbitrary frequency" by Johanna Kappus and Markus Reiﬂ, May 2011.
028 "Asymptotic equivalence and sufficiency for volatility estimation under microstructure noise" by Markus Reiﬂ, May 2011.
029 "Pointwise adaptive estimation for quantile regression" by Markus Reiﬂ, Yves Rozenholc and Charles A. Cuenod, May 2011.
030 "Developing web-based tools for the teaching of statistics: Our Wikis and the German Wikipedia" by Sigbert Klinke, May 2011.
031 "What Explains the German Labor Market Miracle in the Great Recession?" by Michael C. Burda and Jennifer Hunt, June 2011.
032 "The information content of central bank interest rate projections: Evidence from New Zealand" by Gunda-Alexandra Detmers and Dieter Nautz, June 2011.
033 "Asymptotics of Asynchronicity" by Markus Bibinger, June 2011. 034 "An estimator for the quadratic covariation of asynchronously observed
ItÙ processes with noise: Asymptotic distribution theory" by Markus Bibinger, June 2011. 035 "The economics of TARGET2 balances" by Ulrich Bindseil and Philipp Johann Kˆnig, June 2011. 036 "An Indicator for National Systems of Innovation - Methodology and Application to 17 Industrialized Countries" by Heike Belitz, Marius Clemens, Christian von Hirschhausen, Jens Schmidt-Ehmcke, Axel Werwatz and Petra Zloczysti, June 2011. 037 "Neurobiology of value integration: When value impacts valuation" by Soyoung Q. Park, Thorsten Kahnt, Jˆrg Rieskamp and Hauke R. Heekeren, June 2011. 038 "The Neural Basis of Following Advice" by Guido Biele, Jˆrg Rieskamp, Lea K. Krugel and Hauke R. Heekeren, June 2011. 039 "The Persistence of "Bad" Precedents and the Need for Communication: A Coordination Experiment" by Dietmar Fehr, June 2011. 040 "News-driven Business Cycles in SVARs" by Patrick Bunk, July 2011. 041 "The Basel III framework for liquidity standards and monetary policy implementation" by Ulrich Bindseil and Jeroen Lamoot, July 2011. 042 "Pollution permits, Strategic Trading and Dynamic Technology Adoption" by Santiago Moreno-Bromberg and Luca Taschini, July 2011. 043 "CRRA Utility Maximization under Risk Constraints" by Santiago MorenoBromberg, Traian A. Pirvu and Anthony RÈveillac, July 2011.
SFB 649, Spandauer Str. 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
044 "Predicting Bid-Ask Spreads Using Long Memory Autoregressive Conditional Poisson Models" by Axel Groﬂ-Kluﬂmann and Nikolaus Hautsch, July 2011.
045 "Bayesian Networks and Sex-related Homicides" by Stephan Stahlschmidt, Helmut Tausendteufel and Wolfgang K. H‰rdle, July 2011.
046 "The Regulation of Interdependent Markets", by Raffaele Fiocco and Carlo Scarpa, July 2011.
047 "Bargaining and Collusion in a Regulatory Model", by Raffaele Fiocco and Mario Gilli, July 2011.
048 "Large Vector Auto Regressions", by Song Song and Peter J. Bickel, August 2011.
049 "Monetary Policy, Determinacy, and the Natural Rate Hypothesis", by Alexander Meyer-Gohde, August 2011.
050 "The impact of context and promotion on consumer responses and preferences in out-of-stock situations", by Nicole Wiebach and Jana L. Diels, August 2011.
051 "A Network Model of Financial System Resilience", by Kartik Anand, Prasanna Gai, Sujit Kapadia, Simon Brennan and Matthew Willison, August 2011.
052 "Rollover risk, network structure and systemic financial crises", by Kartik Anand, Prasanna Gai and Matteo Marsili, August 2011.
053 "When to Cross the Spread: Curve Following with Singular Control" by Felix Naujokat and Ulrich Horst, August 2011.
054 "TVICA - Time Varying Independent Component Analysis and Its Application to Financial Data" by Ray-Bing Chen, Ying Chen and Wolfgang K. H‰rdle, August 2011.
055 "Pricing Chinese rain: a multi-site multi-period equilibrium pricing model for rainfall derivatives" by Wolfgang K. H‰rdle and Maria Osipenko, August 2011.
056 "Limit Order Flow, Market Impact and Optimal Order Sizes: Evidence from NASDAQ TotalView-ITCH Data" by Nikolaus Hautsch and Ruihong Huang, August 2011.
057 "Optimal Display of Iceberg Orders" by Gˆkhan Cebirolu and Ulrich Horst, August 2011.
058 "Optimal liquidation in dark pools" by Peter Kratz and Torsten Schˆneborn, September 2011.
059 "The Merit of High-Frequency Data in Portfolio Allocation" by Nikolaus Hautsch, Lada M. Kyj and Peter Malec, September 2011.
060 "On the Continuation of the Great Moderation: New evidence from G7 Countries" by Wenjuan Chen, September 2011.
061 "Forward-backward systems for expected utility maximization" by Ulrich Horst, Ying Hu, Peter Imkeller, Anthony RÈveillac and Jianing Zhang.
062 "On heterogeneous latent class models with applications to the analysis of rating scores" by AurÈlie Bertrand and Christian M. Hafner, October 2011.
063 "Multivariate Volatility Modeling of Electricity Futures" by Luc Bauwens, Christian Hafner and Diane Pierret, October 2011.
SFB 649, Spandauer Str. 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2011
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
064 "Semiparametric Estimation with Generated Covariates" by Enno Mammen, Christoph Rothe and Melanie Schienle, October 2011.
065 "Linking corporate reputation and shareholder value using the publication of reputation rankings" by Sven Tischer and Lutz Hildebrandt, October 2011.
066 "Monitoring, Information Technology and the Labor Share" by Dorothee Schneider, October 2011.
067 "Minimal Supersolutions of BSDEs with Lower Semicontinuous Generators" by Gregor Heyne, Michael Kupper and Christoph Mainberger, October 2011.
068 "Bargaining, Openness, and the Labor Share" by Dorothee Schneider, October 2011.
069 "The Labor Share: A Review of Theory and Evidence" by Dorothee Schneider, October 2011.
070 "The Power of Sunspots: An Experimental Analysis" by Dietmar Fehr, Frank Heinemann and Aniol Llorente-Saguer, October 2011.
071 "Econometric analysis of volatile art markets" by Fabian Y. R. P. Bocart and Christian M. Hafner, October 2011.
072 "Financial Network Systemic Risk Contributions" by Nikolaus Hautsch, Julia Schaumburg and Melanie Schienle, October 2011.
073 "Calibration of self-decomposable LÈvy models" by Mathias Trabs, November 2011.
SFB 649, Spandauer Str. 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

