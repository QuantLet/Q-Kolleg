BERLIN

SFB 6 4 9 E C O N O M I C R I S K

SFB 649 Discussion Paper 2009-038
CDO and HAC
Barbara Choro* Wolfgang Härdle*
Ostap Okhrin*
* Humboldt-Universität zu Berlin, Germany
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".
http://sfb649.wiwi.hu-berlin.de ISSN 1860-5664
SFB 649, Humboldt-Universität zu Berlin Spandauer Straße 1, D-10178 Berlin

CDO and HAC 
Barbara Choro´s, Wolfgang Karl H¨ardle, Ostap Okhrin
July 30, 2009
Abstract
Modelling portfolio credit risk is one of the crucial challenges faced by financial services industry in the last few years. We propose the valuation model of collateralized debt obligations (CDO) based on copula functions with up to three parameters, with default intensities estimated from market data and with a random loss given default that is correlated with default times. The methods presented are used to reproduce the spreads of the iTraxx Europe tranches. We apply hierarchical Archimedean copulae (HAC) whose construction allows for the fact that the risky assets of the CDO pool are chosen from six different industry sectors. The dependence among the assets from the same group is specified with the higher value of the copula parameter, otherwise the lower value of the parameter is ascribed. The copula with two and three parameters models the relation between the loss given default and the default times. Our approach describes the market prices better than the standard pricing procedure based on the Gaussian distribution.
Keywords: CDO, CDS, multivariate distributions, Copulae, correlation smile, loss given default.
JEL classification: C13, G12, G13, G21
1 Introduction
The years 2007 and 2008 turned out to be a time of turmoil in the financial markets and were characterised by the collapse of real estate market in the United States. It initially started with the mortgage crisis that spread rapidly and put the world's economy into a recession. One of the triggers that inflated the housing bubble was collateralized debt obligations (CDOs). CDOs are innovative financial products that allow for the tranching and the selling of credit risk on a pool of assets, see Bluhm & Overbeck (2006), Bluhm,
The financial support from the Deutsche Forschungsgemeinschaft via SFB 649 "O¨ konomisches Risiko", Humboldt-Universita¨t zu Berlin is gratefully acknowledged.
Corresponding author. CASE - Center for Applied Statistics and Economics, Institute for Statistics and Econometrics of Humboldt-Universita¨t zu Berlin, Spandauer Straße 1, 10178 Berlin, Germany. Email: barbara.choros@wiwi.hu-berlin.de.
1

Overbeck & Wagner (2002). On the one hand, CDOs give investors many possibilities for diversification and dispersion of the portfolio risk but, on the other hand, their complexity causes difficulty in assigning correct prices.
Prior to the financial meltdown, CDOs were attracting market participants by offering higher returns than corporate bonds with the same credit ratings. When the U.S. housing bubble burst the rating agencies had to significantly downgrade CDO tranches' ratings to basically "junk status" leaving investors with worthless assets that they could not sell. After the market collapsed investors started to investigate the causes of the false valuation and the overstated ratings of CDO tranches. One of the reasons was that the CDO market did not properly identify the synergy between default risks of the pooled assets and failed to evaluate their dependency structure. The difficulty of CDO pricing lies in determining the underlying multivariate distribution and in modelling extreme events.
Since the mid nineties, several industry models for modelling credit risk have been developed. The most prominent commercial models are the KMV's PortfolioManager of Moodys, the CreditMetrics (Gupton, Finger & Bhatia 1997) of Risk Metrics Group and the CreditRisk+ of Credit Suisse Financial Products. The KMV and the CreditMetrics follow the Merton's asset value model (Merton 1974) and apply a decomposition of a firm's credit risk into systematic and idiosyncratic risk components. The main assumption of these two models is the multivariate normality of the asset value log-returns. The homogeneous large pool Gaussian copula (HLPGC) model is a simplified form of the original KMV and CreditMetrics. The HLPGC model incorporates only one factor which reflects a state of economy and is common to all assets. Moreover, it assumes that CDO collateral consists of a very large number of credits of an identical spread and recovery rate and that each obligor is correlated with the market variable with the same correlation. The one-factor HLPGC model became a popular market method for calculating implied correlations due to its analytical tractability. The CreditRisk+ is an actuarial approach in which the portfolio losses are modelled with a Poisson mixture with gamma-distributed random intensities.
The concept of modelling the joint distribution of defaults with copula functions was probably used explicitly for the first time by Li (1999). Li (2000) characterises a default by a random variable called a time-until-default and derives its distribution from market data. He then specifies the joint distribution of these random variables with a oneparameter Gaussian copula. The method presented by Li (2000) has been seen until now as the industry standard in the CDO valuation. However, the Gaussian copula has no upper or lower tail dependence and the description of joint losses with this method is inaccurate. For that reason many extensions to the standard market model and numerous new approaches have been proposed.
The expanded one-factor Gaussian copula model is provided by Gregory & Laurent (2004). The method presented allows for modelling the cluster correlation structure by intraand inter-industry correlations. The authors also introduce the dependence between the defaults and the recovery rate. Andersen & Sidenius (2005) propose a Gaussian copula model with random factor loadings to permit higher correlation in economic depressions.
2

The main disadvantage of Gaussian copula models is that they produce a phenomenon known as the correlation smile. This problem is analogue to the volatility smile observed using the Black-Scholes model in option pricing. The parameters implied by a model are not constant over tranches, but form a smile or a smirk. Amato & Gyntelberg (2005) give several explanations for the correlation smile.
Since the Gaussian copula appeared in the credit market, many other copula models have been proposed, such as t-copula (O'Kane & Schl¨ogl 2005), generalized t-copula (Daul, De Giorgi, Lindskog & McNeil 2003), double t-copula (Hull & White 2004), Clayton copula (Friend & Rogge 2005) and normal inverse Gaussian copula (Kalemanova, Schmid & Werner 2007). The method called the implied copula is presented by Hull & White (2006). Frey, McNeil & Nyfeler (2001) incorporate copulae to industry models. General factor copula models are discussed by Gregory & Laurent (2005). The model proposed by Hofert & Scherer (2008) assumes a hierarchical Archimedean copula (Okhrin, Okhrin & Schmid (2008), Okhrin, Okhrin & Schmid (2009)) as the dependency structure between obligors. The comparison of the popular CDO pricing models is provided by Burtshell, Gregory & Laurent (2008).
Broad literature describes the interaction between obligors in the portfolio through jumps in the default spread processes. The first approach explains the occurrence of jumps by macro-economic factors. In this framework Duffie & Singleton (1999) propose a basic affine model which allows for jumps in the hazard dynamics. Duffie & G^arleanu (2001) show a stochastic intensity model which allows for three types of default events: idiosyncratic defaults, industry-wide defaults in a specific sector of the economy, economy-wide defaults affecting every industry and sector. Mortensen (2006) proposes a multivariate intensity-based model, as an extension to Duffie & G^arleanu (2001). The methods of the second type justify the jumps by default events in the portfolio. Davis & Lo (2001) and Jarrow & Yu (2001) provide a contagion model in which the jump in the default intensity process of one obligor is caused by a default of another obligor. Willemann (2007) presentes the structural jump-diffusion model that allows for two kinds of correlation between defaults: diffusion and jump correlations.
Ang & Chen (2002) find that asset correlations are stochastic and are higher during a market downturn. The default clustering is discussed by Das, Freed, Geng & Kapadia (2006) who propose a two-regime model for economy-wide default risk. Das, Duffie, Kapadia & Saita (2007) investigate the clustering of default times and propose the double stochastic model that rules out default correlation beyond that implied by correlated default intensities. Longstaff & Rajan (2008) show a three-factor model in which the portfolio losses occur as the realisations of three separate Poisson processes describing the firm-specific, sector and economy-wide risk.
In this study we propose CDO valuation based on copula functions, default intensities estimated from market data and a random loss given default. We apply Gaussian and hierarchical Gumbel copulae to capture the dependency structure of the assets from the CDO collateral. In the models introduced the dependency is specified with one and two factors and with up to three parameters. The two factors reflect the state of the
3

global economy and the situation of the industry sector. We discuss the models with a deterministic and a random loss given default. In the second case the relation between loss given default and defaults is determined with Gumbel copulae. We describe the dynamics of the underlying credit default swaps (CDS) in the framework of the reduced form model. The default intensity of each CDS is estimated from historical data. The presented method is used to reproduce the spreads of the iTraxx Europe tranches. We pay special attention to the equity tranche which is priced differently to more senior tranches. The models estimate the CDO spreads in such a way that the copula parameters do not change over tranches. We investigate the behaviour of the parameters implied by all tested models using market values of the tranches. Moreover, we propose a precise method of estimation for which the deviations of the model spreads from the market spreads is negligible.
The empirical part of the work is conducted with the iTraxx Europe data taken from the Bloomberg database. The reference portfolio consists of 125 equally weighted and most liquidly traded CDS contracts on European companies which represent six different industry sectors: consumer, financial, technology-media-telecommunications (TMT), industrials, energy and auto. The number of swaps in the groups are 30, 25, 20, 20, 20, 10 respectively. Every 6 months, on 20 March and 20 September, new series of iTraxx Europe are issued and the underlying pool is reconstituted.
The paper is structured as follows. In Section 2 the CDO concept is shown. Section 3 presents the intensity model for estimating individual default probabilities and describes the valuation of CDS. Section 4 discusses the valuation of CDOs and implied correlations, it also outlines basis of copula functions and introduces methods of modelling dependence in the framework of CDO pricing. Section 5 lays out the calibration algorithm and shows the empirical results. Section 6 gives conclusions.
2 Collateralized Debt Obligations
The collateralized debt obligation is a financial instrument that enables securitization of a large portfolio of assets. The portfolio's risk is sliced into tranches of increasing seniority and then sold separately. Investors, according to their risk preferences, buy default risk of the underlying pool in exchange for a fee. Each tranche has specified priority of bearing claims and of receiving periodic payments. The regulations of Basel II stipulate that a bank holds a significant amount of capital for an unsecuritized pool of assets. Strong capital requirements motivate banks to minimise their exposure and transfer the risk to external investors. Other market participants look for arbitrage opportunities that provide extra yield.
A CDO transaction has two sides ­ asset and liability ­ linked by cash flows (see Figure 1). The asset side refers to the underlying reference portfolio while the liability side consists of securities issued by an issuer, which is often a special purpose vehicle (SPV). An SPV is a company created by an owner of a pool especially for the transaction, to insulate
4

'

$

'

$

Reference

Portfolio, e.g.,

'

-loans -bonds -CDS

Assets
-
 SPV Cash &

etc.

&

%

$
Principals
-

%Cash

Senior Mezzanine

Equity
&

%

Figure 1: Illustration of a CDO cash flow mechanism.
investors from the credit risk of the CDO originator. An originating institution, usually a bank, sells assets to an SPV to manage exposure, shrink their balance sheets and reduce required capital but it often keeps the administration of the pool. The SPV claims the legal rights of the ownership of the credits and of all the cash flows arising from them. To pay out to the originator for the collateral, SPV issues structured notes backed by the pool on its balance. The reference entities sold to the SPV are not at risk if either the SPV or the originator become insolvent. For that reason the SPV's notes in the form of tranches receive better credit ratings and pay less interest than if they were issued by the bank.
CDOs are classified by types of underlying credits: collateralized loan/bond obligations are backed by loans/bonds, CDO-squared have collateral composed of other CDOs, see Bluhm et al. (2002). In this paper we apply the model to synthetic CDOs which are based on the pool of CDS because they are naturally structured as pure credit derivatives without involving any principal cash flows. Synthetic CDOs, in contrast to cash CDOs, transfer the risk away from the originator without the true sale of the collateral. Instead, the synthetic CDOs gain exposure to credit risk by selling protection through CDS contracts. Synthetic CDOs can be either fully or partially funded. A fully funded CDO shifts the entire portfolio's risk to the SPV via CDS. More typical are partially founded CDOs that transfer only the highest risk segment of the collateral.
Each CDO tranche is defined by the detachment (lj) and attachment (uj) points which are the percentages of the portfolio losses. The first losses are covered by the equity tranche, also called a residual or a junior tranche. Table 1 presents the classic tranching taken from the iTraxx index. This example shows that the most subordinated tranche bears the first 3% losses of the portfolio nominal. The equity tranche holders are also paied an upfront fee. It is common that a bank keeps the riskiest piece. If losses constitute 5% of the collateral notional, the equity investors carry the first 3% (thus loosing all their investment), and the next 2% is covered by those who invested in the mezzanine junior tranche. The tranches that carry the lowest risk are called senior tranches and get the highest credit ratings. They receive periodic income at first and as the last are affected
5

by any losses. The senior tranche holders suffer only if the total collateral portfolio loss exceeds 22% of its notional value. Mezzanines have lower ratings than senior tranches but give better returns. The unrated equity tranche offers the highest coupons and gets paid at the end.

Tranche number 1 2 3 4 5 6

Tranche name Equity Mezzanine Junior Mezzanine Senior Super Senior Super Super Senior

Attachment points (%) Lower (lj) Upper (uj)
03 36 69 9 12 12 22 22 100

Table 1: Example of a CDO tranche structure, iTraxx.
Each loss that is covered reduces the notional on which the payments are based and also reduces the value of the periodic fee. After each default the seller of the protection makes a payment equal to the loss to the protection buyer. When the portfolio losses exceed the detachment point, no notional remains and no payment is made.

3 Univariate Credits: CDS
Synthetic CDOs, priced in this study, are backed by a portfolio of d CDS. A CDS is an insurance contract between two counterparties covering the risk that a specified credit defaults. The final result of the CDO calibration strongly depends on the evaluation of the risk of each underlying CDS contract. This section discusses the issues of calculating default probabilities and of the CDS valuation. For a survey of the CDS pricing please refer to Duffie (1999) and Hull & White (2000).
3.1 Default Probabilities
The individual default probabilities of the assets in the portfolio are a key input in the computation of the reference portfolio's probability distribution. The modelling of the distribution consists of estimating the individual default probabilities and specifying the joint behaviour of the credits. The first step in pricing a multiname credit derivative is therefore to construct the default term structure of each underlying asset. Two models are in common use: structural and intensity. Structural models introduced by Hull & White (2001) and further investigated by Hull, White & Predescu (2006) are based on the Merton (1974) approach in which a default occurs if the market value of the company's assets falls below a value of fixed liabilities. Intensity models, also called reduced or hazard rate models, firstly introduced by Lando (1994) and Duffie & Singleton (1999), use prices
6

of defaultable securities traded on the market, like bonds, options or swaps. Default probabilities could also be computed from historical default rates provided by external rating agencies.

This study applies the intensity model to derive the default probabilities from the spreads of the CDS that underlie the iTraxx index. We assume the existence of a filtered probability space (,F, P) with a probability measure P. Let  be a positive random variable representing the time of default of a given risky instrument, with a distribution function F . The term structure of default probability (the credit curve) is defined as:

p(t) = P(  t) = F (t)

(1)

and represents the probability that an obligor defaults within the time interval [0, t]. In this framework the obligor's default is modelled as the time until the first jump of a Poisson process with a deterministic or a stochastic intensity. The unconditional default probabilities are related to the intensity function (t) by the following equality:

t
p(t) = 1 - exp - (u)du ,
0
where the corresponding survival probability term structure is given by:

(2)

p¯(t) = 1 - p(t) = P( > t).

(3)

The probability that a default occurs in a small interval (t, t+t), given that the reference entity survived up to time t, is approximately

t+t

t+t

P(t <   t + t|Ft) = exp -

(u) du

(u) du  (t)t,

tt

where {Ft : t > 0} is the filtration that contains information about the underlying process till time t. Hence the intensity function (t) has the following form:

(t) = lim P(t <   t + t|Ft)

t0

t

(4)

and gives the instantaneous default probability of an asset that has attained age t. Mod-

elling a default process is equivalent to modelling an intensity function. A homogeneous

Poisson process corresponds to a constant intensity function (t) = , otherwise a pro-

cess is called non-homogeneous. In practice, an intensity in form of a step function

(t) =

Tn k=1

k

1(Tk-1

<

t



Tk)

is

applied,

where

{Tk }nk=1

is

a

sequence

of

increas-

ing maturities of the CDS contracts that have the same reference entity. The piecewise

constant intensity incorporates more information and therefore gives a more realistic ap-

proximation of the credit curve than a simple constant function. The parameters k,

k = 1, . . . , n, are calibrated consecutively. First the intensity for the shortest maturity T1 is estimated. Having 1 one estimates 2 from the CDS spread of the maturity T2 and so on. However, this approach requires significantly more market data input when dealing

with large portfolios. In the case of the iTraxx collateral, it is difficult to provide spreads

of several different maturities of 125 CDS contracts.

7

3.2 CDS pricing

Credit default swaps were originally created as a means of shifting the default risk of a loan or a bond to a third-party. However, the CDS market changed so that sellers and buyers of contracts do not have to be owners of the underlying asset but are betting on the possibility of a credit event of a particular asset. Nowadays CDS are the most widely traded credit derivative products, mostly for speculative purposes.
Consider the ith CDS from the CDO reference portfolio of d contracts, i = 1, . . . , d. We assume that the two parties of the transaction enter into the CDS on a trade date t0 and on this day the protection begins. For the iTraxx investor t0 express the time in years from the roll date of the iTraxx product untill the day for which the valuation is carried out. The protection buyer regularly pays premiums to a protection seller who in return agrees to cover losses if the ith company suffers a credit event. The value of the periodic fee is specified by the spread si(t0) of the CDS, the total notional M and the time between the payment days. The protection buyer settles the cash obligations at predetermined dates, usually once per quarter, until the maturity T of the contract or until i < T in the case of default. Thus on a payment day t the buyer of the CDS obtains an amount:
M si(t0)t1(i > t),
where t is a fraction of the year between t and the nearest preceding payment day and 1(·) is an indicator function. If the CDS defaults, the protection seller delivers a payoff equal to the notional value M of the obligation reduced by the recovery rate Ri:
M (1 - Ri)1(i  T )
and receives a part of the premium payment that has accrued since the last payment date:
M si(t0)(i - t)1(t - t < i  t).

The present value of the cumulated insurance payments made by the protection buyer during the life of the CDS is called a premium (fixed) leg P Li and equals

T

P Li(t0) =

(t0, t)M si(t0)t E{1(i > t)}

t=t1

Tt

= (t0, t)M si(t0)t exp - i(u)du ,

t=t1

t0

where t1 is the date of the first payment after the trade is made and the sum is taken over all scheduled payment days. All settlements are discounted to the time point t0 using the following discount factor:

(t0, t) = (1 + rt/4)-4(t-t0)/365 ,

where rt is a compounded quarterly interest rate at time t. However, in the whole study rt is assumed to be constant.

8

The present value of the payoff made by the protection seller in case of credit event is called default leg DLi and equals the expected present value of the contingent payment upon default DPi minus the contingent accrued premium APi:
DLi(t0) = DPi(t0) - APi(t0),
where

DPi(t0) = E{(t0, i)M (1 - Ri)1(i  T )}

Tu

= M (1 - Ri) (t0, u)i(u) exp - i(s)ds du,
t0 t0

T

APi(t0) =

E [(t0, i)M si(t0){i - (t - t)}1(t - t < i  t)]

t=t1

Tt

u

= M si(t0)

{u - (t - t)}(t0, u)i(u) exp - i(s)ds du.

t=t1 t-t

t0

The values of both legs depend on the company's tendency to default described by the

intensity function (t). To emphasise that the premium's value is driven by the intensity

we write si(i, t0). The CDS fair spread is then chosen in such a way that the market value of the contract is zero. On the trading day t0 the expected values of the sum of discounted payments made by the protection buyer and the protection seller must be

equal P Li(t0) = DLi(t0), which implies

si(i, t0) =

T t=t1

(

(t0

,

t)t

E{1(i

E{(t0, i)(1 - Ri)1(i  T )} > t)} + E[(t0, i){i - (t - t)}1(t

-

t

<

i



. t)])

(5)

Having the historical spreads of all d iTraxx underlying single-name CDS one can extract

the default probabilities of these reference entities by inverting the pricing procedure and

implying the intensity functions' parameters. We calibrate the model to fit the CDS

values, assuming that the intensity function is constant over time. The intensity that

yields the quoted spread is found by applying a bisection method. We look for the solution of the equation si(^i, t0) = si(t0), where si(t0) is the spread for the ith CDS
quoted on the market. In Figure 2 we plotted the default probabilities calculated from

the historical CDS spreads of Deutsche Bank with the maturity of 5 years.

As the default probabilities are unobservable, the model used to estimate default probabilities can be verified by comparing theoretical iTraxx index spreads with real market quotes. The index spread s~ at time t0 is not an arithmetic mean of CDS spreads but a survival probability weighted average:

s~(t0) =

d i=1

si(^i
d i=1

,

t0)
T t=t1

T t=t1

{1

-

pi

(^i

,

t)}/(1

+

r/4)4t

{1 - pi(^i, t)}/(1 + r/4)4t

,

(6)

where ^i is the intensity of the ith company implied by the model, si(^i, t0) is the spread defined in (5) with the probability of default denoted here by pi(^i, t) and given by (2).
Figure 3 shows how the real market and the calibrated index spreads change over time. It

can be seen that the estimation of the index is quiet precise which implies that the model

reflects market behaviour well.

9

Spread (bps) PD

0.014 0.012
0.01 0.008 0.006 0.004 0.002
0 20071108 20080128 20080317 20080604
Time
Figure 2: Probabilities of default (2) of Deutsche Bank, time period 20071022-20080630, R = 0.4, r = 0.03.
180 150 120
90 60 30
0 20071108 20080128 20080317 20080604
Time
Figure 3: Comparison of the market iTraxx index spreads (red) with the results of the model (6) (black), time period 20071022-20080630, R = 0.4, r = 0.03.
10

4 Multivariate Credits: CDO
The prices of the CDO tranches depend on the joint random behaviour of the assets in the underlying pool, more precisely, on their likelihood of joint defaults. The correlation is one of the most popular measures of dependence between two random variables. The standard market model for the CDO pricing, introduced by Li (2000), applies a multivariate Gaussian copula to describe the random co-movements of the reference entities. In addition, it assumes for simplicity, one value of the correlation for every pair of assets. An implied correlation can be calculated out of market spreads by inverting a pricing model. The correlations implied from the different tranches of the same CDO are not equal and the observed phenomenon is called an "implied correlation smile", see Bluhm & Overbeck (2006). There are several explanations for this inconsistency. One of the reasons might be an erroneous model. Thus it is of interest to investigate more flexible dependency structures which match the market spreads more accurately than the standard Gaussian one factor model.

4.1 Valuation of CDO

The CDO pricing is a two-step procedure. The main part of the valuation is the same for every approach and consists of defining the structure of payments that are made during the life of the contract. In the second, theoretical stage, the joint and marginal distributions of the reference entities need to be specified. The mechanism of cash flows between the protection seller and the protection buyer was presented in Section 2. We give below the necessary formulae that lead to a closed form of fair spreads of the CDO tranches. Similarly to the CDS, the fair spread is defined as a spread for which the market-to-market value of the contract is zero. This means that if the CDO originator pays the fair spread, the present value of the fee payments is equal to the present value of the contingent payments. Recall that the ith obligor is deemed to default before t  [t0, T ] if i  t. Then the loss variable is defined as:

i(t) = 1(i  t).

The portfolio loss process is the average of the all obligors' losses:

1 L(t) =
d

d
(1 - Ri)i(t),

t  [t0, T ].

i=1

(7)

Figure 4 represents the density function of the L(t) from the homogeneous one-factor Gaussian model for different values of the correlation parameter . It shows that the correlation determines the shape of the portfolio distribution and hence the risk allocation between tranches.

The first losses are absorbed by the equity tranche until they reach a certain threshold. The following losses are covered by more senior tranches. Consider a CDO of J tranches.

11

15

10

f (x)
L

5

0 0 0.1 0.2 0.3 0.4 x

Figure 4: Portfolio loss density fL(·) for different correlation parameters : 0.05 (dotted), 0.1 (dashed), 0.3 (solid), 0.5 (dash-dot) and a fixed probability of default p = 10% in the HLPGC model.

The loss of the tranche j = 1, . . . , J, at time t is determined by its lower lj and upper uj attachment point and the portfolio loss:

Lj(t) = min{max(0, L(t) - lj); uj - lj}

 0, 

L(t) < lj,

= L(t) - lj, lj  L(t)  uj,

 uj - lj, L(t) > uj.

(8)

Similarly like in the case of the univariate contract, the present value of the sum of fee

payments made by the protection buyer during the life of the CDO is called premium

(fixed) leg. The protection seller receives insurance payments for which he obliges himself

to cover losses affecting his tranche. The protection (floating, default) leg refers to the

present value of the sum of contingent payments done upon credit events. The payments

connected with tranche j at time t are calculated from the outstanding notional of the

form:

Fj(t) = (uj - lj) - Lj(t), j = 1, . . . , J.

(9)

For the CDO valuation it is sufficient to determine the cumulative loss distribution at each payment day. This simplification allows avoiding a description of the whole path of the loss process but forces specification of the time of default between the payment days. The credit event can happen at any time but to get a close form solution we make a slightly simplifying assumption that all defaults occur in the middle of a payment period. The premium leg P Lj is then based on the expected average of outstanding notionals from the two nearest payment days:

T
P Lj(t0) = (t0, t)sj(t0)t E{Fj(t) + Fj(t - t)}M/2, j = 2, . . . , J.
t=t1

(10)

12

The premium leg can be expressed with the help of the risky duration RDj defined as:

RDj(t0) =

T t=t1



(t0

,

t)t

E{Fj (t)} uj - lj

,

j

= 2, . . . , J.

Then

P

Lj (t0 )

=

sj

(t0)M

RDj

(t) + RDj(t 2(uj - lj)

-

t)

,

j

= 2, . . . , J.

(11)

The most subordinated tranche is priced differently than the other tranches. The equity

tranche pays an upfront fee once, at the inception of the trade and a fixed coupon of 500

bps during the life of the contract. The upfront payment, denoted by , is expressed in

percent and is quoted on the market. The premium leg of the residual tranche is defined

as:

T
P L1(t0) = (t0)(u1 - l1)M + (t0, t) · 500 · t E{F1(t) + F1(t - t)}M/2.
t=t1

The protection leg DLj for all the tranches is calculated as follows:

T
DLj(t0) = (t0, t) E{Lj(t) - Lj(t - t)}M, j = 1, . . . , J.

(12)

t=t1

The premium sj of the tranche j is chosen in such a way that both premium and protection legs are equal:

P Lj(t0) = DLj(t0).

This leads to the solution:

sj(t0) =

T t=t1

(t0,

t)

E{Lj

(t)

T t=t1

(t0,

t)t

E{Fj

(t)

- +

Lj (t Fj (t

- -

t)} t)}/2

,

for

j

= 2, . . . , J.

If we denote the denominator of the formula (13) by:

(13)

T
P Lj (t0) = (t0, t)t E{Fj(t) + Fj(t - t)}/2,
t=t1
we get the fair spread of the form:

(14)

sj (t0 )

=

DLj (t0 ) P Lj(t0)

for j = 2, . . . , J.

(15)

For the equity tranche the upfront payment is equal to:

100 T (t0) = u1 - l1 t=t0 [(t, t0) E{L1(t) - L1(t - t)} - 500t E{F1(t) + F1(t - t)}/2]

=

100 u1 - l1

{DLj

(t0)/M

-

500P Lj (t0)}.

The CDO spreads sj(t0), j = 2, . . . , J, and the upfront fee (t0) are constantly observed on the market. Our aim is to find a model that computes the prices which are close to

the real values and which do not result in a formation of the implied correlation smile

(see Figure 5, left panel).

13

Compound Correlation Base Correlation

0.7

0.6

0.5

0.4
Equity 0.3

Super Senior

0.2 Senior Mezzanine
0.1 Mezzanine Junior

12345 Tranches

0.7 Super Senior
0.6 0.5 Senior
Mezzanine 0.4
Mezzanine Junior 0.3 Equity
0.2
0.1
12345 Tranches

Figure 5: Implied compound (left) and base (right) correlation smile from the HLPGC model. iTraxx Series 8 with maturity 5 years, from 20071022, R = 0.4, r = 0.03.
Types of Implied Correlation
There are two types of implied correlations: compound and base. The difference between them follows from distinct ideas of calculating the tranche losses (8). The survey of the implied correlations is provided by Finger (2004) and Willemann (2005). The implied compound correlation of a given tranche j is a parameter that makes the tranche spread computed by the model equal to its observed market value. The parameters implied from all tranches often form a smile shape which appears because the implied compound correlation for the equity and senior tranches turns out to be greater than that for the mezzanine tranches. For a correct model the implied correlation should be approximately constant for all tranches. Moreover, while implying the parameters, we come across nonexistence and non-uniqueness of the implied compound correlation for mezzanine and more senior tranches. Sometimes two correlations reproduce the same tranche spread, in other cases we may not obtain any implied correlation at all.
These disadvantages are not possessed by the implied base correlations introduced by McGinty & Ahluwalia (2004). The numerical procedure of implying a base correlation uses a fact that the loss L(lj,uj) of a tranche (lj, uj) can be represented as a difference between losses of the two fictive equity tranches (0, uj) and (0, lj) defined as L(0,uj) and L(0,lj) respectively:
E{L(lj,uj)} = E{L(0,uj)} - E{L(0,lj)}, j = 2, . . . , J.
We fix a single correlation to price the (0, lj) tranche, then we look for a second correlation to price the (0, uj) tranche such that the spread difference is consistent with the observed (lj, uj) tranche spread. The base correlation are uniquely determined as the loss and the premium of the equity tranche always decreases with the correlation parameter. In addition, this measure allows to price the tranches that are not quoted on the market. Since the base correlation depends only on a lower attachment point, we can use it to value off-market tranches by an interpolation approach. The comparison of the compound and the base correlation is shown in Figure 5.
14

4.2 Copulae

The use of copula functions allows for the specification of the default dependency of a high number of credits. We present below the necessary definitions and useful properties. For a survey over the mathematical foundations of copulae we refer to Joe (1997) and Nelsen (2006).

A copula can be defined as an arbitrary distribution function on [0, 1]d with all margins being uniform. The copula function captures the dependency between variables eliminating the impact of the marginal distributions. Copulae gained a high degree of popularity due to the theorem of Sklar (1959). With Sklar's theorem one can express the copula in the following way

C(u1, . . . , ud) = F {F1-1(u1), . . . , Fd-1(ud)}, u1, . . . , ud  [0, 1],
where F1-1(·), . . . , Fd-1(·) are the corresponding quantile functions.
The elliptical cumulative distribution functions, like Gaussian and t-Student, generate the class of the elliptical copulae which have been, until now, of high interest in credit risk modelling. Another important group are Archimedean copulae. The d-dimensional Archimedean copula function C : [0, 1]d  [0, 1] is defined as

C(u1, . . . , ud) = {-1(u1) + · · · + -1(ud)}, u1, . . . , ud  [0, 1],

(16)

where   { : [0; )  [0, 1] | (0) = 1, () = 0; (-1)j(j)  0; j = 1, . . . , } is
called a generator of the copula. In this study  is assumed to be completely monotone.
Nevertheless, McNeil & Neslehova´ (2009) prove that the generator  is required to be dmonotone, i.e. differentiable up to the order d - 2, with (-1)i(i)(x)  0, i = 0, . . . , d - 2 for any x  [0, ) and with (-1)d-2(d-2)(x) being nondecreasing and convex on [0, ).

A prominent example is a Gumbel copula given by

 C(u1, . . . , ud; ) = exp -

d
(- log uj)
j=1

-1 

with a generator

(x; ) = exp {-x1/}, 1   < , x  [0, ).

Note that (16) is symmetric with respect to the permutation of variables which entail that the distribution turns out to be exchangeable. Furthermore, for any dimension d the multivariate structure depends on a single parameter of the generator function .

Each   L is a Laplace transform of some cumulative distribution function M of a posi-

tive random variable, i.e. (t) =

 0

e-tw

dM

(w).

For

an arbitrary cumulative distribution

function F a unique cumulative distribution function G exists, such that


F (x) = G(x)dM () = {- log G(x)}.
0

15

For a d-variate cumulative distribution function F with margins F1, . . . , Fd it holds:



F (x1, . . . , xd) =

G1 · · · · · GddM ()

0

dd

=  - log G(xi) = 

-1{Fi(xi)} .

i=1 i=1

The above formula implies that the copula of F is given by (16). The representation of

a copula in terms of a Laplace transform is very useful for simulating random numbers,

see Whelan (2004), McNeil (2008), Marshall & Olkin (1988). The Laplace transforms

allow for numerous interesting extensions. We can get a more general type of depen-
dency by replacing the product copula G1 · · · Gd with an arbitrary multivariate copula K(G1 , . . . , Gd ) and by replacing M () with a d-variate distribution Md(), such that jth univariate margin has a Laplace transform j, j = 1, . . . , d, see Joe (1997). Using these
transformations we obtain a function called a fully nested copula of the form:

 

C(u1, . . . , ud) =

...

G1 1(u1)G2 1(u2)dM1(1, 2)

0 00

×G3 2

(u3)dM2

(2

,

3

)

.

.

.

Gd-1
d

(ud

)dMd-1

(d-1

).

(17)

Other orders of integration and combinations of the Gi functions lead to different forms of dependencies. In terms of the generators of the cumulative distribution functions M1, . . . , Md, the copula (17) can be rewritten as:
C(u1, . . . , ud) = 1[-1 1  2{. . . [-d-12  d-1{-d-11(u1) + -d-11(u2)} + d--12(u3)] + . . . +-2 1(ud-1)} + -1 1(ud)]
= 1{1-1  C2(u1, . . . , ud-1) + -1 1(ud)} = C1{C2(u1, . . . , ud-1), ud}.

The presented generalisation of the multivariate Archimedean copulae leads to the class of hierarchical Archimedean copulae (HAC). The profound study of HAC is provided by Okhrin et al. (2008) and Okhrin et al. (2009).

According to McNeil (2008), if 1, . . . , d-1 are completely monotonic generators and i  i+1 have completely monotonic derivatives for i = 1, . . . , d - 1, then (17) is a proper copula function.

Note that generators i within a HAC can come either from a single generator family or from different generator families. If i belong to the same family, then the complete monotonicity of i  i+1 imposes some constraints on the parameters 1, . . . , d-1. For the majority of the copulae the parameters should decrease from the lowest to the highest
level of a hierarchy to guarantee a feasible HAC. If i are members of different families, then the complete monotonicity of i  i+1 might not be fulfilled at all.

4.3 Joint Defaults
Assume that a CDO pool contains d CDS contracts whose individual risks are described with the credit curves pi(t) given by (2) or equivalently with the survival functions p¯i(t)
16

given by (3), for i = 1, . . . , d and t  [t0, T ]. In the simulation study we consider that the ith obligor survives until t if and only if

Ui  p¯i(t),

(18)

where a random variable Ui, called a trigger, is uniformly distributed on [0, 1].
The difficulty in modelling the default risk of the CDO lies in finding the relation between default times 1, . . . , d of the underling securities. The main task consist of determining the joint distribution of the stopping times such that the marginal distributions are given by the credit curves. Multivariate copula functions provide a convenient way of specifing the joint distribution with given margins.

Note that the random variable p¯i(i) has the uniform distribution. Therefore the numbers U1, . . . , Ud have the same joint distribution as p¯1(1), . . . , p¯d(d). The default times are obtained by taking the inverse of the survival functions in the points U1, . . . , Ud.
The joint distribution of the triggers satisfies:

C(u1, . . . , ud) = P(U1  u1, . . . , Ud  ud).

Applying the marginal survival probabilities at time t we obtain:

C{p¯1(t), . . . , p¯d(t)} = P{U1  p¯1(t), . . . , Ud  p¯d(t)}.

The above default time copula fully describes the non-linear dependency structure of its

underlyings. The uniform marginal distributions of the copula ensure that the ith margin

is equal p¯i:

P{Ui  p¯i(t)} = p¯i(t).

The time to default variable

i = inf{t  t0 : p¯i(t)  Ui},

(19)

is calculated as the first time when the process p¯i(t) reaches the level of the trigger variable Ui. Assuming the constant intensities we simply compute that

i

=

- log Ui . i

The choice of the appropriate copula plays a crucial role in the final results. The selected function should represent desirable tail properties and the algorithm of generating the random numbers from it need to be known. The multi-parameter model can contain up to d(d - 1)/2 parameters if the dependency is assumed to be Gaussian or t-Student and up to d - 1 parameters for the HAC. In both situations the calibration of full models is unfeasible for large d and some techniques for reducing dimension have to be introduced.

The simplest way of handling the dimensionality in modelling the iTraxx data is to assume that all credits influence each other in the same way. Then a copula that define the relation between the portfolio's components has only one parameter.

17

Another approach uses the fact that the collateral is divided into classes. In the case of the iTraxx index, the CDS from the pool represent six industry sectors. To check whether we can identify the groups in data we applied a cluster analysis to the daily log-returns of the CDS spreads from 22 October 2007. The modified correlation matrix was used as a distance matrix. We obtained following six clusters: 9, 15, 17, 25, 28, 31. The result is similar to the true partition of the collateral what confirms that it is reasonable to include the sector aspect in the following research. Therefore we can construct the sevenparameter model in which the dependency in each group is described with a distinct oneparameter copula and the relations outside the groups are characterised with additional, seventh parameter. In such a case the correlation matrix has the following form:



1 · · · 2

 

...



1 · · · · · · ...

 

2

···

1

1



 

1

···

1

 

...



 

...



1 · · · 3 ...
3 · · · 1

R

=

 



...

 

1 · · · 6

  

...



 

6 · · · 1

  

...

  

...

1 ...

1 · · · · · ·

· · · · · · 1

· · · · · · 1 

...

 

...

  

























...

 



...

 



1

···

1

 



1

· · · 7

 

...

 



7 · · · 1

(20)

When one deals with copulae, the correlation term  in the matrix above means, not Pearson linear correlation, but the Kendall's or the Spearman's rank correlation.

In the empirical study we will apply a simplification that assumes i = j and i = 1 for i, j = 2, . . . , 7. Then the model comprises the industry factor which imposes different inter- and intra-industry correlations. In the context of the Archimedean copluae the two-factor approach can be handled by HAC. Using the partially nested HAC we first describe the dependency within the industry sector with an Archimedean copula C2 and then we join all groups with another Archimedean copula C1. The applied HAC has the following form:

C(u1, . . . , ud; ) = C1{ C2(u1, . . . , um1; 2), C2(um1+1, . . . , um1+m2; 2), . . . , C2(um1+...+m5+1, . . . , ud; 2); 1},

(21)

where  = (1, 2) and mk, k = 1, . . . , 6, indicates a number of the companies in kth industry sector. The graphical representation is shown in Figure 6. The Gaussian copula with sector correlations is discussed by Gregory & Laurent (2004).

When in (20) all parameters are equal, i = j for i, j = 1, . . . , 7, one deals with the one-factor model. If we, in addition, assume the normal copula, we get the standard

18

C1 (125)
C2 C2 C2 C2 C2 C2 (30) (25) (20) (20) (20) (10)

u1

u2 ... u29

u30

Figure 6: Partially nested 125-dimensional HAC.
Gaussian copula model. Even though it is often criticized because of its simplifications, the Gaussian copula model still remains the benchmark on the market.
The appropriate multivariate distribution should reflect the tendency observed in financial data of joint extreme movements. That behaviour is described by the means of a tail dependence. The tail dependence gives the limiting proportion that some margins exceed a certain threshold conditional on the fact that others have already exceeded that threshold. In the CDO framework the upper tail dependence allows us to quantify the risk that a CDS defaults (negation of (18) occurs) given that a different CDS defaults. The tail dependence is a property of a copula function and is independent of marginal distributions. The normal distribution is asymptotically tail independent so by its construction is unable to handle the extremal dependence. For that reasons we will focus on a Gumbel copula which exhibits the upper tail dependence. The Gumbel copula is suitable to describe the outcomes that are likely to simultaneously realize upper tail values. The different tail behaviour of the Gauss and Gumbel copula is clearly visible in Figure 7 showing the contour plots of the 3-dimensional one and two-parameter copula densities.
The tail dependence of a bivariate distribution is deeply studied by Joe (1997). A common measure of the bivariate tail dependence is given by the so-called tail dependence coefficient. Several generalisations to the multivariate tail dependence have been proposed. Schmidt & Stadtmu¨ller (2006) present tail copulae that describe the dependence structure of multi-dimensional distributions in the tail. The tail dependence functions are also discussed by Klu¨ppelberg, Kuhn & Peng (2008) and Nikoloulopoulos, Joe & Li (2008).
4.4 Loss Given Default
Because of the high complexity of the CDO valuation it is a common practice to introduce simplifications and to neglect some of the parameters. Most of the models that are used to reproduce the tranche spreads assume the constant recovery rate and one value of the default probability equal for all the underlying credits, see f.e. Hofert & Scherer (2008).
19

Figure 7: Isosurface of the Gauss (top left) and Gumbel (top right) copula density with Kendall's rank correlation 0.6. Isosurface of the Gauss (bottom left) and Gumbel (bottom right) copula density with Kendall's rank correlations 0.5 and 0.8. Margins are modelled with the standard normal distribution.
However, as the spreads are calculated not on the total amount of the losses but only on its fraction that cannot be recovered, the loss given default has the significant effect on the final value of the payments. In the following proposition we take advantage of the finding of Altman, Brady, Resti & Sironi (2005) and Hamilton, Varma, Ou & Cantor (2005) who show that the recovery rate is stochastic and strongly negatively correlated with the default probabilities.
There is no standard method of modelling the recovery rate. Nevertheless many ways of introducing the recovery rate to the default risk modelling have been proposed. The stochastic recovery rate is also applied by Jarrow (2001) and Andersen & Sidenius (2005). Duffie & Singleton (1999) assume the recovery to be a proportion of the market data value, which is random but the recovery proportion is fixed. Hull & White (2004), Hull & White (2006) use the recovery rate that is fixed over time and for all obligors. Duffie & Ga^rleanu (2001) take it as a uniform random variable and Hull et al. (2006) assume that in the Gaussian copula framework it follows a beta distribution. However, Scaillet & Renault (2004) estimate the recovery rate density nonparametrically using a beta kernel method and parametrically using a beta distribution calibrated on the empirical mean
20

C1 (126)

C2 (125)

LGD

u1

u2 ... u124

u125

Figure 8: HAC with the random loss given default.

and variance. The nonparametric density estimates shows that the recovery rate is not beta distributed. Sch¨onbucher (2003) models the recovery of a defaulted obligor with a logistic normal process. R¨osch & Scheule (2005) propose a multifactor-model for defaults and recoveries. Das & Hanouna (2009) find that the identification of the recovery rate and default intensities is infeasible using only the term structure of CDS spreads. They provide a jump-to-default model that uses the stock prices and the stock volatility with credit spreads to identify the implied functions of the recovery rate and the default probability. Pan & Singleton (2008) handle with the identification problem and propose a model which separately identifies the parameters through the information contained in the term structure of CDS contract.

In the following section we propose a method of modelling the relation between the joint default times and the loss given default. We keep the assumption of the constant recovery rate in the univariate model for CDS contracts, but we bring in the additional randomness to the CDO valuation. The high dimensionality of the collateral forces us to apply the same loss given default for all the underlyings. However, we apply copula functions that enable us to reflect the observed relations. We have already pointed out that the Gumbel copula is characterised by interesting properties which make it suitable for credit risk modelling. In the next step we will focus on this family while developing the model. As the Gumbel copula can only represent positive dependence, we introduce the dependence between the default times and the loss given default. For our problem we apply hierarchical Archimedean copulae composed of Gumbel copulae of different dimensions. As there is no clear evidence on the specific distribution of the loss given default we leave it uniformly distributed on [0, 1].

The first proposition is the straightforward extension of the one-parameter model. The hierarchical structure integrates the loss given default with the default times as illustrated in Figure 8. The applied copula has the following form:

C(u1, . . . , ud, ud+1; ) = C1{ud+1, C2(u1, . . . , ud; 2); 1},

(22)

where  = (1, 2) . On the first level the whole pool of credits is modelled with a 125-dimensional copula C2 with the parameter 2 as was done in the simplest case. The

21

C1 (126)

C2 (125)

LGD

C3 C3 ... C3 C3

(30) (25)

(20) (10)

u1

u2 ... u29

u30

Figure 9: HAC with the random loss given default and the sector structure.

second level joins the defaults and the loss given default with a 126-dimensional copula C1 with the parameter 1. A similar approach has been recently investigated by Ho¨cht & Zagst (2009).

Another model incorporates the natural structure of the CDO pool and is visualised in Figure 9. The corresponding copula function is given by:

C(u1, . . . , ud, ud+1; ) = C1[ ud+1, C2{C3(u1, . . . , um1; 3), C3(um1+1, . . . , um1+m2; 3), . . . ,

C3(um1+...+m5+1, . . . , ud; 3); 2}; 1],

(23)

where  = (1, 2, 3) . The lowest level of the hierarchy connects the defaults within the sectors of the CDO collateral. The middle stage joins the six sectors. The highest level aggregates the loss given default and the Archimedean copula from the previous level.

The possible extension of this approach could be to introduce distinct loss given defaults for each sector. Then the copula would have the following form:

C(u1, . . . , ud, . . . , ud+6; ) = C1[ C2{ud+1, C3(u1, . . . , um1; 3); 2}, C2{ud+2, C3(um1+1, . . . , um1+m2; 3); 2}, . . . , C2{ud+6, C3(um1+...+m5+1, . . . , ud; 3); 2}; 1],

(24)

where  = (1, 2, 3) . We start by coupling random variables within sectors. At the second level we connect each sector with the loss given default. The final stage consist of joining the subgroups with the 131-dimensional copula. (23) and (24) require the estimation of three parameters, however the complexity of last method makes it computationally expensive and involves time demanding simulations.

22

Spread (bps) Upfront Fee (%)

700 560 420 280 140
0 20071116 20080122 20080328 20080604 Time

50 40 30 20 10
0 20071116 20080122 20080328 20080604 Time

Figure 10: Spreads of iTraxx tranches, Series 8, maturity 5 years, data from 2007102220080630. Left panel: mezzanine junior (dashed black), mezzanine (dashed red), senior (solid black), super senior (solid red). Right panel: upfront fee of the equity tranche.
5 Empirical Results

The empirical research of this study was performed using the iTraxx Euro index series 8 with a maturity of 5 years. The series 8 was issued on 20 September 2007 and expires on 20 December 2012. The computations were carried out on ten randomly chosen days: 20071022, 20071025, 20071116, 20071205, 20080110, 20080227, 20080313, 20080423, 20080529, 20080630. The historical data from the considered period are depicted in Figure 10. The constant interest rate r = 0.03 was assumed. We considered all d = 125 underlying CDS contracts and J = 5 CDO tranches, from the equity to the super senior.
We start by estimating the univariate distributions of each time to default variable i, i = 1, . . . , 125, in the framework of the reduced form model presented in the section 3.1. We proceed with the CDS pricing method described in Section 3.2 assuming that the unknown intensities are constant until maturity. The recovery rate is assumed to be constant and equal for all contracts R = 0.4. The fair spread of ith contract given by (5) is then a function of one parameter i. The intensity for which the fair spread matches the market spread is implied by the model using a bisection method.
Afterwards we generate N = 106 times a vector of trigger variables (U1, . . . , Ud)  C from different dependency structures. The copulae taken into consideration were the one and two-parameter Gaussian and the one and two-parameter Gumbel with the constant loss given default. The applied two-parameter Gumbel copula is a HAC of the form (21). We also test the two and three-parameter HAC Gumbel copula with a random loss given default given by (22) and (23). The method of sampling from a hierarchical Gumbel copula was taken from McNeil (2008).
The Monte Carlo samples of the default times allow for the portfolio loss process L(t), the loss Lj(t) and the outstanding notional Fj(t) of each tranche to be calculated using (7), (8) and (9) respectively for every payment date t after t0 and till maturity T . The
23

D

8
6
4
2
0 0 0.2 0.4 0.6 0.8 1


Figure 11: Calibration of the one-factor Gaussian model. Measure D as a function of the correlation  and the number of simulations N : 103 (thin black), 104 (thick red), 105 (thick black), data from 20071022, R = 0.4, r = 0.03.

simulated losses are applied to obtain the default legs DLj(t0) defined in (12) and P Lj (t0) from (14). The expected values in these formulae are calculated as the sample averages over 106 values. We denote the sample default leg with DLj(t0) and the sample P Lj(t0)

with P Lj (t0). Finally, the model spread is computed as:

sjc(t0)

=

DLj (t0 )


for j = 1, . . . , J.

P Lj (t0)

The copula parameters are found by adjusting them to reproduce the true prices. The main idea of the calibration is to minimise the cumulative relative deviations of the model spreads scj from the market spreads smj :

D(t0)

d=ef

J j=1

|sjc(t0) - sjm(t0)| sjm(t0)



min .

(25)

As the first tranche does not quote spread on the market, we do not observe sm1 . To allow for the comparison of the first tranche with other tranches we transform the equity tranche that gives the upfront fee and the constant running spread into the tranche with changing running spread and no upfront fee. The equivalent equity tranche has the following spread

s1m(t0) = m(t0)(u1 - l1)100/P Lj (t0) + 500, where m(t0) is the market value of the upfront fee.

We begin by discussing outcomes of the copula models with the constant loss given default that are carried out with R = 0.4. In the case of the one-parameter copulae, the result is attained with the bisection method. For the optimal copula parameter the objective function D, defined in (25), satisfies D < , where  is a small enough.

Figure 11 exhibits the measure D calculated for the one-factor Gaussian model for   (0, 1). We see that the final result is very sensitive to the number of Monte Carlo simulations performed.

24

66

44

 2D D
2

22

0 2

46 

8 10

0 0.14 0.33 0.52 0.71 K

0.9

Figure 12: Calibration of the one-factor Gumbel model. Measure D as a function of  (left) and K (right), data from 20071022, R = 0.4, r = 0.03, N = 104.

1500

1500

1000

1000

500 500

0

0

500

1000

1500

1

0

0

500

1000

1500

1

Figure 13: Default times of Kingfisher and Deutsche Bank based on the samples generated from Gaussian (left) and Gumbel (right) copula with estimated parameters, data from 20071022, R = 0.4, r = 0.03, N = 104.

D

10

8

6

4

2 0 0.5

10

0.5 1

1 2

Figure 14: Calibration of the two-factor Gaussian model with the constant loss given
default. Measure D as a function of 1 and 2, data from 20071022, R = 0.4, r = 0.03, N = 104.

25

The measure D for the one-factor Gumbel model for  and the Kendall's rank correlation coefficient K is depicted in Figure 12. The Kendall's rank correlation can be conveniently computed for the Gumbel copula via the identity K = 1 - 1/. For both parameters we obtain the unique solution.
As the Gumbel copula exhibits the upper tail dependence, it generates higher aggregate loss fluctuations which lead to a higher risk of the collateral. Figure 13 illustrates the correlated default times of two companies: Kingfisher from the retail industry and Deutsche Bank from the financial sector. The samples were generated from the Gaussian and the Gumbel bivariate copula with parameters estimated from the CDO pricing model, see Table 2. The default times from the Gumbel copula are placed nearer to the origin and the axes, than the default times from Gaussian copula which are more dispersed and allocated further from the origin. The CDS of Kingfisher revealed a remarkably higher value of lambda which caused the asymmetry layout in the graph where the points are more vertically spread.
In the estimation of the two-parameter models the 2-dimensional minimum of a function D is computed using the Nelder-Mead downhill simplex search method, see Press, Teukolsky, Vetterling & Flannery (2002). The parameter 2 that measures the dependence within the industry sector represents a stronger relation. We therefore impose the constraint that 2 is never smaller than 1. Moreover, the condition 1  2 guarantees that the correlation matrix (20) is positive-definite and the function C is a proper copula, see McNeil & Neslehov´a (2009).
The calibration of the two-factor model with the Gaussian dependency structure is illustrated in Figure 14. The plot does not visibly point to where the minimum is, as it is in Figures 11 and 12, but indicates the region where we should carry on looking. Figure 15 exhibits how the measure D in the two-factor Gumbel model changes when both parameters change. While dealing with 1, 2, the minimum is located near the point (1, 1). In the case of the Kendall's rank correlations, the area where we search for the minimum is located close to the point (0.12, 0.12) on the diagonal.
We compare the simplex optimisation with the simpler search method inspired by the technique applied by Hofert & Scherer (2008). In this approach we first assume that the unknown parameters are equal, 1 = 2. For the starting point we take the outcome of the one-parameter model estimation. Afterwards we move on a two-dimensional grid created from the possible values of the parameters. We go along the path by changing 1 and 2 where the measure D is minimised. Because of the constraints, the grid has a triangular shape. We start from the diagonal of the grid and calculate the function D in three points equidistant from the origin. The considered points lie to the left, to the left diagonally and above. We choose the direction that gives the smallest value for D. The steps of the simple search algorithm for two-factor models are depicted in Figure 16 (upper panel). The solution of the one-factor models are marked with a small black dot on the diagonals. Other black points represent the path where the objective function has its local minimum. The global minimum is selected by the comparison of all local ones and is marked with a bold dot. For both copulae the final solution was found in not more than 15 steps, see
26

D

4 3 2 1 0 0
0.2 0.4 0
K1

0.2 K
2

0.4

Figure 15: Calibration of the two-factor Gumbel model with the constant loss given default. Measure D as a function of 1, 2 (left) and K1 , K2 (right), data from 20071022, R = 0.4, r = 0.03, N = 104.
lower panel of Figure 16. Nevertheless the two-parameter models require a more accurate minimisation method. Adding one parameter to the single-parameter model meaningfully increases the complexity and the duration of the estimation procedure. Figures 14 and 15 present the smoothed objective function which is in practice very coarse. Therefore, it is much more difficult to optimise and demand a high number of simulations.
The calibration of the models with the random loss given default is conducted the same as in the case of the constant loss given default models. We assume that the loss given default is uniformly distributed on [0, 1]. Figure 17 illustrates how the measure D changes in the one-factor Gumbel model when the Kendall's rank correlation and the loss given default vary. With the increasing Kendall's rank correlation the minimum is found for the decreasing loss given default.
The results of the estimation of six models are exhibited in Table 2. In the table 1-Gauss, 1-Gumb., 2-Gauss, 2-Gumb., 2-Gumb. and 3-Gumb. stand for one-parameter Gaussian, Gumbel, two-parameter Gaussian, Gumbel and three-parameter Gumbel copula model respectively. The values of measure D show that the Gumbel copula models provide a much more precise fit to iTraxx market data than the Gaussian copula models. The models with the random loss given default achieve the best results. However, the threeparameter model outperformed the two-parameter model with the random loss given only in two cases. Surprisingly, by applying the most complex structure with three parameters we do not come closer to the true values of the spreads. The two-parameter models with the constant loss given default describe the prices better than the models with only one parameter. However, the two parameters seem to be very close to each other and the improvement of the two-factor model compared to the one-factor model for both dependency structure is small.
The calibration of the models carried out on 27 February and 13 March 2008 revealed unrealistically high values of all parameters with relatively small values of D. These specific dates were marked with asterisks in Table 2. Plausible reasons for this disturbance
27


2
D 
2

0.5
0.4
0.3
0.2
0.1 0.1 0.2 0.3 0.4 0.5 
1
0.36

1.162
1.152
1.142
1.132
1.122 1.122 1.132 1.142 1.152 1.162 
1

0.33

0.3

0.27
6 12 18 24 30 Steps

Figure 16: Calibration of the two-factor Gaussian (upper left) and Gumbel (upper right and bottom) model with the simple search algorithm, data from 20071022, R = 0.4, r = 0.03, N = 106.

10

D

5

0 1
0.5 01
K

0.5 LGD

0

Figure 17: Measure D as a function of the Kendall's rank correlation K and the loss given default in the one-factor Gumbel model. Data from 20071022, r = 0.03, N = 104.

28

Relative Deviations

0.25 0.2
0.15 0.1
0.05 0 1 1
0.8 0.6 0.4 0.2
0 1

234 Tranches
234 Tranches

5 5

Relative Deviations

Relative Deviations

1 0.8 0.6 0.4 0.2
0 1
1 0.8 0.6 0.4 0.2
0 1

234 Tranches
234 Tranches

5 5

Relative Deviations

Figure 18: Relative deviations from the market upfront fee (first tranche) and the relative deviations from the market spreads (tranches 2-5) for the Gumbel models with the constant loss given default: one-factor (red), the two-factor (dash-dot) and with the random loss given default: with the industry structure (dashed red) and without (dashed black). Data from 20071022, 20080110, 20080630, 20080529 (clockwise).
might be found in the economical situation at that time. Events that took place on these two particular days might have been so significant that they destabilised the market which was then reflected by the models. On 27 February 2008 several items of bad news came from the telecoms sector. Telecommunications companies Versatel and Nortel announced financial difficulties due to worsening conditions on the mobile telephony and Internet markets. Moreover, the European Union imposed a fine of e899 million on Microsoft, the largest penalty in the history of EU competition policy, for refusing to comply with a long-standing request to provide competitors with key software data at a fair price. On 13 March 2008 the fifth largest investment bank in the United States, Bear Stearns reported a 15 billion (88%) drop in liquid assets and confronted the US authorities with the company's collapse. A few days later the Federal Reserve provided funds and guarantees to enable J.P. Morgan Chase to purchase the insolvent bank. Bear Stearns spectacularly went bankrupt after the failure of its two hedge funds whose investments were highly concentrated in the subprime market. The estimation results show that even if in most cases the Gumbel copula models satisfactorily reproduce the CDO spreads, the models are not able to resist some downward market shocks.
29

Date
20071022 20071025 20071116 20071205 20080110 20080227 20080313 20080423 20080529 20080630

1-Gauss 1
0.2356 (2.2971)
0.1459 (2.7750)
0.1930 (3.9309)
0.1459 (4.1684)
0.2997 (3.5166)
0.9874 (2.0559)
0.9986 (2.3416)
0.2361 (4.4135)
0.2363 (4.1966)
0.2326 (4.1478)

constant LGD

1-Gumb. 2-Gauss

1 1 2

1.1448 0.2348 0.2396

(0.2987)

(2.2767)

1.1160 0.2048 0.2275

(0.3605)

(2.7136)

1.1523 0.1794 0.2514

(1.3065)

(3.9106)

1.1337 0.1635 0.2246

(1.1457)

(3.9603)

1.1877 0.2785 0.4015

(1.0741)

(3.5113)

1.6654 0.8433 0.9985

(1.8529)

(3.0295)

1.5704 0.9964 0.9997

(1.8892)

(2.3483)

1.1749 0.2300 0.2416

(2.0350)

(4.3862)

1.1462 0.2207 0.3168

(1.6679)

(4.1749)

1.1843 0.2326 0.2453

(1.8005)

(4.0947)

2-Gumb. 1 2
1.1340 1.1405 (0.2168)
1.1108 1.1119 (0.3481)
1.1637 1.1645 (1.2876)
1.1339 1.1342 (1.1153)
1.1838 1.1887 (1.0581)
1.6429 1.6485 (1.8037)
1.5647 1.5684 (1.8858)
1.1735 1.1798 (2.0279)
1.1478 1.1589 (1.6361)
1.1849 1.1904 (1.7821)

random LGD

2-Gumb.

3-Gumb.

1 2

1 2 3

1.0626 1.0866 1.0572 1.0920 1.0933

(0.0444)

(0.0498)

1.0320 1.1018 1.0121 1.1130 1.1271

(0.0879)

(0.1539)

1.0008 1.2117 1.0013 1.2041 1.2086

(0.5704)

(0.6029)

1.0014 1.1807 1.0048 1.1709 1.1721

(0.5060)

(0.5359)

1.0009 1.2708 1.0028 1.2633 1.2705

(0.1806)

(0.1999)

1.0005 1.4440 1.0015 1.4208 1.4324

(0.5997)

(0.6282)

1.0009 1.4056 1.0008 1.4377 1.4384

(0.7743)

(0.7727)

1.0020 1.2833 1.0008 1.3096 1.3191

(0.8769)

(0.8850)

1.0008 1.2117 1.0004 1.2979 1.3228

(0.7067)

(0.9525)

1.0034 1.3230 1.0023 1.3127 1.3190

(0.5664)

(0.5420)

30

Table 2: Parameters and values of the measure D (in brackets) of the estimated copula models.

Compound Kendall K

0.25 0.2
0.15 0.1
0.05 0 1
0.25 0.2
0.15 0.1
0.05 0 1

234 Tranches
234 Tranches

5 5

Compound Kendall K

Compound Kendall K

0.25 0.2
0.15 0.1
0.05 0 1
0.25 0.2
0.15 0.1
0.05 0 1

234 Tranches
234 Tranches

5 5

Compound Kendall K

Figure 19: Implied compound Kendall's K. Upper panel: copula models with the constant loss given default, Gaussian (left) and Gumbel (right), one-factor model (dashed), two-factor model (solid). Lower panel: copula models with the random loss given default, without the industry structure (left) and with (right), K1 (red), K2 (black), 3K (dashed). Data from 20071022, r = 0.03, N = 106.
By looking at the values of measure D, the question arises how the relative errors are distributed among tranches. If one model outperforms another, does it mean that it provides a better results for each tranche? Figure 18 exhibits the relative errors computed separately for each tranche on the following days: 20071022, 20080110, 20080529, 20080630. The upfront fees and the spreads that are compared with the real market quotes are supplementary results obtained during minimisation of the function D and correspond to the values given in Table 2. The plots clearly point out that the equity tranche has the strongest impact on calibration and the significant reduction of the estimation error was achieved using the models with the random loss given default. We observe that the curves tend not to be parallel. Even for 20080110 and 20080630, where the models with the same loss given default types generate the curves that have similar shapes, the improvement varies across tranches. From these plots we can conclude that there is no one single model that ascribes the smallest proportions of the estimation error for every tranche.

31

Base Kendall K

0.5 0.4 0.3 0.2 0.1
0 1

234 Tranches

5

Base Kendall K

0.5 0.4 0.3 0.2 0.1
0 1

234 Tranches

5

Base Kendall K

0.5 0.4 0.3 0.2 0.1
0 1

234 Tranches

5

Base Kendall K

0.5 0.4 0.3 0.2 0.1
0 1

234 Tranches

5

Figure 20: Implied base Kendall's K. Upper panel: copula models with the constant loss given default, Gaussian (left) and Gumbel (right): one-factor model (dashed), two-factor model (solid) Lower panel: copula models with the random loss given default, without the industry structure (left) and with (right), 1K (red), K2 (black), K3 (dashed). Data from 20071022, r = 0.03, N = 106.
Finally, we investigate the implied copula parameters using data from 22 October 2007. We consider both compound and base correlations that were discussed in Section 4.1. To compare the Gaussian with the Gumbel dependency structure we transform all parameters into Kendall's rank correlations. In the case of two-factor models we imply all copula parameters simultaneously. Figure 19 shows implied compound and Figure 20 presents implied base Kendall K. The compound correlations implied by the Gaussian models disclose the typical smile. The base implied correlations of the Gauss copula strictly increase. We observe that the Gumbel models flatten the implied compound and base parameter curves. The compound correlations of Gumbel copulae form dissimilar curves so it is not possible to infer the models' accuracy from their shapes. From the base correlation plots we see that the Gumbel models with random loss given default have the most horizontal form of all which confirms that they produce the most exact results.

32

6 Conclusions
This work presents copula based models to price CDOs. The dynamics of the individual default intensities are described by means of the reduce form model. The default intensities are estimated from the real market data of 125 CDS contracts that constitute a portfolio of the iTraxx Europe index. The construction of payments that are settled within the CDO and CDS contracts is given. The concept of multivariate copula functions is presented. We explain how to specify a joint distribution of assets with HACs. We propose models that use HACs to describe the dependency structure between default times and the loss given default. We measure a closeness of calibrated spreads with corresponding historical observations with a tractable function that incorporates the information from every tranche.
Empirical results exhibit that the standard market model based on the Gaussian distribution fails to replicate real market structures. Our findings indicate that the Gumbel copula approach is an appropriate way of defining the dependency in the problem of CDO valuation. Moreover, we show that in cases of constant loss given default the two factors provide a better risk evaluation than the single factor. The model that joints the default times with the random loss given default reveal the best fit to market tranche quotes. We further analyse the models and investigate the behaviour of the implied correlation smiles. We uncover that the Gumbel models significantly flatten the curves. However, we observe that the models are highly sensitive to the number of executed simulations and are not immune to market turbulences.
This paper develops an understanding of the CDO underlying dependency structure and should motivate a dynamic approach study. The ability of the models to correctly describe the dependence in the high dimensions makes it useful in pricing and hedging other complex credit derivatives.
References
Altman, E., Brady, B., Resti, A. & Sironi, A. (2005). The link between default and recovery rates: theory, empirical evidence and implications, The Journal of Business 78(6): 2203­2228.
Amato, J. & Gyntelberg, J. (2005). CDS index tranches and the pricing of credit risk correlations, BIS Quarterly Review 3(1): 73­87.
Andersen, L. & Sidenius, J. (2005). Extensions of the Gaussian copula, Journal of Credit Risk 1(1): 29­70.
Ang, A. & Chen, J. (2002). Asymmetric correlations of equity portfolios, Journal of Financial Economics 63(3): 443­494.
Bluhm, C. & Overbeck, L. (2006). Structured Credit Portfolio Analysis, Baskets and CDOs, CRC Press LLC.
33

Bluhm, C., Overbeck, L. & Wagner, C. (2002). An Introduction to Credit Risk Modelling, CRC Press LLC.
Burtshell, X., Gregory, J. & Laurent, J.-P. (2008). A comparative analysis of CDO pricing models, in G. Meissner (ed.), The Definitive Guide to CDOs, Risk Books, pp. 389­ 427.
Das, S., Duffie, D., Kapadia, N. & Saita, L. (2007). Common failings: how corporate defaults are correlated, Journal of Finance 62(1): 93­117.
Das, S., Freed, L., Geng, G. & Kapadia, N. (2006). Correlated default risk, Journal of Fixed Income 14(1): 7­32.
Das, S. & Hanouna, P. (2009). Implied recovery, Journal of Economic Dynamics and Control . Forthcoming.
Daul, S., De Giorgi, E., Lindskog, F. & McNeil, A. (2003). Using the grouped t-copula, RISK 16(11): 73­76.
Davis, M. & Lo, V. (2001). Infectious defaults, Quantitative Finance 1(4): 382­387.
Duffie, D. (1999). Credit swap valuation, Financial Analysts Journal 55(1): 73­87.
Duffie, D. & G^arleanu, N. (2001). Risk and valuation of collateralized debt obligations, Financial Analysts Journal 57(1): 41­59.
Duffie, D. & Singleton, K. (1999). Modeling term structures of defaultable bonds, Review of Financial Studies 12(4): 687­720.
Finger, C. (2004). Issues in the pricing of synthetic CDOs, The Journal of Credit Risk 1(1): 113­124.
Frey, R., McNeil, A. & Nyfeler, M. (2001). Copulas and credit models, RISK 14(10): 111­ 114.
Friend, A. & Rogge, E. (2005). Correlation at first sight, Economic Notes 34(2): 155­183.
Gregory, J. & Laurent, J.-P. (2004). In the core of correlation, RISK 17(10): 87­91.
Gregory, J. & Laurent, J.-P. (2005). Basket default swaps, CDOs and factor copulas, Journal of Risk 7(5): 103­122.
Gupton, G., Finger, C. & Bhatia, M. (1997). Creditmetrics ­ technical document, Technical document, Morgan Guaranty Trust Company.
Hamilton, D., Varma, P., Ou, S. & Cantor, R. (2005). Default and recovery rates of corporate bond issuers, Technical report, Moody's Investor's Services.
Ho¨cht, S. & Zagst, R. (2009). Pricing distressed cdos with stochastic recovery, Working paper, Universita¨t Mu¨nchen.
34

Hofert, M. & Scherer, M. (2008). CDO pricing with nested Archimedean copulas, Working paper, Universit¨at Ulm.
Hull, J. & White, A. (2000). Valuing credit default swaps I: no counterparty default risk, Journal of Derivatives 8(1): 29­40.
Hull, J. & White, A. (2001). Valuing credit default swaps II: modeling default correlations, Journal of Derivatives 8(3): 12­22.
Hull, J. & White, A. (2004). Valuation of a CDO and an nth to default CDS without monte carlo simulation, Journal of Derivatives 12(2): 8­23.
Hull, J. & White, A. (2006). Valuing credit derivatives using an implied copula approach, Journal of Derivatives 14(2): 8­28.
Hull, J., White, A. & Predescu, M. (2006). The valuation of correlation-dependent credit derivatives using a structural model, Working paper, University of Toronto.
Jarrow, R. (2001). Default parameter estimation using market prices, Financial Analysts Journal 57(5): 75­92.
Jarrow, R. & Yu, F. (2001). Counterparty risk and the pricing of defaultable securities, Journal of Finance 56(5): 1765­1799.
Joe, H. (1997). Multivariate Models and Dependence Concepts, Chapman & Hall, London.
Kalemanova, A., Schmid, B. & Werner, R. (2007). The normal inverse Gaussian distribution for synthetic CDO pricing, Journal of Derivatives 14(3): 80­93.
Klu¨ppelberg, C., Kuhn, G. & Peng, L. (2008). Semi-parametric models for the multivariate tail dependence function - the asymptotically dependent case, Scandinavian Journal of Statistics 35(4): 701­718.
Lando, D. (1994). Three Essays on Contingent Claims Pricing, PhD thesis, Cornell University.
Li, D. X. (1999). Creditmetrics monitor, Technical document, RiskMetrics.
Li, D. X. (2000). On default correlation: a copula function approach, The Journal of Fixed Income 9(4): 43­54.
Longstaff, F. & Rajan, A. (2008). An empirical analysis of the pricing of collateralized debt obligations, Journal of Finance 63(2): 529­563.
Marshall, A. & Olkin, J. (1988). Families of multivariate distributions, Journal of the American Statistical Association 83(403): 834­841.
McGinty, L. & Ahluwalia, R. (2004). A model for base correlation calculation, Technical report, JP Morgan.
McNeil, A. (2008). Sampling nested Archimedean copulas, Journal Statistical Computation and Simulation 78(6): 567­581.
35

McNeil, A. & Neslehova´, J. (2009). Multivariate Archimedean copulas, d-monotone functions and l1 norm symmetric distributions, Annals of Statistics . Forthcoming.
Merton, R. (1974). On the pricing of corporate debt: the risk structure of interest rates, Journal of Finance 29(2): 449­470.
Mortensen, A. (2006). Semi-analytical valuation of basket credit derivatives in intensitybased models, Journal of Derivatives 13(4): 8­26.
Nelsen, R. (2006). An Introduction to Copulas, Springer Verlag, New York.
Nikoloulopoulos, A., Joe, H. & Li, H. (2008). Extreme value properties of multivariate t copulas, Extremes 12(2): 129148.
O'Kane, D. & Schl¨ogl, L. (2005). A note on the large homogeneous portfolio approximation with the Student-t copula, Finance and Stochastics 9(4): 577­584.
Okhrin, O., Okhrin, Y. & Schmid, W. (2008). On the structure and estimation of hierarchical Archimedean copulas, Journal of Econometrics . Under revision.
Okhrin, O., Okhrin, Y. & Schmid, W. (2009). Properties of the hierarchical Archimedean copulas, Discussion paper, SFB 649, Humboldt Universit¨at zu Berlin.
Pan, J. & Singleton, K. (2008). Default and recovery implicit in the term structure of sovereign CDS spreads, The Journal of Finance 63(5): 2345­2384.
Press, W., Teukolsky, S., Vetterling, W. & Flannery, B. (2002). Numerical Recipes in C++. The Art of Scientific Computing, 2 edn, Cambridge University Press.
R¨osch, D. & Scheule, H. (2005). A multifactor approach for systematic default and recovery risk, Journal of Fixed Income 15(2): 63­75.
Scaillet, O. & Renault, O. (2004). On the way to recovery: A nonparametric bias free estimation of recovery rate densities, Journal of Banking and Finance 28(12): 2915­ 2931.
Schmidt, R. & Stadtmu¨ller, U. (2006). Nonparametric estimation of tail dependence, Scandinavian Journal of Statistics 33(2): 307­335.
Sch¨onbucher, P. (2003). Credit Derivatives Pricing Models: Model, Pricing and Implementation, John Wiley & Sons.
Sklar, A. (1959). Fonctions de r´epartition `a n dimensions et leurs marges, Publ. Inst. Stat. Univ. Paris 8: 299­231.
Whelan, N. (2004). Sampling from Archimedean copulas, Quantitative Finance 4(3): 339­ 352.
Willemann, S. (2005). An evaluation of the base correlation framework for synthetic CDOs, Journal of Credit Risk 1(4): 180­190.
36

Willemann, S. (2007). Fitting the cdo correlation skew: a tractable structural jumpdiffusion model, Journal of Credit Risk 3(1): 63­90.
37

SFB 649 Discussion Paper Series 2009
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
001 "Implied Market Price of Weather Risk" by Wolfgang Härdle and Brenda López Cabrera, January 2009.
002 "On the Systemic Nature of Weather Risk" by Guenther Filler, Martin Odening, Ostap Okhrin and Wei Xu, January 2009.
003 "Localized Realized Volatility Modelling" by Ying Chen, Wolfgang Karl Härdle and Uta Pigorsch, January 2009.
004 "New recipes for estimating default intensities" by Alexander Baranovski, Carsten von Lieres and André Wilch, January 2009.
005 "Panel Cointegration Testing in the Presence of a Time Trend" by Bernd Droge and Deniz Dilan Karaman Örsal, January 2009.
006 "Regulatory Risk under Optimal Incentive Regulation" by Roland Strausz, January 2009.
007 "Combination of multivariate volatility forecasts" by Alessandra Amendola and Giuseppe Storti, January 2009.
008 "Mortality modeling: Lee-Carter and the macroeconomy" by Katja Hanewald, January 2009.
009 "Stochastic Population Forecast for Germany and its Consequence for the German Pension System" by Wolfgang Härdle and Alena Mysickova, February 2009.
010 "A Microeconomic Explanation of the EPK Paradox" by Wolfgang Härdle, Volker Krätschmer and Rouslan Moro, February 2009.
011 "Defending Against Speculative Attacks" by Tijmen Daniëls, Henk Jager and Franc Klaassen, February 2009.
012 "On the Existence of the Moments of the Asymptotic Trace Statistic" by Deniz Dilan Karaman Örsal and Bernd Droge, February 2009.
013 "CDO Pricing with Copulae" by Barbara Choros, Wolfgang Härdle and Ostap Okhrin, March 2009.
014 "Properties of Hierarchical Archimedean Copulas" by Ostap Okhrin, Yarema Okhrin and Wolfgang Schmid, March 2009.
015 "Stochastic Mortality, Macroeconomic Risks, and Life Insurer Solvency" by Katja Hanewald, Thomas Post and Helmut Gründl, March 2009.
016 "Men, Women, and the Ballot Woman Suffrage in the United States" by Sebastian Braun and Michael Kvasnicka, March 2009.
017 "The Importance of Two-Sided Heterogeneity for the Cyclicality of Labour Market Dynamics" by Ronald Bachmann and Peggy David, March 2009.
018 "Transparency through Financial Claims with Fingerprints ­ A Free Market Mechanism for Preventing Mortgage Securitization Induced Financial Crises" by Helmut Gründl and Thomas Post, March 2009.
019 "A Joint Analysis of the KOSPI 200 Option and ODAX Option Markets Dynamics" by Ji Cao, Wolfgang Härdle and Julius Mungo, March 2009.
020 "Putting Up a Good Fight: The Galí-Monacelli Model versus `The Six Major Puzzles in International Macroeconomics'", by Stefan Ried, April 2009.
021 "Spectral estimation of the fractional order of a Lévy process" by Denis Belomestny, April 2009.
022 "Individual Welfare Gains from Deferred Life-Annuities under Stochastic Lee-Carter Mortality" by Thomas Post, April 2009.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

SFB 649 Discussion Paper Series 2009
For a complete list of Discussion Papers published by the SFB 649, please visit http://sfb649.wiwi.hu-berlin.de.
023 "Pricing Bermudan options using regression: optimal rates of convergence for lower estimates" by Denis Belomestny, April 2009.
024 "Incorporating the Dynamics of Leverage into Default Prediction" by Gunter Löffler and Alina Maurer, April 2009.
025 "Measuring the effects of geographical distance on stock market correlation" by Stefanie Eckel, Gunter Löffler, Alina Maurer and Volker Schmidt, April 2009.
026 "Regression methods for stochastic control problems and their convergence analysis" by Denis Belomestny, Anastasia Kolodko and John Schoenmakers, May 2009.
027 "Unionisation Structures, Productivity, and Firm Performance" by Sebastian Braun, May 2009.
028 "Optimal Smoothing for a Computationally and Statistically Efficient Single Index Estimator" by Yingcun Xia, Wolfgang Härdle and Oliver Linton, May 2009.
029 "Controllability and Persistence of Money Market Rates along the Yield Curve: Evidence from the Euro Area" by Ulrike Busch and Dieter Nautz, May 2009.
030 "Non-constant Hazard Function and Inflation Dynamics" by Fang Yao, May 2009.
031 "De copulis non est disputandum - Copulae: An Overview" by Wolfgang Härdle and Ostap Okhrin, May 2009.
032 "Weather-based estimation of wildfire risk" by Joanne Ho and Martin Odening, June 2009.
033 "TFP Growth in Old and New Europe" by Michael C. Burda and Battista Severgnini, June 2009.
034 "How does entry regulation influence entry into self-employment and occupational mobility?" by Susanne Prantl and Alexandra Spitz-Oener, June 2009.
035 "Trade-Off Between Consumption Growth and Inequality: Theory and Evidence for Germany" by Runli Xie, June 2009.
036 "Inflation and Growth: New Evidence From a Dynamic Panel Threshold Analysis" by Stephanie Kremer, Alexander Bick and Dieter Nautz, July 2009.
037 "The Impact of the European Monetary Union on Inflation Persistence in the Euro Area" by Barbara Meller and Dieter Nautz, July 2009.
038 "CDO and HAC" by Barbara Choro, Wolfgang Härdle and Ostap Okhrin, July 2009.
SFB 649, Spandauer Straße 1, D-10178 Berlin http://sfb649.wiwi.hu-berlin.de
This research was supported by the Deutsche Forschungsgemeinschaft through the SFB 649 "Economic Risk".

